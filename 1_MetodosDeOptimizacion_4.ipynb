{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ba8293",
   "metadata": {},
   "source": [
    "# Existen 3 buenos metodos para optimizar el modelo en forma de backpropagation\n",
    "\n",
    "#### ADAM\n",
    "#### SGD\n",
    "#### rmsPROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07b844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf8b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1002c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93fb15",
   "metadata": {},
   "source": [
    "## creamos la distribucion para la prueba TOMANDO EN CUENTA SOLO 1000 IMAGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1beae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "Y_train=[]\n",
    "dataTr=[]\n",
    "for filename in glob.glob(os.path.join('data/train/malignant','*.jpg')):\n",
    "    dataTr.append([1,cv2.imread(filename)])\n",
    "for filename in glob.glob(os.path.join('data/train/benign','*.jpg')):\n",
    "    dataTr.append([0,cv2.imread(filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9391f6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en total tenemos: 2637 imagenes dentro de la carpeta train\n"
     ]
    }
   ],
   "source": [
    "shuffle(dataTr)\n",
    "print(\"en total tenemos: \"+str(len(dataTr))+ \" imagenes dentro de la carpeta train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45410d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para entrenamiento tendremos: 700 imagenes de la carpeta de train\n",
      "para prueba tendremos: 300 imagenes de la carpeta de test\n"
     ]
    }
   ],
   "source": [
    "porcion1=dataTr[0:700]\n",
    "porcion2=dataTr[701:1001]\n",
    "print(\"para entrenamiento tendremos: \"+str(len(porcion1))+ \" imagenes de la carpeta de train\")\n",
    "print(\"para prueba tendremos: \"+str(len(porcion2))+ \" imagenes de la carpeta de test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995873d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particion(datos):\n",
    "    imagenes=[]\n",
    "    etiquetas=[]\n",
    "    for i,j in datos:\n",
    "        imagenes.append(j)\n",
    "        etiquetas.append(i)\n",
    "    imagenes=np.array(imagenes)\n",
    "    etiquetas=np.array(etiquetas)\n",
    "    return (imagenes,etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8496c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e,y_e=particion(porcion1)\n",
    "x_p,y_p=particion(porcion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e444a4",
   "metadata": {},
   "source": [
    "# CREAMOS LAS CAPAS DE LA CONVOLUCION Y RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ac164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creacion_modelo():\n",
    "    modelo=Sequential()\n",
    "    modelo.add(Convolution2D(32,(3,3),input_shape=(224,224,3),activation='relu'))\n",
    "    modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "    modelo.add(Flatten())\n",
    "    modelo.add(Dense(128,activation='relu'))\n",
    "    modelo.add(Dense(150,activation='relu'))\n",
    "    modelo.add(Dense(150,activation='relu'))\n",
    "    modelo.add(Dense(1,activation='sigmoid'))\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc328ca6",
   "metadata": {},
   "source": [
    "## Importamos la libreria de KERAS donde se almacenan los metodos de Descenso de Gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7b8146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43434d4",
   "metadata": {},
   "source": [
    "#### pondremos el valor que biene por defecto en el learning rate que es del 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edab759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1296d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacion(x_e,y_e,x_p,y_p,model,epocas):\n",
    "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
    "    a=model.evaluate(x_p,y_p)\n",
    "    return a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "431e190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion(modelo,porcentaje,nombre,v1,v2):\n",
    "    prediccion=0\n",
    "    epocas=1\n",
    "    while(True):\n",
    "        if prediccion < porcentaje:\n",
    "            prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
    "            epocas +=1\n",
    "            v1.append(epocas-1)\n",
    "            v2.append(prediccion)\n",
    "        else:\n",
    "            print(\"==> Para el metodo \"+nombre+\" se utilizo: \"+str(epocas-1)+\" epocas para llegar a mas del \"+str(porcentaje)+\"% de acertividad\")\n",
    "            break   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445dc97f",
   "metadata": {},
   "source": [
    "## metodo ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b17b6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo1=creacion_modelo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7522eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_adam = keras.optimizers.Adam(learning_rate=lr)\n",
    "modelo1.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be52e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 1249.4435 - acc: 0.4814 - val_loss: 31.7744 - val_acc: 0.4533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 31.7744 - acc: 0.4533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 9ms/sample - loss: 31.1187 - acc: 0.6314 - val_loss: 8.9569 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 8.9569 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 9ms/sample - loss: 5.6508 - acc: 0.7300 - val_loss: 9.2342 - val_acc: 0.5667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 9.2342 - acc: 0.5667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 8.6089 - acc: 0.6943 - val_loss: 6.7400 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 6.7400 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 3.1340 - acc: 0.8100 - val_loss: 1.6969 - val_acc: 0.7833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6969 - acc: 0.7833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 9ms/sample - loss: 4.0383 - acc: 0.7829 - val_loss: 8.9401 - val_acc: 0.7533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 8.9401 - acc: 0.7533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 2.7447 - acc: 0.7957 - val_loss: 2.1124 - val_acc: 0.7400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.1124 - acc: 0.7400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5152 - acc: 0.8986 - val_loss: 1.0282 - val_acc: 0.7800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0282 - acc: 0.7800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.1023 - acc: 0.9614 - val_loss: 1.4399 - val_acc: 0.7667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4399 - acc: 0.7667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.0687 - acc: 0.9714 - val_loss: 1.0281 - val_acc: 0.7867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0281 - acc: 0.7867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.0422 - acc: 0.9857 - val_loss: 1.0149 - val_acc: 0.7933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0149 - acc: 0.7933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.0327 - acc: 0.9900 - val_loss: 1.0193 - val_acc: 0.7933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0193 - acc: 0.7933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 9ms/sample - loss: 0.0249 - acc: 0.9943 - val_loss: 1.0626 - val_acc: 0.7967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0626 - acc: 0.7967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 9ms/sample - loss: 0.0189 - acc: 0.9943 - val_loss: 1.1209 - val_acc: 0.7933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1209 - acc: 0.7933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 9ms/sample - loss: 0.0143 - acc: 0.9971 - val_loss: 1.1931 - val_acc: 0.8033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1931 - acc: 0.8033\n",
      "==> Para el metodo ADAM se utilizo: 15 epocas para llegar a mas del 80% de acertividad\n"
     ]
    }
   ],
   "source": [
    "v_eA=[]\n",
    "v_aA=[]\n",
    "evaluacion(modelo1,80,\"ADAM\",v_eA,v_aA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac3b278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 394272)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               50466944  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 150)               19350     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 50,509,991\n",
      "Trainable params: 50,509,991\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87927e24",
   "metadata": {},
   "source": [
    "## metodo SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e15ac7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "modelo2=creacion_modelo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a540575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "modelo_sgd = keras.optimizers.SGD(learning_rate=lr)\n",
    "modelo2.compile(optimizer=modelo_sgd,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f8b033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 9ms/sample - loss: 119.6275 - acc: 0.6800 - val_loss: 0.7340 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7340 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5997 - acc: 0.7214 - val_loss: 0.6988 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6988 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5790 - acc: 0.7171 - val_loss: 0.7308 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7308 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5647 - acc: 0.7329 - val_loss: 0.7192 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7192 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5626 - acc: 0.7143 - val_loss: 0.7470 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7470 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5538 - acc: 0.7129 - val_loss: 0.7507 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7507 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5446 - acc: 0.7186 - val_loss: 0.7568 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7568 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5367 - acc: 0.7186 - val_loss: 0.7525 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7525 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5295 - acc: 0.7243 - val_loss: 0.7973 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7973 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5256 - acc: 0.7271 - val_loss: 0.7772 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7772 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5218 - acc: 0.7329 - val_loss: 0.7922 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7922 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5192 - acc: 0.7329 - val_loss: 0.7818 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7818 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5150 - acc: 0.7386 - val_loss: 0.7965 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7965 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5165 - acc: 0.7471 - val_loss: 0.8239 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8239 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5535 - acc: 0.7257 - val_loss: 0.7055 - val_acc: 0.7267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7055 - acc: 0.7267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5423 - acc: 0.7386 - val_loss: 0.7073 - val_acc: 0.7200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7073 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5209 - acc: 0.7571 - val_loss: 0.7783 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7783 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.5073 - acc: 0.7514 - val_loss: 0.7810 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7810 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4990 - acc: 0.7643 - val_loss: 0.8159 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8159 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4953 - acc: 0.7686 - val_loss: 0.8180 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8180 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4882 - acc: 0.7743 - val_loss: 0.7918 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7918 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4828 - acc: 0.7771 - val_loss: 0.8157 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8157 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4838 - acc: 0.7829 - val_loss: 0.8143 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8143 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4807 - acc: 0.8029 - val_loss: 0.8215 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8215 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4730 - acc: 0.7971 - val_loss: 0.8336 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8336 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4728 - acc: 0.8129 - val_loss: 0.8224 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8224 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4661 - acc: 0.8171 - val_loss: 0.8898 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8898 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4642 - acc: 0.8186 - val_loss: 0.8646 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8646 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4692 - acc: 0.8357 - val_loss: 0.8446 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8446 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4831 - acc: 0.8186 - val_loss: 0.8765 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8765 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4634 - acc: 0.8343 - val_loss: 0.7800 - val_acc: 0.7367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7800 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4565 - acc: 0.8386 - val_loss: 0.8624 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8624 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4498 - acc: 0.8529 - val_loss: 0.9186 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9186 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4607 - acc: 0.8500 - val_loss: 0.8711 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8711 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4460 - acc: 0.8629 - val_loss: 0.8994 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8994 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4433 - acc: 0.8557 - val_loss: 0.9278 - val_acc: 0.7400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9278 - acc: 0.7400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4357 - acc: 0.8614 - val_loss: 0.8639 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8639 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4327 - acc: 0.8700 - val_loss: 0.9183 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9183 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4338 - acc: 0.8729 - val_loss: 0.8748 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8748 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4288 - acc: 0.8714 - val_loss: 0.9040 - val_acc: 0.7200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9040 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4264 - acc: 0.8814 - val_loss: 0.9268 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9268 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4573 - acc: 0.8614 - val_loss: 0.8589 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8589 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4395 - acc: 0.8757 - val_loss: 0.8820 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8820 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4196 - acc: 0.8843 - val_loss: 0.8548 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8548 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4250 - acc: 0.8857 - val_loss: 0.9331 - val_acc: 0.7200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9331 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4140 - acc: 0.8914 - val_loss: 0.8907 - val_acc: 0.7200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8907 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4776 - acc: 0.8243 - val_loss: 0.7286 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7286 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4920 - acc: 0.8143 - val_loss: 0.8123 - val_acc: 0.7467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8123 - acc: 0.7467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4511 - acc: 0.8514 - val_loss: 0.7755 - val_acc: 0.7433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7755 - acc: 0.7433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4105 - acc: 0.8971 - val_loss: 0.9032 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9032 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 9ms/sample - loss: 0.4123 - acc: 0.8886 - val_loss: 0.9677 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9677 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3949 - acc: 0.9057 - val_loss: 1.0586 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0586 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3946 - acc: 0.9014 - val_loss: 0.9744 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9744 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3860 - acc: 0.9043 - val_loss: 1.2067 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2067 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4653 - acc: 0.8643 - val_loss: 0.8365 - val_acc: 0.7433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8365 - acc: 0.7433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4111 - acc: 0.8971 - val_loss: 0.8223 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8223 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4093 - acc: 0.9043 - val_loss: 0.9199 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9199 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4486 - acc: 0.8471 - val_loss: 1.0149 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0149 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4428 - acc: 0.8443 - val_loss: 0.8472 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8472 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4298 - acc: 0.8600 - val_loss: 0.9831 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9831 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4225 - acc: 0.8729 - val_loss: 0.8712 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8712 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3837 - acc: 0.9071 - val_loss: 1.0436 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0436 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3728 - acc: 0.9171 - val_loss: 0.9572 - val_acc: 0.7233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9572 - acc: 0.7233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3743 - acc: 0.9200 - val_loss: 0.9692 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9692 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3749 - acc: 0.9114 - val_loss: 0.9562 - val_acc: 0.7400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9562 - acc: 0.7400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3649 - acc: 0.9214 - val_loss: 1.0646 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0646 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3668 - acc: 0.9157 - val_loss: 0.9835 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9835 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3570 - acc: 0.9314 - val_loss: 0.9557 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9557 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3622 - acc: 0.9157 - val_loss: 1.0087 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0087 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3907 - acc: 0.8943 - val_loss: 0.9220 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9220 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3876 - acc: 0.8914 - val_loss: 0.8453 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8453 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3690 - acc: 0.9100 - val_loss: 0.9201 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9201 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3668 - acc: 0.9143 - val_loss: 0.8968 - val_acc: 0.7267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8968 - acc: 0.7267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3459 - acc: 0.9329 - val_loss: 0.9898 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9898 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3447 - acc: 0.9357 - val_loss: 1.1888 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1888 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3497 - acc: 0.9257 - val_loss: 1.3127 - val_acc: 0.7333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3127 - acc: 0.7333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3515 - acc: 0.9214 - val_loss: 1.0328 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0328 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3376 - acc: 0.9357 - val_loss: 1.1487 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1487 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3451 - acc: 0.9314 - val_loss: 0.9136 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9136 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3757 - acc: 0.8971 - val_loss: 0.9121 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9121 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3609 - acc: 0.9129 - val_loss: 0.8934 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8934 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3602 - acc: 0.9157 - val_loss: 0.9123 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9123 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3549 - acc: 0.9057 - val_loss: 0.8637 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8637 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3352 - acc: 0.9357 - val_loss: 0.9434 - val_acc: 0.7233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9434 - acc: 0.7233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3421 - acc: 0.9286 - val_loss: 1.1331 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1331 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3636 - acc: 0.9086 - val_loss: 0.8810 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8810 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.3530 - acc: 0.9129 - val_loss: 0.8229 - val_acc: 0.7200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8229 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 9ms/sample - loss: 0.4058 - acc: 0.8529 - val_loss: 0.9946 - val_acc: 0.7400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9946 - acc: 0.7400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3294 - acc: 0.9386 - val_loss: 1.0590 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0590 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3402 - acc: 0.9271 - val_loss: 0.8455 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8455 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3655 - acc: 0.9000 - val_loss: 0.8801 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8801 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3557 - acc: 0.9086 - val_loss: 0.8544 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8544 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3548 - acc: 0.9014 - val_loss: 0.8443 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8443 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3566 - acc: 0.8986 - val_loss: 0.9908 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9908 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3512 - acc: 0.9043 - val_loss: 0.9332 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9332 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3528 - acc: 0.9214 - val_loss: 0.8413 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8413 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3477 - acc: 0.9129 - val_loss: 0.9911 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9911 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3291 - acc: 0.9257 - val_loss: 1.0328 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0328 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3291 - acc: 0.9271 - val_loss: 0.9299 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9299 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3233 - acc: 0.9329 - val_loss: 0.9481 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9481 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3335 - acc: 0.9329 - val_loss: 0.9210 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9210 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3422 - acc: 0.9186 - val_loss: 1.0157 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0157 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3207 - acc: 0.9343 - val_loss: 1.1155 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1155 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3162 - acc: 0.9386 - val_loss: 1.0158 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0158 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3080 - acc: 0.9457 - val_loss: 0.8890 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8890 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3280 - acc: 0.9229 - val_loss: 0.9392 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9392 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3418 - acc: 0.9143 - val_loss: 1.0894 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0894 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3219 - acc: 0.9300 - val_loss: 0.8834 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8834 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3297 - acc: 0.9300 - val_loss: 0.9909 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9909 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3628 - acc: 0.8857 - val_loss: 0.7853 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7853 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3238 - acc: 0.9271 - val_loss: 0.9458 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9458 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3043 - acc: 0.9429 - val_loss: 0.8461 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8461 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3055 - acc: 0.9400 - val_loss: 0.8428 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8428 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2929 - acc: 0.9486 - val_loss: 1.0657 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0657 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2888 - acc: 0.9543 - val_loss: 1.0605 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0605 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2833 - acc: 0.9586 - val_loss: 1.1897 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1897 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2811 - acc: 0.9543 - val_loss: 1.0722 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0722 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2759 - acc: 0.9600 - val_loss: 1.0694 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0694 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2805 - acc: 0.9557 - val_loss: 1.1149 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1149 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3189 - acc: 0.9157 - val_loss: 0.8298 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8298 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5813 - acc: 0.7871 - val_loss: 0.7438 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7438 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3437 - acc: 0.9014 - val_loss: 0.9518 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9518 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2835 - acc: 0.9586 - val_loss: 0.9601 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9601 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3605 - acc: 0.8757 - val_loss: 0.8163 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8163 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4147 - acc: 0.8300 - val_loss: 1.0484 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0484 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3024 - acc: 0.9329 - val_loss: 0.7903 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7903 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3180 - acc: 0.9186 - val_loss: 0.9657 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9657 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2723 - acc: 0.9557 - val_loss: 0.8793 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8793 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3867 - acc: 0.9214 - val_loss: 0.7911 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7911 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2649 - acc: 0.9629 - val_loss: 0.9555 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9555 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2582 - acc: 0.9686 - val_loss: 1.2116 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2116 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2628 - acc: 0.9671 - val_loss: 1.1238 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1238 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2549 - acc: 0.9729 - val_loss: 1.2170 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2170 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2665 - acc: 0.9586 - val_loss: 1.1808 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1808 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2486 - acc: 0.9714 - val_loss: 1.0811 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0811 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2465 - acc: 0.9757 - val_loss: 1.2447 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2447 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2438 - acc: 0.9786 - val_loss: 1.1260 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1260 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2766 - acc: 0.9486 - val_loss: 0.7683 - val_acc: 0.7433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7683 - acc: 0.7433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2976 - acc: 0.9414 - val_loss: 1.0840 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0840 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2605 - acc: 0.9657 - val_loss: 1.1180 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1180 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4003 - acc: 0.8371 - val_loss: 0.7970 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7970 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2738 - acc: 0.9500 - val_loss: 0.9224 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9224 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2466 - acc: 0.9714 - val_loss: 1.0085 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0085 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2398 - acc: 0.9743 - val_loss: 1.1532 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1532 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2473 - acc: 0.9671 - val_loss: 0.7930 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7930 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2582 - acc: 0.9600 - val_loss: 1.2059 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2059 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2331 - acc: 0.9814 - val_loss: 1.1716 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1716 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2461 - acc: 0.9671 - val_loss: 1.0204 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0204 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2399 - acc: 0.9743 - val_loss: 1.1295 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1295 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2320 - acc: 0.9771 - val_loss: 1.1605 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1605 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2258 - acc: 0.9829 - val_loss: 1.0448 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0448 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2670 - acc: 0.9500 - val_loss: 1.1505 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1505 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2293 - acc: 0.9786 - val_loss: 1.4666 - val_acc: 0.5900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4666 - acc: 0.5900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2373 - acc: 0.9786 - val_loss: 1.0100 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0100 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2301 - acc: 0.9714 - val_loss: 1.2138 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2138 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2218 - acc: 0.9814 - val_loss: 1.2131 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2131 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2234 - acc: 0.9800 - val_loss: 1.2208 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2208 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2141 - acc: 0.9857 - val_loss: 1.1875 - val_acc: 0.6333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1875 - acc: 0.6333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2119 - acc: 0.9871 - val_loss: 1.2092 - val_acc: 0.6333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2092 - acc: 0.6333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2127 - acc: 0.9857 - val_loss: 1.2377 - val_acc: 0.6333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2377 - acc: 0.6333\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2105 - acc: 0.9857 - val_loss: 1.4691 - val_acc: 0.5800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4691 - acc: 0.5800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2097 - acc: 0.9871 - val_loss: 1.4007 - val_acc: 0.6100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4007 - acc: 0.6100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2164 - acc: 0.9800 - val_loss: 1.2764 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2764 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2048 - acc: 0.9900 - val_loss: 1.3417 - val_acc: 0.6200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3417 - acc: 0.6200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2038 - acc: 0.9900 - val_loss: 1.4583 - val_acc: 0.5867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4583 - acc: 0.5867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2259 - acc: 0.9757 - val_loss: 1.3316 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3316 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2406 - acc: 0.9614 - val_loss: 0.8391 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8391 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2436 - acc: 0.9571 - val_loss: 1.1844 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1844 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2048 - acc: 0.9871 - val_loss: 1.2726 - val_acc: 0.6333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2726 - acc: 0.6333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1983 - acc: 0.9900 - val_loss: 1.3436 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3436 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1983 - acc: 0.9914 - val_loss: 1.2057 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2057 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1964 - acc: 0.9914 - val_loss: 1.3112 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3112 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1931 - acc: 0.9914 - val_loss: 1.3594 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3594 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2006 - acc: 0.9871 - val_loss: 1.2223 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2223 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2359 - acc: 0.9571 - val_loss: 1.3836 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3836 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1900 - acc: 0.9943 - val_loss: 1.4238 - val_acc: 0.6267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4238 - acc: 0.6267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1943 - acc: 0.9900 - val_loss: 1.2944 - val_acc: 0.6233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2944 - acc: 0.6233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2210 - acc: 0.9643 - val_loss: 1.2687 - val_acc: 0.6300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2687 - acc: 0.6300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1863 - acc: 0.9943 - val_loss: 1.3697 - val_acc: 0.6167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3697 - acc: 0.6167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2128 - acc: 0.9757 - val_loss: 1.4326 - val_acc: 0.6100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4326 - acc: 0.6100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2317 - acc: 0.9586 - val_loss: 1.2550 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2550 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1855 - acc: 0.9900 - val_loss: 1.2099 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2099 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1974 - acc: 0.9814 - val_loss: 1.4004 - val_acc: 0.6333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4004 - acc: 0.6333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1847 - acc: 0.9914 - val_loss: 1.3917 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3917 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1784 - acc: 0.9971 - val_loss: 1.6303 - val_acc: 0.5767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6303 - acc: 0.5767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1829 - acc: 0.9929 - val_loss: 1.8491 - val_acc: 0.5333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8491 - acc: 0.5333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4163 - acc: 0.8129 - val_loss: 0.9245 - val_acc: 0.7433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9245 - acc: 0.7433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2511 - acc: 0.9457 - val_loss: 1.3765 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3765 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1938 - acc: 0.9886 - val_loss: 1.5201 - val_acc: 0.6200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5201 - acc: 0.6200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1939 - acc: 0.9843 - val_loss: 1.3930 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3930 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1919 - acc: 0.9843 - val_loss: 1.4950 - val_acc: 0.6200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4950 - acc: 0.6200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1765 - acc: 0.9929 - val_loss: 1.5289 - val_acc: 0.6133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5289 - acc: 0.6133\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1769 - acc: 0.9929 - val_loss: 1.6248 - val_acc: 0.6033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6248 - acc: 0.6033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1708 - acc: 0.9971 - val_loss: 1.5053 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5053 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1687 - acc: 0.9971 - val_loss: 1.5770 - val_acc: 0.6167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5770 - acc: 0.6167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1717 - acc: 0.9957 - val_loss: 1.2557 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2557 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1688 - acc: 0.9957 - val_loss: 1.4629 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4629 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1661 - acc: 0.9971 - val_loss: 1.5136 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5136 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1648 - acc: 0.9971 - val_loss: 1.5228 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5228 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1640 - acc: 0.9971 - val_loss: 1.4837 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4837 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1630 - acc: 0.9971 - val_loss: 1.5615 - val_acc: 0.6300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5615 - acc: 0.6300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1621 - acc: 0.9971 - val_loss: 1.5137 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5137 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1611 - acc: 0.9971 - val_loss: 1.5112 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5112 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1603 - acc: 0.9971 - val_loss: 1.5168 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5168 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1594 - acc: 0.9971 - val_loss: 1.5662 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5662 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1586 - acc: 0.9971 - val_loss: 1.5670 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5670 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1577 - acc: 0.9971 - val_loss: 1.5447 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5447 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1568 - acc: 0.9971 - val_loss: 1.6082 - val_acc: 0.6267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6082 - acc: 0.6267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1561 - acc: 0.9971 - val_loss: 1.5727 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5727 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1553 - acc: 0.9971 - val_loss: 1.5955 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5955 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1545 - acc: 0.9971 - val_loss: 1.5414 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5414 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1537 - acc: 0.9971 - val_loss: 1.5639 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5639 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1529 - acc: 0.9971 - val_loss: 1.5488 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5488 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1521 - acc: 0.9971 - val_loss: 1.5525 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5525 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1514 - acc: 0.9971 - val_loss: 1.5512 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5512 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1506 - acc: 0.9971 - val_loss: 1.5518 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5518 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1498 - acc: 0.9971 - val_loss: 1.5831 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5831 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1491 - acc: 0.9971 - val_loss: 1.5971 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5971 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1483 - acc: 0.9971 - val_loss: 1.5646 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5646 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1476 - acc: 0.9971 - val_loss: 1.5948 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5948 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1468 - acc: 0.9971 - val_loss: 1.5955 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5955 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1461 - acc: 0.9971 - val_loss: 1.5773 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5773 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1454 - acc: 0.9971 - val_loss: 1.5752 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5752 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1446 - acc: 0.9971 - val_loss: 1.5861 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5861 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1439 - acc: 0.9971 - val_loss: 1.5818 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5818 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1432 - acc: 0.9971 - val_loss: 1.5865 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5865 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1425 - acc: 0.9971 - val_loss: 1.5844 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5844 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1418 - acc: 0.9971 - val_loss: 1.5777 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5777 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1412 - acc: 0.9971 - val_loss: 1.5241 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5241 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1405 - acc: 0.9971 - val_loss: 1.5233 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5233 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1398 - acc: 0.9971 - val_loss: 1.5325 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5325 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1391 - acc: 0.9971 - val_loss: 1.5314 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5314 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1384 - acc: 0.9971 - val_loss: 1.5551 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5551 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1377 - acc: 0.9971 - val_loss: 1.5696 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5696 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1371 - acc: 0.9971 - val_loss: 1.5526 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5526 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1364 - acc: 0.9971 - val_loss: 1.5559 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5559 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1357 - acc: 0.9971 - val_loss: 1.5591 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5591 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1351 - acc: 0.9971 - val_loss: 1.5565 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5565 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1344 - acc: 0.9971 - val_loss: 1.5584 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5584 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1337 - acc: 0.9971 - val_loss: 1.5712 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5712 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1331 - acc: 0.9971 - val_loss: 1.5679 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5679 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1324 - acc: 0.9971 - val_loss: 1.5780 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5780 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1318 - acc: 0.9971 - val_loss: 1.5794 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5794 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1312 - acc: 0.9971 - val_loss: 1.5790 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5790 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1305 - acc: 0.9971 - val_loss: 1.5782 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5782 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1299 - acc: 0.9971 - val_loss: 1.5717 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5717 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1293 - acc: 0.9971 - val_loss: 1.5986 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5986 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1286 - acc: 0.9971 - val_loss: 1.5800 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5800 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1280 - acc: 0.9971 - val_loss: 1.6002 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6002 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1274 - acc: 0.9971 - val_loss: 1.5870 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5870 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1268 - acc: 0.9971 - val_loss: 1.5883 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5883 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1262 - acc: 0.9971 - val_loss: 1.5922 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5922 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1256 - acc: 0.9971 - val_loss: 1.5916 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5916 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1250 - acc: 0.9971 - val_loss: 1.6076 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6076 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1244 - acc: 0.9971 - val_loss: 1.5914 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5914 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1238 - acc: 0.9971 - val_loss: 1.5960 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5960 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1232 - acc: 0.9971 - val_loss: 1.5969 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5969 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1226 - acc: 0.9971 - val_loss: 1.6017 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6017 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1220 - acc: 0.9971 - val_loss: 1.5938 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5938 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1215 - acc: 0.9971 - val_loss: 1.5966 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5966 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1209 - acc: 0.9971 - val_loss: 1.6013 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6013 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1203 - acc: 0.9971 - val_loss: 1.6175 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6175 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1198 - acc: 0.9971 - val_loss: 1.6037 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6037 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1192 - acc: 0.9971 - val_loss: 1.5985 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5985 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1186 - acc: 0.9971 - val_loss: 1.6040 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6040 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1181 - acc: 0.9971 - val_loss: 1.6095 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6095 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1175 - acc: 0.9971 - val_loss: 1.5989 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5989 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1170 - acc: 0.9971 - val_loss: 1.6044 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6044 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1164 - acc: 0.9971 - val_loss: 1.6069 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6069 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1159 - acc: 0.9971 - val_loss: 1.6056 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6056 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1153 - acc: 0.9971 - val_loss: 1.6057 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6057 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1148 - acc: 0.9971 - val_loss: 1.6091 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6091 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1143 - acc: 0.9971 - val_loss: 1.6168 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6168 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1137 - acc: 0.9971 - val_loss: 1.6181 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6181 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1132 - acc: 0.9971 - val_loss: 1.6055 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6055 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1127 - acc: 0.9971 - val_loss: 1.6127 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6127 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1122 - acc: 0.9971 - val_loss: 1.6089 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6089 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1116 - acc: 0.9971 - val_loss: 1.6056 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6056 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1111 - acc: 0.9971 - val_loss: 1.6060 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6060 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1106 - acc: 0.9971 - val_loss: 1.6057 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6057 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1101 - acc: 0.9971 - val_loss: 1.6161 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6161 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1096 - acc: 0.9971 - val_loss: 1.6077 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6077 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1091 - acc: 0.9971 - val_loss: 1.6105 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6105 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1086 - acc: 0.9971 - val_loss: 1.6253 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6253 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1081 - acc: 0.9971 - val_loss: 1.6135 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6135 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1078 - acc: 0.9971 - val_loss: 1.6085 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6085 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1071 - acc: 0.9971 - val_loss: 1.6080 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6080 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1066 - acc: 0.9971 - val_loss: 1.6076 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6076 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1061 - acc: 0.9971 - val_loss: 1.6075 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6075 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1056 - acc: 0.9971 - val_loss: 1.6047 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6047 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1052 - acc: 0.9971 - val_loss: 1.6109 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6109 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1047 - acc: 0.9971 - val_loss: 1.6091 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6091 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1042 - acc: 0.9971 - val_loss: 1.6213 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6213 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1038 - acc: 0.9971 - val_loss: 1.5989 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5989 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1033 - acc: 0.9971 - val_loss: 1.6065 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6065 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1028 - acc: 0.9971 - val_loss: 1.6075 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6075 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1023 - acc: 0.9971 - val_loss: 1.6100 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6100 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1019 - acc: 0.9971 - val_loss: 1.6061 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6061 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1014 - acc: 0.9971 - val_loss: 1.6070 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6070 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1010 - acc: 0.9971 - val_loss: 1.6091 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6091 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1005 - acc: 0.9971 - val_loss: 1.6090 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6090 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1001 - acc: 0.9971 - val_loss: 1.6044 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6044 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0996 - acc: 0.9971 - val_loss: 1.6048 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6048 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0992 - acc: 0.9971 - val_loss: 1.6084 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6084 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0987 - acc: 0.9971 - val_loss: 1.6042 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6042 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0983 - acc: 0.9971 - val_loss: 1.6038 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6038 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0979 - acc: 0.9971 - val_loss: 1.6130 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6130 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0974 - acc: 0.9971 - val_loss: 1.6086 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6086 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0970 - acc: 0.9971 - val_loss: 1.6210 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6210 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0966 - acc: 0.9971 - val_loss: 1.6110 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6110 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0961 - acc: 0.9971 - val_loss: 1.6230 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6230 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0957 - acc: 0.9971 - val_loss: 1.6220 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6220 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0953 - acc: 0.9971 - val_loss: 1.5934 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5934 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0949 - acc: 0.9971 - val_loss: 1.5959 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5959 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0945 - acc: 0.9971 - val_loss: 1.6036 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6036 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0941 - acc: 0.9971 - val_loss: 1.5987 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5987 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0936 - acc: 0.9971 - val_loss: 1.5957 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5957 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0932 - acc: 0.9971 - val_loss: 1.5976 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5976 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0928 - acc: 0.9971 - val_loss: 1.5963 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5963 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0924 - acc: 0.9971 - val_loss: 1.5982 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5982 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0920 - acc: 0.9971 - val_loss: 1.5982 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5982 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0916 - acc: 0.9971 - val_loss: 1.6016 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6016 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0912 - acc: 0.9971 - val_loss: 1.5901 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5901 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0908 - acc: 0.9971 - val_loss: 1.6082 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6082 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0904 - acc: 0.9971 - val_loss: 1.5971 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5971 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0900 - acc: 0.9971 - val_loss: 1.5998 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5998 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0896 - acc: 0.9971 - val_loss: 1.5978 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5978 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0893 - acc: 0.9971 - val_loss: 1.6023 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6023 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0889 - acc: 0.9971 - val_loss: 1.6093 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6093 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0885 - acc: 0.9971 - val_loss: 1.6030 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6030 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0881 - acc: 0.9971 - val_loss: 1.5992 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5992 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0877 - acc: 0.9971 - val_loss: 1.6021 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6021 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0874 - acc: 0.9971 - val_loss: 1.6069 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6069 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0870 - acc: 0.9971 - val_loss: 1.6047 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6047 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0866 - acc: 0.9971 - val_loss: 1.6076 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6076 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0863 - acc: 0.9971 - val_loss: 1.6048 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6048 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0859 - acc: 0.9971 - val_loss: 1.6079 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6079 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0855 - acc: 0.9971 - val_loss: 1.6051 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6051 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0852 - acc: 0.9971 - val_loss: 1.6063 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6063 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0848 - acc: 0.9971 - val_loss: 1.6082 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6082 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0845 - acc: 0.9971 - val_loss: 1.6059 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6059 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0841 - acc: 0.9971 - val_loss: 1.6082 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6082 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0837 - acc: 0.9971 - val_loss: 1.6124 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6124 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0834 - acc: 0.9971 - val_loss: 1.6074 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6074 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0831 - acc: 0.9971 - val_loss: 1.6048 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6048 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0827 - acc: 0.9971 - val_loss: 1.6037 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6037 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0824 - acc: 0.9971 - val_loss: 1.6083 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6083 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0820 - acc: 0.9971 - val_loss: 1.6051 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6051 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0817 - acc: 0.9971 - val_loss: 1.6065 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6065 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0813 - acc: 0.9971 - val_loss: 1.6065 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6065 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0810 - acc: 0.9971 - val_loss: 1.6065 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6065 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0807 - acc: 0.9971 - val_loss: 1.6063 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6063 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0803 - acc: 0.9971 - val_loss: 1.6134 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6134 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0800 - acc: 0.9971 - val_loss: 1.6095 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6095 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0797 - acc: 0.9971 - val_loss: 1.6058 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6058 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0793 - acc: 0.9971 - val_loss: 1.6113 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6113 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0790 - acc: 0.9971 - val_loss: 1.6763 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6763 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0788 - acc: 0.9971 - val_loss: 1.6124 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6124 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0785 - acc: 0.9971 - val_loss: 1.6021 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6021 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1357 - acc: 0.9700 - val_loss: 1.1943 - val_acc: 0.7333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1943 - acc: 0.7333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4603 - acc: 0.8314 - val_loss: 0.8749 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8749 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4098 - acc: 0.8271 - val_loss: 0.8336 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8336 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3618 - acc: 0.8429 - val_loss: 0.8366 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8366 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3545 - acc: 0.8571 - val_loss: 0.8671 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8671 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3957 - acc: 0.8200 - val_loss: 0.8825 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8825 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4543 - acc: 0.8057 - val_loss: 0.8819 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8819 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3769 - acc: 0.8300 - val_loss: 1.0265 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0265 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3657 - acc: 0.8414 - val_loss: 0.9787 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9787 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3468 - acc: 0.8586 - val_loss: 1.0265 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0265 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3255 - acc: 0.8886 - val_loss: 1.0610 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0610 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3385 - acc: 0.8657 - val_loss: 1.1845 - val_acc: 0.7233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1845 - acc: 0.7233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2184 - acc: 0.9357 - val_loss: 1.0529 - val_acc: 0.7367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0529 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2298 - acc: 0.9286 - val_loss: 0.9980 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9980 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2881 - acc: 0.8871 - val_loss: 0.8865 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8865 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3483 - acc: 0.8457 - val_loss: 1.0937 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0937 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3228 - acc: 0.8729 - val_loss: 1.0506 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0506 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2743 - acc: 0.9171 - val_loss: 0.9740 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9740 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2523 - acc: 0.9214 - val_loss: 1.0937 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0937 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2921 - acc: 0.8943 - val_loss: 1.1571 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1571 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3367 - acc: 0.8657 - val_loss: 1.0230 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0230 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3650 - acc: 0.8300 - val_loss: 1.0306 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0306 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3964 - acc: 0.8171 - val_loss: 1.1589 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1589 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3789 - acc: 0.8371 - val_loss: 1.4285 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4285 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3662 - acc: 0.8386 - val_loss: 1.2764 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2764 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3502 - acc: 0.8557 - val_loss: 1.1901 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1901 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3232 - acc: 0.8614 - val_loss: 1.2088 - val_acc: 0.7200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2088 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3135 - acc: 0.8743 - val_loss: 1.0326 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0326 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2833 - acc: 0.8871 - val_loss: 1.1298 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1298 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2801 - acc: 0.8886 - val_loss: 0.7829 - val_acc: 0.6233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7829 - acc: 0.6233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3751 - acc: 0.8171 - val_loss: 1.0640 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0640 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2959 - acc: 0.8843 - val_loss: 1.0866 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0866 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2567 - acc: 0.9000 - val_loss: 1.2931 - val_acc: 0.7267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2931 - acc: 0.7267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2735 - acc: 0.8971 - val_loss: 1.1192 - val_acc: 0.7233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1192 - acc: 0.7233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2644 - acc: 0.8986 - val_loss: 1.3199 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3199 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2613 - acc: 0.9014 - val_loss: 1.1126 - val_acc: 0.7400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1126 - acc: 0.7400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2160 - acc: 0.9271 - val_loss: 1.3793 - val_acc: 0.7267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3793 - acc: 0.7267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2780 - acc: 0.9129 - val_loss: 2.4259 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.4259 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3199 - acc: 0.9000 - val_loss: 1.1969 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1969 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3021 - acc: 0.8914 - val_loss: 1.7792 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7792 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4883 - acc: 0.8114 - val_loss: 1.8514 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8514 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3851 - acc: 0.8400 - val_loss: 1.2596 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2596 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3019 - acc: 0.9100 - val_loss: 2.1594 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.1594 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3269 - acc: 0.8871 - val_loss: 1.2774 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2774 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2848 - acc: 0.9129 - val_loss: 1.2929 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2929 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4081 - acc: 0.8686 - val_loss: 1.9026 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.9026 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3225 - acc: 0.9057 - val_loss: 1.1355 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1355 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2938 - acc: 0.9071 - val_loss: 1.2084 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2084 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2325 - acc: 0.9300 - val_loss: 1.5027 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5027 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4650 - acc: 0.7729 - val_loss: 1.1855 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1855 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2679 - acc: 0.9157 - val_loss: 1.4889 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4889 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2747 - acc: 0.9314 - val_loss: 2.0227 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.0227 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1895 - acc: 0.9543 - val_loss: 1.8115 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8115 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1937 - acc: 0.9400 - val_loss: 1.8567 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8567 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1557 - acc: 0.9686 - val_loss: 2.0007 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.0007 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2524 - acc: 0.9329 - val_loss: 2.3432 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.3432 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1923 - acc: 0.9486 - val_loss: 2.0556 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.0556 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2495 - acc: 0.9229 - val_loss: 1.9293 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.9293 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2694 - acc: 0.9386 - val_loss: 0.8956 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8956 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4288 - acc: 0.8100 - val_loss: 0.8966 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8966 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2813 - acc: 0.8971 - val_loss: 1.0659 - val_acc: 0.7400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0659 - acc: 0.7400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3108 - acc: 0.8900 - val_loss: 1.1412 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1412 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2117 - acc: 0.9329 - val_loss: 1.5116 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5116 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2387 - acc: 0.9243 - val_loss: 0.9618 - val_acc: 0.7400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9618 - acc: 0.7400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5142 - acc: 0.8043 - val_loss: 0.9164 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9164 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3305 - acc: 0.8714 - val_loss: 0.9647 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9647 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3366 - acc: 0.8586 - val_loss: 1.0594 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0594 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2597 - acc: 0.9100 - val_loss: 1.1204 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1204 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1898 - acc: 0.9529 - val_loss: 1.2674 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2674 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 1.3861 - acc: 0.8629 - val_loss: 0.9915 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9915 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4222 - acc: 0.7943 - val_loss: 1.6295 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6295 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1802 - acc: 0.9543 - val_loss: 2.0511 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.0511 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1553 - acc: 0.9700 - val_loss: 2.5688 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.5688 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1287 - acc: 0.9786 - val_loss: 2.2620 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.2620 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1174 - acc: 0.9829 - val_loss: 2.2953 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.2953 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1031 - acc: 0.9843 - val_loss: 2.4461 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.4461 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1771 - acc: 0.9471 - val_loss: 2.3897 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.3897 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2045 - acc: 0.9314 - val_loss: 0.9537 - val_acc: 0.6000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9537 - acc: 0.6000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.6440 - acc: 0.6371 - val_loss: 0.8152 - val_acc: 0.6300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8152 - acc: 0.6300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5912 - acc: 0.6586 - val_loss: 0.8188 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8188 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5361 - acc: 0.7171 - val_loss: 0.9237 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9237 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4804 - acc: 0.7700 - val_loss: 0.8649 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8649 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5794 - acc: 0.6886 - val_loss: 0.8235 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8235 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5683 - acc: 0.6757 - val_loss: 0.8473 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8473 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4841 - acc: 0.7629 - val_loss: 0.9259 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9259 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5181 - acc: 0.7729 - val_loss: 0.8841 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8841 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 1.7549 - acc: 0.7229 - val_loss: 1.1948 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1948 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4494 - acc: 0.7857 - val_loss: 1.5004 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5004 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3768 - acc: 0.8443 - val_loss: 2.0122 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.0122 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2599 - acc: 0.9100 - val_loss: 2.1786 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.1786 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4478 - acc: 0.8286 - val_loss: 1.6393 - val_acc: 0.7233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6393 - acc: 0.7233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3486 - acc: 0.8957 - val_loss: 1.4560 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4560 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3122 - acc: 0.8971 - val_loss: 1.9049 - val_acc: 0.7233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.9049 - acc: 0.7233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1859 - acc: 0.9729 - val_loss: 2.4770 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.4770 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4537 - acc: 0.8671 - val_loss: 1.7833 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7833 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1729 - acc: 0.9614 - val_loss: 2.6675 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.6675 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1495 - acc: 0.9600 - val_loss: 1.5265 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5265 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1928 - acc: 0.9371 - val_loss: 2.8155 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8155 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0983 - acc: 0.9914 - val_loss: 2.2371 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.2371 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1043 - acc: 0.9857 - val_loss: 2.5182 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.5182 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0978 - acc: 0.9871 - val_loss: 2.2305 - val_acc: 0.7233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.2305 - acc: 0.7233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1008 - acc: 0.9843 - val_loss: 2.5490 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.5490 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0814 - acc: 0.9914 - val_loss: 2.6148 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.6148 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1302 - acc: 0.9686 - val_loss: 2.7440 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7440 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2922 - acc: 0.8871 - val_loss: 2.4832 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.4832 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1043 - acc: 0.9800 - val_loss: 2.6746 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.6746 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0897 - acc: 0.9871 - val_loss: 2.7102 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7102 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0859 - acc: 0.9900 - val_loss: 2.5908 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.5908 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0778 - acc: 0.9929 - val_loss: 2.8174 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8174 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0810 - acc: 0.9914 - val_loss: 2.5611 - val_acc: 0.7200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.5611 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1180 - acc: 0.9743 - val_loss: 2.7426 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7426 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0802 - acc: 0.9914 - val_loss: 2.7569 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7569 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0720 - acc: 0.9943 - val_loss: 2.7608 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7608 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0787 - acc: 0.9914 - val_loss: 2.6168 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.6168 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0742 - acc: 0.9929 - val_loss: 2.7103 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7103 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0772 - acc: 0.9914 - val_loss: 2.7139 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7139 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0687 - acc: 0.9971 - val_loss: 2.7615 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7615 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0715 - acc: 0.9957 - val_loss: 2.6973 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.6973 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0737 - acc: 0.9929 - val_loss: 2.9626 - val_acc: 0.6233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.9626 - acc: 0.6233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0794 - acc: 0.9943 - val_loss: 2.8901 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8901 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1490 - acc: 0.9571 - val_loss: 2.8187 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8187 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0788 - acc: 0.9914 - val_loss: 2.7863 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7863 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0751 - acc: 0.9914 - val_loss: 2.8265 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8265 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0691 - acc: 0.9957 - val_loss: 3.0010 - val_acc: 0.6200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.0010 - acc: 0.6200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0682 - acc: 0.9943 - val_loss: 2.9132 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.9132 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0652 - acc: 0.9943 - val_loss: 2.8677 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8677 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1047 - acc: 0.9771 - val_loss: 2.8081 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8081 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0628 - acc: 0.9943 - val_loss: 2.8573 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8573 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0614 - acc: 0.9971 - val_loss: 2.8991 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8991 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0612 - acc: 0.9971 - val_loss: 2.7776 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.7776 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0607 - acc: 0.9971 - val_loss: 2.8842 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8842 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0797 - acc: 0.9843 - val_loss: 1.3665 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3665 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5471 - acc: 0.7786 - val_loss: 1.2352 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2352 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4293 - acc: 0.7900 - val_loss: 1.7093 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7093 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3699 - acc: 0.8486 - val_loss: 1.9330 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.9330 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3342 - acc: 0.8829 - val_loss: 2.0906 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.0906 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2611 - acc: 0.9129 - val_loss: 1.8118 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8118 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2789 - acc: 0.9129 - val_loss: 1.9754 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.9754 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2028 - acc: 0.9543 - val_loss: 2.9316 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.9316 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1521 - acc: 0.9643 - val_loss: 2.8086 - val_acc: 0.7267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8086 - acc: 0.7267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2867 - acc: 0.9371 - val_loss: 2.0377 - val_acc: 0.7233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.0377 - acc: 0.7233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1836 - acc: 0.9471 - val_loss: 2.3799 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.3799 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1485 - acc: 0.9686 - val_loss: 2.3372 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.3372 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1068 - acc: 0.9800 - val_loss: 3.6952 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.6952 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0816 - acc: 0.9914 - val_loss: 3.2684 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.2684 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3341 - acc: 0.8586 - val_loss: 1.5113 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5113 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2426 - acc: 0.9086 - val_loss: 2.9827 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.9827 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0987 - acc: 0.9843 - val_loss: 3.1871 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.1871 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0712 - acc: 0.9929 - val_loss: 3.2084 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.2084 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0607 - acc: 0.9971 - val_loss: 3.3522 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3522 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0589 - acc: 0.9971 - val_loss: 3.3180 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3180 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0570 - acc: 0.9986 - val_loss: 3.3321 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3321 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0563 - acc: 0.9986 - val_loss: 3.3086 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3086 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1487 - acc: 0.9586 - val_loss: 3.0052 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.0052 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0700 - acc: 0.9900 - val_loss: 3.4117 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.4117 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0673 - acc: 0.9957 - val_loss: 3.2143 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.2143 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0571 - acc: 0.9971 - val_loss: 3.3975 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3975 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0560 - acc: 0.9986 - val_loss: 3.3584 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3584 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0545 - acc: 0.9971 - val_loss: 3.3734 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3734 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0534 - acc: 0.9986 - val_loss: 3.4349 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.4349 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0550 - acc: 0.9971 - val_loss: 3.4428 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.4428 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0756 - acc: 0.9900 - val_loss: 3.4950 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.4950 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0632 - acc: 0.9929 - val_loss: 1.8362 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8362 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1401 - acc: 0.9614 - val_loss: 3.4837 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.4837 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0668 - acc: 0.9929 - val_loss: 3.1967 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.1967 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0550 - acc: 0.9971 - val_loss: 3.3546 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3546 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0537 - acc: 0.9986 - val_loss: 3.4234 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.4234 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0557 - acc: 0.9971 - val_loss: 3.5139 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.5139 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0543 - acc: 0.9971 - val_loss: 3.4394 - val_acc: 0.6200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.4394 - acc: 0.6200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0525 - acc: 0.9986 - val_loss: 3.3403 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3403 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0492 - acc: 0.9986 - val_loss: 3.3402 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.3402 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5610 - acc: 0.7971 - val_loss: 1.1553 - val_acc: 0.5433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1553 - acc: 0.5433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 4.8307 - acc: 0.5957 - val_loss: 0.6607 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6607 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5297 - acc: 0.7186 - val_loss: 0.6577 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6577 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4759 - acc: 0.7643 - val_loss: 0.7717 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7717 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4101 - acc: 0.8129 - val_loss: 0.8242 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8242 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3940 - acc: 0.8243 - val_loss: 0.9051 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9051 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3676 - acc: 0.8457 - val_loss: 0.7711 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7711 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3235 - acc: 0.8729 - val_loss: 0.9850 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9850 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.6203 - acc: 0.6586 - val_loss: 0.6634 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6634 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5742 - acc: 0.6714 - val_loss: 0.6574 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6574 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5218 - acc: 0.7286 - val_loss: 0.7220 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7220 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2649 - acc: 0.9057 - val_loss: 0.9361 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9361 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2502 - acc: 0.9043 - val_loss: 1.1948 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1948 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1526 - acc: 0.9771 - val_loss: 1.5858 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5858 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1056 - acc: 0.9814 - val_loss: 2.8432 - val_acc: 0.6300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8432 - acc: 0.6300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.6363 - acc: 0.6586 - val_loss: 0.7072 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7072 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5876 - acc: 0.6586 - val_loss: 0.8520 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8520 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5976 - acc: 0.6729 - val_loss: 0.6690 - val_acc: 0.6067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6690 - acc: 0.6067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.6105 - acc: 0.6371 - val_loss: 0.6685 - val_acc: 0.6067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6685 - acc: 0.6067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.6024 - acc: 0.6429 - val_loss: 0.6717 - val_acc: 0.6067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6717 - acc: 0.6067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5881 - acc: 0.6586 - val_loss: 0.6757 - val_acc: 0.6267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6757 - acc: 0.6267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5586 - acc: 0.6929 - val_loss: 0.7080 - val_acc: 0.6267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7080 - acc: 0.6267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4376 - acc: 0.8029 - val_loss: 0.7240 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7240 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.4025 - acc: 0.8171 - val_loss: 0.8232 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8232 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3769 - acc: 0.8357 - val_loss: 0.7978 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7978 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 1.7634 - acc: 0.6971 - val_loss: 0.6968 - val_acc: 0.6133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6968 - acc: 0.6133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.5439 - acc: 0.7029 - val_loss: 0.7382 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7382 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2895 - acc: 0.8757 - val_loss: 1.6192 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6192 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0855 - acc: 0.9886 - val_loss: 1.5929 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5929 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0775 - acc: 0.9929 - val_loss: 1.4116 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4116 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1185 - acc: 0.9886 - val_loss: 1.6928 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6928 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0545 - acc: 0.9971 - val_loss: 1.5792 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5792 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0536 - acc: 0.9971 - val_loss: 1.6717 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6717 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0529 - acc: 0.9971 - val_loss: 1.6785 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6785 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0524 - acc: 0.9971 - val_loss: 1.7018 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7018 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0520 - acc: 0.9971 - val_loss: 1.6888 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6888 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0521 - acc: 0.9971 - val_loss: 1.6038 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6038 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0511 - acc: 0.9971 - val_loss: 1.7181 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7181 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0506 - acc: 0.9971 - val_loss: 1.6560 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6560 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0516 - acc: 0.9971 - val_loss: 1.6444 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6444 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0502 - acc: 0.9971 - val_loss: 1.6637 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6637 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0511 - acc: 0.9971 - val_loss: 1.6139 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6139 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0492 - acc: 0.9971 - val_loss: 1.5619 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5619 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0554 - acc: 0.9929 - val_loss: 1.5943 - val_acc: 0.6833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5943 - acc: 0.6833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0501 - acc: 0.9957 - val_loss: 1.6892 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6892 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0476 - acc: 0.9986 - val_loss: 1.7792 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7792 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0475 - acc: 0.9986 - val_loss: 1.7501 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7501 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0468 - acc: 0.9986 - val_loss: 1.7326 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7326 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0465 - acc: 0.9986 - val_loss: 1.7720 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7720 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0462 - acc: 0.9986 - val_loss: 1.7517 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7517 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0455 - acc: 0.9986 - val_loss: 1.7275 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7275 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0451 - acc: 0.9986 - val_loss: 1.8262 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8262 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0449 - acc: 0.9986 - val_loss: 1.7415 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7415 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0445 - acc: 0.9986 - val_loss: 1.8769 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8769 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0441 - acc: 0.9986 - val_loss: 1.7821 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7821 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0442 - acc: 0.9986 - val_loss: 1.7901 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7901 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0432 - acc: 0.9986 - val_loss: 1.7690 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7690 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0435 - acc: 0.9986 - val_loss: 1.8456 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8456 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0429 - acc: 0.9986 - val_loss: 1.9598 - val_acc: 0.6167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.9598 - acc: 0.6167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2687 - acc: 0.8943 - val_loss: 1.7870 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7870 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0940 - acc: 0.9914 - val_loss: 1.4300 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4300 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1534 - acc: 0.9914 - val_loss: 1.0175 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0175 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1014 - acc: 0.9771 - val_loss: 1.2032 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2032 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.3337 - acc: 0.9857 - val_loss: 1.2191 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2191 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0559 - acc: 0.9929 - val_loss: 1.5228 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5228 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0804 - acc: 0.9829 - val_loss: 2.3470 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.3470 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.1032 - acc: 0.9700 - val_loss: 1.4891 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4891 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0715 - acc: 0.9900 - val_loss: 1.3063 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3063 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0778 - acc: 0.9871 - val_loss: 1.3772 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.3772 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0612 - acc: 0.9929 - val_loss: 1.5833 - val_acc: 0.6100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5833 - acc: 0.6100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0608 - acc: 0.9929 - val_loss: 1.6340 - val_acc: 0.6300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6340 - acc: 0.6300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0623 - acc: 0.9943 - val_loss: 1.5041 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5041 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0549 - acc: 0.9957 - val_loss: 1.5380 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5380 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0789 - acc: 0.9829 - val_loss: 1.1852 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.1852 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.2060 - acc: 0.9614 - val_loss: 1.0204 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.0204 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0712 - acc: 0.9871 - val_loss: 1.6321 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6321 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0489 - acc: 0.9957 - val_loss: 1.5770 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5770 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0527 - acc: 0.9943 - val_loss: 1.2116 - val_acc: 0.7367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2116 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0669 - acc: 0.9886 - val_loss: 1.4728 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.4728 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0440 - acc: 0.9971 - val_loss: 1.6554 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6554 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0407 - acc: 1.0000 - val_loss: 1.6843 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6843 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0396 - acc: 1.0000 - val_loss: 1.7218 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7218 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 1.7779 - val_acc: 0.6333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7779 - acc: 0.6333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0383 - acc: 1.0000 - val_loss: 1.7008 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7008 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0382 - acc: 1.0000 - val_loss: 1.7023 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7023 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0378 - acc: 1.0000 - val_loss: 1.7180 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7180 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0375 - acc: 1.0000 - val_loss: 1.7766 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7766 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0373 - acc: 1.0000 - val_loss: 1.7781 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7781 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0370 - acc: 1.0000 - val_loss: 1.7244 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7244 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 1.7437 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7437 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0365 - acc: 1.0000 - val_loss: 1.7339 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7339 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 1.7288 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7288 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0360 - acc: 1.0000 - val_loss: 1.7369 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7369 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0358 - acc: 1.0000 - val_loss: 1.7519 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7519 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 1.7308 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7308 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 1.7400 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7400 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0352 - acc: 1.0000 - val_loss: 1.7454 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7454 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0350 - acc: 1.0000 - val_loss: 1.7494 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7494 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0348 - acc: 1.0000 - val_loss: 1.7357 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7357 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 1.7404 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7404 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 1.7479 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7479 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0343 - acc: 1.0000 - val_loss: 1.7454 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7454 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 1.7370 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7370 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0340 - acc: 1.0000 - val_loss: 1.7539 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7539 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0338 - acc: 1.0000 - val_loss: 1.7562 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7562 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 1.7614 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7614 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 1.7455 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7455 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0333 - acc: 1.0000 - val_loss: 1.7477 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7477 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0332 - acc: 1.0000 - val_loss: 1.7478 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7478 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 1.7575 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7575 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0329 - acc: 1.0000 - val_loss: 1.7492 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7492 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 1.7524 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7524 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 1.7670 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7670 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 1.7531 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7531 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0323 - acc: 1.0000 - val_loss: 1.7542 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7542 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0321 - acc: 1.0000 - val_loss: 1.7557 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7557 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 1.7584 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7584 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 1.7527 - val_acc: 0.6500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7527 - acc: 0.6500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0317 - acc: 1.0000 - val_loss: 1.7559 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7559 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 1.7553 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7553 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0314 - acc: 1.0000 - val_loss: 1.7554 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7554 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 1.7676 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7676 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 1.7536 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7536 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 1.7580 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7580 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 1.7591 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7591 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 1.7584 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7584 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0306 - acc: 1.0000 - val_loss: 1.7653 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7653 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 1.7592 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7592 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 1.7591 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7591 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 1.7598 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7598 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 1.7608 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7608 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 1.7647 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7647 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0299 - acc: 1.0000 - val_loss: 1.7624 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7624 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 1.7627 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7627 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 1.7655 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7655 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 1.7629 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7629 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 1.7613 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7613 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0293 - acc: 1.0000 - val_loss: 1.7657 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7657 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 1.7675 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7675 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 1.7766 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7766 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 1.7687 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7687 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 1.7642 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7642 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 1.7656 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7656 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 1.7662 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7662 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 1.7757 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7757 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 1.7676 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7676 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 1.7668 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7668 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 1.7729 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7729 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 1.7770 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7770 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0279 - acc: 1.0000 - val_loss: 1.7669 - val_acc: 0.6600\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7669 - acc: 0.6600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 1.7704 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7704 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 1.7719 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7719 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 1.7727 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7727 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 1.7701 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7701 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 1.7695 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7695 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 1.7725 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7725 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 1.7728 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7728 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 1.7723 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7723 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 1.7764 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7764 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 1.7791 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7791 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 1.7816 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7816 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 1.7748 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7748 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 1.7775 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7775 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 1.7743 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7743 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 1.7772 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7772 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 1.7798 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7798 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0261 - acc: 1.0000 - val_loss: 1.7780 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7780 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 1.7775 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7775 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 1.7796 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7796 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 1.7813 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7813 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0257 - acc: 1.0000 - val_loss: 1.7802 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7802 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 1.7836 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7836 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 1.7784 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7784 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 1.7804 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7804 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 1.7853 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7853 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 1.7802 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7802 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 1.7869 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7869 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 1.7855 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7855 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 1.7859 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7859 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0248 - acc: 1.0000 - val_loss: 1.7890 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7890 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 1.7889 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7889 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 1.7897 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7897 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 1.7888 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7888 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 1.7950 - val_acc: 0.6800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7950 - acc: 0.6800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 1.7928 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7928 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 1.7899 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7899 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 1.7921 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7921 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 1.7885 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7885 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 1.7929 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7929 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 1.7916 - val_acc: 0.6767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7916 - acc: 0.6767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 1.7941 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7941 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 1.7939 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7939 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 1.7967 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7967 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 1.7953 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7953 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 1.7944 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7944 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 1.7935 - val_acc: 0.6733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7935 - acc: 0.6733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 1.8020 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8020 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 1.7942 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7942 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 1.7980 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7980 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 1.7996 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7996 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 1.7965 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7965 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 1.8003 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8003 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 1.8027 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8027 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 1.8023 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8023 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 1.8038 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8038 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 1.8064 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8064 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 1.8045 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8045 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 1.8050 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8050 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 1.8045 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8045 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 1.8063 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8063 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 1.8088 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8088 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 1.8057 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8057 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 1.8101 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8101 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 1.8067 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8067 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 1.8106 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8106 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 1.8079 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8079 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 1.8081 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8081 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 1.8114 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8114 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 1.8104 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8104 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 1.8113 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8113 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 1.8106 - val_acc: 0.6667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8106 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 5s 8ms/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 1.8116 - val_acc: 0.6633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.8116 - acc: 0.6633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "416/700 [================>.............] - ETA: 2s - loss: 0.0208 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_5192\\3377308904.py\", line 3, in <module>\n",
      "    evaluacion(modelo2,80,\"SGD\",v_eS,v_aS)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_5192\\1219012479.py\", line 6, in evaluacion\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_5192\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\contrib\\__init__.py\", line 39, in <module>\n",
      "    from tensorflow.contrib import compiler\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\contrib\\compiler\\__init__.py\", line 21, in <module>\n",
      "    from tensorflow.contrib.compiler import jit\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\contrib\\compiler\\__init__.py\", line 22, in <module>\n",
      "    from tensorflow.contrib.compiler import xla\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\contrib\\compiler\\xla.py\", line 22, in <module>\n",
      "    from tensorflow.python.estimator import model_fn as model_fn_lib\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\estimator\\model_fn.py\", line 26, in <module>\n",
      "    from tensorflow_estimator.python.estimator import model_fn\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow_estimator._api.v1 import estimator\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow_estimator._api.v1.estimator import experimental\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\experimental\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\", line 27, in <module>\n",
      "    from tensorflow_estimator.python.estimator import estimator\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 36, in <module>\n",
      "    from tensorflow.python.profiler import trace\n",
      "ImportError: cannot import name 'trace' from 'tensorflow.python.profiler' (C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\profiler\\__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_5192\\3377308904.py\", line 3, in <module>\n",
      "    evaluacion(modelo2,80,\"SGD\",v_eS,v_aS)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_5192\\1219012479.py\", line 6, in evaluacion\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_5192\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_5192\\3377308904.py\", line 3, in <module>\n",
      "    evaluacion(modelo2,80,\"SGD\",v_eS,v_aS)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_5192\\1219012479.py\", line 6, in evaluacion\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_5192\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "v_eS=[]\n",
    "v_aS=[]\n",
    "evaluacion(modelo2,80,\"SGD\",v_eS,v_aS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82faed78",
   "metadata": {},
   "source": [
    "## metodo RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ac96049",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo3=creacion_modelo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53cdd812",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_RMSprop = keras.optimizers.RMSprop(learning_rate=lr)\n",
    "modelo3.compile(optimizer=modelo_RMSprop,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91a59d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 3901.1270 - acc: 0.5286 - val_loss: 2092.6327 - val_acc: 0.4333\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 2092.6328 - acc: 0.4333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 480.5798 - acc: 0.5171 - val_loss: 114.1496 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 114.1496 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 159.0920 - acc: 0.6114 - val_loss: 29.4581 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 29.4581 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 23.9253 - acc: 0.7129 - val_loss: 4.5763 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.5763 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 1.7780 - acc: 0.7971 - val_loss: 2.0196 - val_acc: 0.7433\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 2.0196 - acc: 0.7433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 1.2118 - acc: 0.8800 - val_loss: 2.1346 - val_acc: 0.7600\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 2.1346 - acc: 0.7600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 6.0284 - acc: 0.8829 - val_loss: 12.1429 - val_acc: 0.5733\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 12.1429 - acc: 0.5733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 1.1735 - acc: 0.9214 - val_loss: 3.0056 - val_acc: 0.7533\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 3.0056 - acc: 0.7533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.8239 - acc: 0.9700 - val_loss: 15.7757 - val_acc: 0.7367\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 15.7757 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 15.9350 - acc: 0.7829 - val_loss: 2.7641 - val_acc: 0.7333\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 2.7641 - acc: 0.7333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.0725 - acc: 0.9700 - val_loss: 4.1216 - val_acc: 0.7833\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.1216 - acc: 0.7833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 4.7999 - acc: 0.9129 - val_loss: 2.9500 - val_acc: 0.7867\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 2.9500 - acc: 0.7867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 10s 15ms/sample - loss: 0.0429 - acc: 0.9900 - val_loss: 3.2594 - val_acc: 0.7833\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 3.2594 - acc: 0.7833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 18.1067 - acc: 0.9600 - val_loss: 23.4066 - val_acc: 0.7333\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 23.4066 - acc: 0.7333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 8.5100 - acc: 0.7957 - val_loss: 2.7041 - val_acc: 0.7567\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 2.7041 - acc: 0.7567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.2647 - acc: 0.9543 - val_loss: 7.0174 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 7.0174 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 1.0645 - acc: 0.9471 - val_loss: 2.5241 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 2.5241 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.0224 - acc: 0.9986 - val_loss: 3.6166 - val_acc: 0.7367\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 3.6166 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 103.4170 - acc: 0.7071 - val_loss: 7.3898 - val_acc: 0.7667\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 7.3898 - acc: 0.7667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 2.7067 - acc: 0.8914 - val_loss: 47.5608 - val_acc: 0.5833\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 47.5608 - acc: 0.5833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 17.2380 - acc: 0.8157 - val_loss: 3.6963 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 3.6963 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.3790 - acc: 0.9571 - val_loss: 4.5608 - val_acc: 0.7533\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.5608 - acc: 0.7533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 10.9273 - acc: 0.9329 - val_loss: 470.4098 - val_acc: 0.5667\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 470.4098 - acc: 0.5667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 35.2858 - acc: 0.8071 - val_loss: 5.3822 - val_acc: 0.7867\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 5.3822 - acc: 0.7867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.2020 - acc: 0.9671 - val_loss: 6.1769 - val_acc: 0.7900\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 6.1769 - acc: 0.7900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 30.6246 - acc: 0.8414 - val_loss: 7.0542 - val_acc: 0.7633\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 7.0542 - acc: 0.7633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.3908 - acc: 0.9643 - val_loss: 4.3249 - val_acc: 0.7667\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.3249 - acc: 0.7667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.3989 - acc: 0.9643 - val_loss: 3.6033 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 3.6033 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.0060 - acc: 0.9986 - val_loss: 14.0832 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 14.0832 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 56.4993 - acc: 0.7186 - val_loss: 4.8591 - val_acc: 0.7733\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.8591 - acc: 0.7733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 2.7438 - acc: 0.9171 - val_loss: 6.8309 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 6.8309 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.3404 - acc: 0.9729 - val_loss: 4.7432 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.7432 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 23.8361 - acc: 0.8486 - val_loss: 4.5873 - val_acc: 0.7767\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.5873 - acc: 0.7767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.3017 - acc: 0.9671 - val_loss: 4.4347 - val_acc: 0.7600\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.4347 - acc: 0.7600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 15.5076 - acc: 0.8557 - val_loss: 4.1125 - val_acc: 0.7367\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.1125 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.5471 - acc: 0.9571 - val_loss: 4.5807 - val_acc: 0.7467\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.5807 - acc: 0.7467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.0280 - acc: 0.9957 - val_loss: 4.4202 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.4202 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 23.8539 - acc: 0.9000 - val_loss: 146.9470 - val_acc: 0.5800\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 146.9470 - acc: 0.5800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 66.6238 - acc: 0.7129 - val_loss: 7.9026 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 7.9026 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.8617 - acc: 0.9414 - val_loss: 6.8348 - val_acc: 0.7600\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 6.8348 - acc: 0.7600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 80.5682 - acc: 0.8443 - val_loss: 11.5252 - val_acc: 0.7467\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 11.5252 - acc: 0.7467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 1.9399 - acc: 0.9214 - val_loss: 7.6670 - val_acc: 0.7967\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 7.6670 - acc: 0.7967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.0917 - acc: 0.9886 - val_loss: 7.1401 - val_acc: 0.7767\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 7.1401 - acc: 0.7767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.0099 - acc: 0.9986 - val_loss: 7.2978 - val_acc: 0.7900\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 7.2978 - acc: 0.7900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 29.8572 - acc: 0.7800 - val_loss: 24.8495 - val_acc: 0.6200\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 24.8495 - acc: 0.6200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 30.6112 - acc: 0.8686 - val_loss: 17.4500 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 17.4500 - acc: 0.6400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 3.6360 - acc: 0.8729 - val_loss: 5.8919 - val_acc: 0.7633\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 5.8919 - acc: 0.7633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 15ms/sample - loss: 0.0152 - acc: 0.9943 - val_loss: 5.2579 - val_acc: 0.8000\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 5.2579 - acc: 0.8000\n",
      "==> Para el metodo RMSprop se utilizo: 48 epocas para llegar a mas del 80% de acertividad\n"
     ]
    }
   ],
   "source": [
    "v_eR=[]\n",
    "v_aR=[]\n",
    "evaluacion(modelo3,80,\"RMSprop\",v_eR,v_aR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf1301",
   "metadata": {},
   "source": [
    "## Graficas respecto a los metodos de optimizacion de RMSProp y ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80aa81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f02f88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96b6dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75.3333330154419, 76.99999809265137, 73.33333492279053, 77.66666412353516, 79.666668176651, 76.33333206176758, 79.3333351612091, 76.66666507720947, 79.666668176651, 80.0000011920929]\n"
     ]
    }
   ],
   "source": [
    "print(v_aA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f5a970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43.33333373069763, 56.333333253860474, 64.66666460037231, 70.99999785423279, 74.33333396911621, 75.99999904632568, 57.33333230018616, 75.3333330154419, 73.66666793823242, 73.33333492279053, 78.33333611488342, 78.66666913032532, 78.33333611488342, 73.33333492279053, 75.66666603088379, 71.33333086967468, 73.00000190734863, 73.66666793823242, 76.66666507720947, 58.33333134651184, 75.0, 75.3333330154419, 56.66666626930237, 78.66666913032532, 79.00000214576721, 76.33333206176758, 76.66666507720947, 75.0, 73.00000190734863, 77.33333110809326, 75.0, 75.0, 77.66666412353516, 75.99999904632568, 73.66666793823242, 74.6666669845581, 75.0, 57.999998331069946, 75.0, 75.99999904632568, 74.6666669845581, 79.666668176651, 77.66666412353516, 79.00000214576721, 62.00000047683716, 63.999998569488525, 76.33333206176758, 80.0000011920929]\n"
     ]
    }
   ],
   "source": [
    "print(v_aR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21cf329c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAACxaElEQVR4nOzdd1xTVx8G8Odms4csFUFxD1SKtW5wolhrq22te72tbdVqbW2xrcxq1S63rda66qqjfa3ifgX33gtRcCICyh6Z9/0jzTUhARIIBMjv6ycfyL03N+eEYB7OPYNhWZYFIYQQQkgNxLN0AQghhBBCyouCDCGEEEJqLAoyhBBCCKmxKMgQQgghpMaiIEMIIYSQGouCDCGEEEJqLAoyhBBCCKmxKMgQQgghpMaiIEMIIYSQGouCTA3QsGFDjBs3rtLOf//+fTAMg7Vr15br8WvXrgXDMLh//75Zy1UTBAcHIzg42OTHxcXFgWEYxMXFVdpzlKSiP29CCKlOKMhUMc2HvkQiwZMnT/T2BwcHo02bNhYoGSnJzZs3ERkZaRVBLTMzEwKBAH/++aeli1IrFRQUIDIy0qgAay6RkZFgGIa7CYVCNGzYEJ988gmysrL0jpfJZFi0aBECAgLg6OgIZ2dntG7dGh988AFu377NHaf5v4xhGBw/flzvPCzLokGDBmAYBq+//rrOPu3y8Hg81KtXD/369avS16Uqvfvuu2AYBl9++aXB/Zo/bDQ3sVgMT09PBAcHY+7cuUhPTzfb+f/44w+Dx3Tt2hUMw9TIzx8KMhYilUoxb948o45NSEjAqlWrKrlEpCQ3b95EVFSUwSBz4MABHDhwwORz9ujRA4WFhejRo4cZSmg++/fvB8Mw6Nevn6WLUisVFBQgKirKIh/YK1aswIYNG7B06VJ07NgRS5Ys0QsYADB06FB89tlnaNOmDebNm4eoqCj06NEDe/fuxenTp/WOl0gk2LRpk972+Ph4PH78GGKx2GB5+vbtiw0bNmDdunX48MMPcfXqVfTq1Qt79+6teGWrkZycHPzzzz9o2LAhNm/ejNKWN/zkk0+wYcMGrFy5EjNnzoSrqysiIiLQsmVL/O9//6vw+Uv6Wd2/fx8nT56ERCIxvYLVgMDSBbBW7du3x6pVqzBr1izUq1ev1GNL+o+AVK6ioiKIRKJSjylrf0l4PF61/E8jNjYWXbt2hbOzs6WLQgDk5+fDzs7OLOd6++234ebmBgCYNGkS3nvvPWzduhVnz55Fx44dAQDnzp3D7t27MWfOHHz11Vc6j1+6dKnBFpzQ0FBs27YNixcvhkDw8iNl06ZNCAwMREZGhsHyNGvWDKNGjeLuv/XWW2jbti0WLlyIAQMGGHyM5neSx6s5f4Pv2LEDSqUSv//+O3r16oWjR48iKCjI4LHdu3fH22+/rbPtypUr6NevH4YOHYqbN2+ibt265T5/aGgodu3ahYyMDO69AKh/Vp6enmjatCkyMzMrWOOqV3PeDbXMV199BaVSaVSrjHYfmfPnz4NhGKxbt07vOM1f07t37+a2PXnyBBMmTICnpyfEYjFat26N33//vdzlvnHjBnr16gUbGxt4e3vj22+/hUqlMnjs3r170b17d9jZ2cHBwQEDBw7EjRs3ynyOFy9e4PPPP4e/vz/s7e3h6OiIAQMG4MqVK3rHLlmyBK1bt4atrS1cXFzQoUMHvb84jHkNNE2vW7ZswTfffIP69evD1tYWixcvxjvvvAMA6NmzJ9c8q/mLWrv/yrNnzyAQCBAVFaVXzoSEBDAMg6VLl+o8X/G/zFeuXInGjRvDxsYGHTt2xLFjx/TOJZPJEB4ejsDAQDg5OcHOzg7du3fHkSNH9I7NysrCuHHj4OTkBGdnZ4wdO9bghxEAqFQq7Nu3DwMHDtTZ/scffyAwMBA2NjZwdXXFe++9h0ePHukco7kkeuHCBXTp0gU2NjZo1KgRfvnlF73nSUtLw8SJE+Hp6QmJRIJ27doZfD+rVCosWrQI/v7+kEgkcHd3R//+/XH+/HnumDVr1qBXr17w8PCAWCxGq1atsGLFCr1znT9/HiEhIXBzc+PKNmHCBIOvQ3HGvI/HjRsHe3t7PHnyBG+++Sbs7e3h7u6Ozz//HEqlEoD6r153d3cAQFRUFPdeioyM1DnHvXv3EBoaCgcHB4wcOZJ7LRYuXIjWrVtDIpHA09MTkyZNqtCHTvfu3QEA9+7d47Zpvu/atave8Xw+H3Xq1NHbPnz4cDx//hwHDx7ktslkMmzfvh0jRowwujz+/v5wc3NDcnIygJJ/J3NycgAA27Zt496Xbm5uGDVqlN7les1rmpSUhJCQENjZ2aFevXqIjo4uteUCAMaOHQs3NzfI5XK9ff369UPz5s2NqtfGjRvRt29f9OzZEy1btsTGjRuNepxGu3btsHDhQmRlZXH/f5T3/IMHD4ZYLMa2bdt0tm/atAnvvvsu+Hy+SWWrLijIWEijRo0wZswYrFq1CikpKUY/rkOHDvDz8zPYh2Hr1q1wcXFBSEgIAPUHa6dOnXDo0CFMmTIFixYtQpMmTTBx4kQsXLjQ5DKnpqaiZ8+euHz5MsLCwjB9+nSsX78eixYt0jt2w4YNGDhwIOzt7TF//nzMnj0bN2/eRLdu3crsa5KUlIS///4br7/+On766SfMnDkT165dQ1BQkM5rtWrVKnzyySdo1aoVFi5ciKioKLRv3x5nzpzhjjH1NYiJicGePXvw+eefY+7cuejXrx8++eQTAOrwuWHDBmzYsAEtW7bUe6ynpyeCgoJK/Nnw+XwuFBmyevVqTJo0CV5eXliwYAG6du2KN954Qy805OTk4LfffkNwcDDmz5+PyMhIpKenIyQkBJcvX+aOY1kWgwcPxoYNGzBq1Ch8++23ePz4McaOHWvw+c+dO4f09HSEhoZy2+bMmYMxY8agadOm+OmnnzB9+nQcPnwYPXr00AtEmZmZCA0NRWBgIBYsWABvb2989NFHOqGxsLAQwcHB2LBhA0aOHInvv/8eTk5OGDdunN77aOLEiZg+fToaNGiA+fPnIywsDBKJROfyxooVK+Dr64uvvvoKP/74Ixo0aICPP/4Yy5Yt445JS0tDv379cP/+fYSFhWHJkiUYOXKkwcskxZnyPlYqlQgJCUGdOnXwww8/ICgoCD/++CNWrlwJAHB3d+dC1ltvvcW9l4YMGcKdQ6FQICQkBB4eHvjhhx8wdOhQAOoWlJkzZ6Jr165YtGgRxo8fj40bNyIkJMTgB60xNOV3cXHhtvn6+gJQfzgqFAqjztOwYUN07twZmzdv5rbt3bsX2dnZeO+994wuT2ZmJjIzM/XCUvHfSZFIhLVr13IfvN999x3ef/997Ny5E926ddN7XyqVSvTv3x+enp5YsGABAgMDERERgYiIiFLLM3r0aDx//hz79+/X2Z6amor//e9/Oq1JJUlJScGRI0cwfPhwAOrQt337dshkMiNekZfefvtt2NjY6F3GNvX8tra2GDx4sM7P6sqVK7hx44ZJobPaYUmVWrNmDQuAPXfuHHvv3j1WIBCwn3zyCbc/KCiIbd26tc5jfH192bFjx3L3Z82axQqFQvbFixfcNqlUyjo7O7MTJkzgtk2cOJGtW7cum5GRoXO+9957j3VycmILCgpYlmXZ5ORkFgC7Zs2aUss+ffp0FgB75swZbltaWhrr5OTEAmCTk5NZlmXZ3Nxc1tnZmX3//fd1Hp+amso6OTnpbS+uqKiIVSqVOtuSk5NZsVjMRkdHc9sGDx6s91oVZ+xrcOTIERYA6+fnx23T2LZtGwuAPXLkiN75g4KC2KCgIO7+r7/+ygJgr127pnNcq1at2F69enH3Nc+nOadMJmM9PDzY9u3bs1KplDtu5cqVLACd51AoFDrHsCzLZmZmsp6enjo//7///psFwC5YsEDnsd27dzf48549ezbr6+vL3b9//z7L5/PZOXPm6Bx37do1ViAQ6GwPCgpiAbA//vgjt00qlbLt27dnPTw8WJlMxrIsyy5cuJAFwP7xxx/ccTKZjO3cuTNrb2/P5uTksCzLsv/73/9YADq/GxoqlYr7vvjPimVZNiQkhPXz8+Pu//XXX9zvnClMeR+PHTuWBaDz/mRZlg0ICGADAwO5++np6SwANiIiQu/5NOcICwvT2X7s2DEWALtx40ad7fv27TO4vbiIiAgWAJuQkMCmp6ez9+/fZ3///XfWxsaGdXd3Z/Pz87ljVSoV97P09PRkhw8fzi5btox98OCB3nm1/y9bunQp6+DgwP083nnnHbZnz54sy6r//xo4cKDOYwGwEydOZNPT09m0tDT2zJkzbO/evXXeQyX9Tmp+V9q0acMWFhZy23fv3s0CYMPDw/Ve06lTp+rUceDAgaxIJGLT09NLfN2USiXr7e3NDhs2TGf7Tz/9xDIMwyYlJZX8ov/rhx9+YG1sbLj39Z07d1gA7F9//aVznKau27ZtK/Fc7dq1Y11cXCp8/t27d7MMw7APHz5kWZZlZ86cyf2+GPr8qQmoRcaC/Pz8MHr0aKxcuRJPnz41+nHDhg2DXC7Hzp07uW0HDhxAVlYWhg0bBkD91/iOHTswaNAgsCyLjIwM7hYSEoLs7GxcvHjRpPLGxsaiU6dO3PV0QP1Xpqb5W+PgwYPIysrC8OHDdZ6Xz+fjtddeM3gJRJtYLOaugSuVSjx//hz29vZo3ry5TpmdnZ3x+PFjnDt3zuB5yvMajB07FjY2Nia9LtqGDBkCgUCArVu3ctuuX7+Omzdvcj8bQ86fP4+0tDR8+OGHOv1uNJeFtPH5fO4YlUqFFy9eQKFQoEOHDjr1iY2NhUAgwEcffaTz2KlTpxosQ2xsrM5lpZ07d0KlUuHdd9/Vee28vLzQtGlTvZ+jQCDApEmTuPsikQiTJk1CWloaLly4wD2Hl5cX9xckAAiFQnzyySfIy8tDfHw8APV1f4ZhDP7VzDAM9732zyo7OxsZGRkICgpCUlISsrOzAYDr77N7926TWi/K8z7+8MMPde53794dSUlJRj8nAJ2fF6C+hOLk5IS+ffvqlCMwMBD29vZl/j5pNG/eHO7u7mjYsCEmTJiAJk2aYO/evbC1teWOYRgG+/fvx7fffgsXFxds3rwZkydPhq+vL4YNG1biZcl3330XhYWF2L17N3Jzc7F79+4y/8JfvXo13N3d4eHhgddeew0nTpzAjBkzMH36dJ3jiv9Oan5XPv74Y51+ZgMHDkSLFi2wZ88eveeaMmWKTh2nTJkCmUyGQ4cOlVg+Ho+HkSNHYteuXcjNzeW2b9y4EV26dEGjRo1KrZ/m2IEDB8LBwQEA0LRpUwQGBpp8eQkA7O3tdcpR3vP369cPrq6u2LJlC1iWxZYtW3R+H2siCjIW9s0330ChUBg9gglQXzNt0aKFzofl1q1b4ebmhl69egEA0tPTkZWVhZUrV8Ld3V3nNn78eADqJndTPHjwAE2bNtXbXvxacWJiIgCgV69ees994MCBMp9XpVLh559/RtOmTSEWi+Hm5gZ3d3dcvXqV+3ACgC+//BL29vbo2LEjmjZtismTJ+PEiRPc/vK8Bsb851QaNzc39O7dW+fy0tatWyEQCHQuIRT34MEDANB7fYVCIfz8/PSOX7duHdq2bQuJRII6derA3d0de/bs0Xl9Hjx4gLp168Le3l7nsYau7aempuLixYs6QSYxMREsy6Jp06Z6r9+tW7f0Xrt69erpdUxt1qwZgJeXMTTvoeKdNTWX6jSvw71791CvXj24urrqlVXbiRMn0KdPH9jZ2cHZ2Rnu7u5cJ1XNaxEUFIShQ4ciKioKbm5uGDx4MNasWQOpVFrquU19H2v68WhzcXExqR+LQCCAt7e3Xjmys7Ph4eGhV468vDyjf4937NiBgwcPYtOmTejUqRPS0tIMhnaxWIyvv/4at27dQkpKCjZv3oxOnTrhzz//1AkE2tzd3dGnTx9s2rQJO3fuhFKp1Ou0WtzgwYNx8OBBHDp0CGfOnEFGRgZ+/PFHvfdG8d9JzXvE0Pu4RYsW3H4NHo+n9ztU/H1ZkjFjxqCwsBB//fUXAHVftwsXLmD06NGlPg4Abt26hUuXLqFr1664e/cudwsODsbu3bu5vj7GysvL4wJLRc4vFArxzjvvYNOmTTh69CgePXpUsy8rgUYtWZyfnx9GjRqFlStXIiwszOjHDRs2DHPmzEFGRgYcHBywa9cuDB8+nBs1oOmAO2rUqBL7RLRt27biFTBA89wbNmyAl5eX3n7tkQ2GzJ07F7Nnz8aECRMQExMDV1dX8Hg8TJ8+XadjccuWLZGQkIDdu3dj37592LFjB5YvX47w8HBERUWV6zWoSGuMxnvvvYfx48fj8uXLaN++Pf7880/07t1bZ5RARfzxxx8YN24c3nzzTcycORMeHh5cXwHtjpum2Lt3LyQSCXr27MltU6lUYBgGe/fuNdgJsHhAqmr37t1D79690aJFC/z0009o0KABRCIRYmNj8fPPP3M/f4ZhsH37dpw+fRr//PMP9u/fjwkTJuDHH3/E6dOnS6yHqe9jc3SU1G6N1C6Hh4dHiX9lFw9PJenRowf3Hhw0aBD8/f0xcuRIXLhwocRRQHXr1sV7772HoUOHonXr1vjzzz+xdu1ag7/DI0aMwPvvv4/U1FQMGDCgzJFv3t7e6NOnT5nlNsfvZHm1atUKgYGB+OOPPzBmzBj88ccfEIlEePfdd8t8rGa+lk8//RSffvqp3v4dO3Zwf1CVRS6X486dOzpzvFTk/CNGjMAvv/yCyMhItGvXDq1atTKqHNUVBZlq4JtvvsEff/yB+fPnG/2YYcOGISoqCjt27ICnpydycnJ0Ota5u7vDwcEBSqXSqP8sjOHr68v9laotISFB537jxo0BAB4eHuV67u3bt6Nnz55YvXq1zvasrCy9MGBnZ4dhw4Zh2LBhkMlkGDJkCObMmYNZs2aZ7TXQvpRhjDfffBOTJk3iWszu3LmDWbNmlfoYTSfLxMRErlUNUP8HlpycjHbt2nHbtm/fDj8/P+zcuVOnbMUvw/j6+uLw4cPIy8vT+bAu/vMCgD179qBnz546HxqNGzcGy7Jo1KgR9xdsaVJSUvSGC9+5cweAukOopkxXr16FSqXS+fDUTLSmeR0aN26M/fv348WLFyW2yvzzzz+QSqXYtWsXfHx8uO0lXWrp1KkTOnXqhDlz5mDTpk0YOXIktmzZgv/85z8Gj6/o+9gQU99LmnIcOnQIXbt2NduHur29PSIiIjB+/Hj8+eefZXbKFQqFaNu2LRITE7nLi8W99dZbmDRpEk6fPq3TWmxumvdIQkKCzu+KZptmv4ZKpUJSUpLOe7j4+7I0Y8aMwYwZM/D06VNs2rQJAwcO1OkgbQjLsti0aRN69uyJjz/+WG9/TEwMNm7caHSQ2b59OwoLC7mBHBU9f7du3eDj44O4uDiTPneqK7q0VA00btwYo0aNwq+//orU1FSjHtOyZUv4+/tj69at2Lp1K+rWraszuRqfz8fQoUOxY8cOXL9+Xe/xZc0UaUhoaChOnz6Ns2fP6pyn+F+KISEhcHR0xNy5cw32SSjrufl8vt7QyG3btukNrXz+/LnOfZFIhFatWoFlWcjlcrO9BpoP5pL6BxTn7OyMkJAQ/Pnnn9iyZQtEIhHefPPNUh/ToUMHuLu745dfftEZcbB27Vq959X85a/9Gp05cwanTp3SOS40NBQKhUJnOLJSqcSSJUt0jpPL5Th48KDesOshQ4aAz+cjKipK7+fBsqze669QKPDrr79y92UyGX799Ve4u7sjMDCQK1NqaqrOB51CocCSJUtgb2/PzX8xdOhQsCxrcCi7piyGXofs7GysWbNG5/jMzEy98rdv3x4ASr28VNH3sSGa/ijGvpcAdf8TpVKJmJgYvX0KhcKkc2kbOXIkvL29dT7IEhMT8fDhQ71js7KycOrUKbi4uJTYAmRvb48VK1YgMjISgwYNKleZjNGhQwd4eHjgl19+0fn57d27F7du3dJ7HwPQGbbMsiyWLl0KoVCI3r17l/l8w4cPB8MwmDZtGpKSkowarXTixAncv38f48ePx9tvv613GzZsGI4cOWLUiNUrV65g+vTpcHFxweTJk81yfoZhsHjxYkRERBh1may6oxaZauLrr7/Ghg0bkJCQgNatWxv1mGHDhiE8PBwSiQQTJ07Uax6eN28ejhw5gtdeew3vv/8+WrVqhRcvXuDixYs4dOgQXrx4YVIZv/jiC2zYsAH9+/fHtGnTYGdnh5UrV3J/ZWs4OjpixYoVGD16NF555RW89957cHd3x8OHD7Fnzx507drV4HwIGq+//jqio6Mxfvx4dOnSBdeuXcPGjRv1rnP369cPXl5e6Nq1Kzw9PXHr1i0sXbpUp/ObOV6D9u3bg8/nY/78+cjOzoZYLObmLinJsGHDMGrUKCxfvhwhISFlNrMLhUJ8++23mDRpEnr16oVhw4YhOTkZa9as0av366+/jp07d+Ktt97CwIEDkZycjF9++QWtWrVCXl4ed9ygQYPQtWtXhIWF4f79+2jVqhV27typ048GAI4fP46cnBy9D4DGjRvj22+/xaxZs3D//n28+eabcHBwQHJyMv766y988MEH+Pzzz7nj69Wrh/nz5+P+/fto1qwZtm7disuXL2PlypUQCoUAgA8++AC//vorxo0bhwsXLqBhw4bYvn07Tpw4gYULF3I/t549e2L06NFYvHgxEhMT0b9/f6hUKhw7dgw9e/bElClT0K9fP4hEIgwaNAiTJk1CXl4eVq1aBQ8PD53O8+vWrcPy5cvx1ltvoXHjxsjNzcWqVavg6OioM9S8uIq+jw2xsbFBq1atsHXrVjRr1gyurq5o06ZNqdPCBwUFYdKkSfjuu+9w+fJl9OvXD0KhEImJidi2bRsWLVpUZn8UQ4RCIaZNm4aZM2di37596N+/P65cuYIRI0ZgwIAB6N69O1xdXfHkyROsW7cOKSkpWLhwYamX0Eq6hGtOQqEQ8+fPx/jx4xEUFIThw4fj2bNnWLRoERo2bKh3mUUikWDfvn0YO3YsXnvtNezduxd79uzBV199ZdRlOc38Rdu2bYOzs7PBoFTcxo0bwefzSzz2jTfewNdff40tW7ZgxowZ3PZjx46hqKiIG+Rw4sQJ7Nq1C05OTvjrr7+4lrDynl/b4MGDMXjw4DLrUiNU8Sgpq6c9ZLE4zVDBsoZfayQmJrIAWADs8ePHDT7fs2fP2MmTJ7MNGjRghUIh6+Xlxfbu3ZtduXIld4yxw69ZlmWvXr3KBgUFsRKJhK1fvz4bExPDrl69Wmf4tcaRI0fYkJAQ1snJiZVIJGzjxo3ZcePGsefPny/1OYqKitjPPvuMrVu3LmtjY8N27dqVPXXqlMGhzj169GDr1KnDisVitnHjxuzMmTPZ7Oxsk1+DsoY/rlq1ivXz82P5fL7OsOniZdLIyclhbWxs9IYaF3++4kO6ly9fzjZq1IgVi8Vshw4d2KNHj+o9h0qlYufOncv6+vqyYrGYDQgIYHfv3s2OHTtWZ/g0y7Ls8+fP2dGjR7OOjo6sk5MTO3r0aPbSpUs6P+/PP/+cbdWqlcF6syzL7tixg+3WrRtrZ2fH2tnZsS1atGAnT57MJiQkcMdohm2eP3+e7dy5MyuRSFhfX1926dKleud79uwZO378eNbNzY0ViUSsv7+/wfeeQqFgv//+e7ZFixasSCRi3d3d2QEDBrAXLlzgjtm1axfbtm1bViKRsA0bNmTnz5/P/v777zrvx4sXL7LDhw9nfXx8WLFYzHp4eLCvv/56me9DDWPex2PHjmXt7Oz0HqsZ+qzt5MmTbGBgICsSiXSGYpd0Do2VK1eygYGBrI2NDevg4MD6+/uzX3zxBZuSklJq+TVlMDTUODs7m3VycuLeX8+ePWPnzZvHBgUFsXXr1mUFAgHr4uLC9urVi92+fbvOY0v7v0xbScOvJ0+eXOrjyvqd3Lp1KxsQEMCKxWLW1dWVHTlyJPv48WOdYzSv6b1799h+/fqxtra2rKenJxsREaE3xUNp/vzzTxYA+8EHH5R5rEwmY+vUqcN279691OMaNWrEBgQEsCz7sq6am1AoZN3d3dkePXqwc+bMYdPS0sxy/tKGd7NszR1+zbBsGdMbEkJqtVatWuH111/HggULyn2O4OBgZGRkGLyER4iljBs3Dtu3b9dpqSyP//73v3jzzTdx9OhRbkZkUn3QpSVCrJhMJsOwYcOMGoVBiLVatWoV/Pz80K1bN0sXhRhAQYYQKyYSicqcqp0Qa7VlyxZcvXoVe/bswaJFi8o16oxUPgoyhBBCiAHDhw+Hvb09Jk6caHCYM6keqI8MIYQQQmosmkeGEEIIITWWRYNMZGQkGIbRubVo0YLbX1RUhMmTJ6NOnTqwt7fH0KFD8ezZMwuWmBBCCCHVicX7yLRu3VpnBVLtNTw+/fRT7Nmzh1v9dcqUKRgyZIjOwoBlUalUSElJgYODA3XUIoQQQmoIlmWRm5uLevXqlbgeGFANgoxAIDC4bkd2djZWr16NTZs2cetprFmzBi1btsTp06fRqVMno86fkpKCBg0amLXMhBBCCKkajx490lsVXpvFg0xiYiLq1asHiUSCzp0747vvvoOPjw8uXLgAuVyus1hbixYt4OPjg1OnThkdZDRTnj969AiOjo6VUgdzkcvlOHDgADcFuTWwxjoD1llva6wzYJ31tsY6A9ZZ78qsc05ODho0aMB9jpfEokHmtddew9q1a9G8eXM8ffoUUVFR6N69O65fv47U1FSIRCK9NWo8PT1LXVhRKpXqLCSWm5sLQL3GiSWXgzeGQCCAra0tbGxsrOaXwBrrDFhnva2xzoB11tsa6wxYZ70rs86axVrL6hZSrYZfZ2VlwdfXFz/99BNsbGwwfvx4vdVpO3bsiJ49e5a49HhkZKTBFXM3bdrErTxLCCGEkOqtoKAAI0aMQHZ2dqlXVCx+aUmbs7MzmjVrhrt376Jv376QyWTIysrSaZV59uyZwT41GrNmzdJZ7VPTNNWvX78acWnp4MGD6Nu3r9WkeWusM2Cd9bbGOgPWWW9rrDNgnfWuzDrn5OQYdVy1CjJ5eXm4d+8eRo8ejcDAQAiFQhw+fBhDhw4FACQkJODhw4fo3LlziecQi8UQi8V624VCYY15Y9WkspqLNdYZsM56W2OdAeustzXWGbDOeldGnY09n0WDzOeff45BgwbB19cXKSkpiIiIAJ/Px/Dhw+Hk5ISJEydixowZcHV1haOjI6ZOnYrOnTsb3dHXFEqlkrseZylyuRwCgQBFRUVQKpUWLUtVKU+dhUIh+Hx+JZeMEEJITWDRIPP48WMMHz4cz58/h7u7O7p164bTp0/D3d0dAPDzzz+Dx+Nh6NChkEqlCAkJwfLly81aBpZlkZqaiqysLLOet7xl8fLywqNHj6xmzpvy1tnZ2RleXl5W8zoRQggxzKJBZsuWLaXul0gkWLZsGZYtW1ZpZdCEGA8PD9ja2lr0g1GlUiEvLw/29valTv5Tm5haZ5ZlUVBQgLS0NABA3bp1K7uIhBBCqrFq1UemqimVSi7E1KlTx9LFgUqlgkwmg0QisaogY2qdNcPo09LS4OHhQZeZCCHEilnHp2UJNH1iaFh2zaP5mVm6XxMhhBDLsuogo0H9LGoe+pkRQggBKMgQQgghpAajIEMIIYQQo0XGRSImPsbgvpj4GETGRVZpeSjImIFSCcTFAZs3q79W1RQwp06dAp/Px8CBA3W2379/HwzDcDcHBwe0bt0akydPRmJioknn0j4fn8/HkydPdPY9ffoUAoEADMPg/v37ZqsbIYSQ6onP8BEeF64XZmLiYxAeFw4+U7UDMCjIVNDOnUDDhkDPnsCIEeqvDRuqt1e21atXY+rUqTh69ChSUlL09h86dAhPnz7FlStXMHfuXNy6dQvt2rXD4cOHTT4XANSvXx/r16/X2bZu3TrUr1/fPBUihBBS7c0Omo3o4Gh1mDkag8dFjzE7bjbC48IRHRyN2UGzq7Q8Vj38uqJ27gTefhsovuzmkyfq7du3A0OGVM5z5+XlYevWrTh//jxSU1Oxdu1afPXVVzrH1KlTh1uXys/PD4MGDULv3r0xceJE3Lt3jxu2bMy5AGDs2LFYs2YNZs2axW1bs2YNxo4di5gYw82MhBBCar5caS5uZ9zGrYxb3Fc3WzfEHH/5f78lQgxALTIG5eerb9oBRSZTb9Msxq1UAtOm6YcY4OW2adN0LzNpzqtSvdxW3tHDf/75J1q0aIHmzZtj1KhR+P3331HWQuY8Hg/Tpk3DgwcPcOHCBZPP9cYbbyAzMxPHjx8HABw/fhyZmZkYNGhQ+SpBCCGk2mBZFk9zn+JI8hEsP7ccU2Onou+GvvD+yRuO8xzR8beOGPv3WHx3/Dv8fftvZBRkcI8VMAKLhBiAWmQMsrdXf01LA/5dLQHffw988w3wn/8Aq1YBx44Bjx+XfA6WVe8/dgwIDlZva9gQyMgArl8HWrdWb1u7Fnj/fdPLuHr1aowaNQoA0L9/f2RnZyM+Ph7BmicrQYsWLQCo+7107NjRpHMJhUIu6HTr1g2///47Ro0aZXWLoxFCSE2mUCmQnJms07pyK139fbY0u8THedp5oqV7S7So0wIt3VviQsoFrL+6HgJGAAWrQEx8jEXCDAWZcnr61LzHmSIhIQFnz57FX3/9BQAQCAQYNmwYVq9eXWaQ0bS0aOZhMfVcEyZMQJcuXTB37lxs27YNp06dgkKhMF/lCCGEmEW+LB8JzxPUYSX9Fm4/V39NfJEImVJm8DE8hgc/Fz+0cGuBlm4tdb662Lhwx8XEx2D91fWI6BGBgJwAXHK8hPC4cACgPjLVQV6e+qv2hL8zZwLTpwOCf18xY5f40T5OM6jn3xn2AQDjxplevtWrV0OhUKBevXrcNpZlIRaLsXTp0lIfe+vWLQBAo0aNjDqXk5OTzuP9/f3RokULDB8+HC1btkSbNm1w+fJl0ytBCCEEkXGR4DN8gx/+MfExULJKRAZHlvh4lmWRUZCh06qiaWl5kP2gxMfZCGzQ3K25XlhpWqcpJAJJqWXWjE6KDo5GWJcwxMbG4utuX4PP41skzFCQMcDOTn+bSKS+aXTvDnh7qzv2GuqawjDq/d27l35eU6/KKBQKrF+/Hj/++CP69euns+/NN9/E5s2b0b9/f4OPValUWLx4MRo1aoSAgACjzvXhhx/qnWfChAn4+OOPsWLFCtMKTwghRIdmKDOg++GvHRYAQKlS4kH2A651Rfuy0IvCFyWe383WTS+stHRvCR8nH/CY8nWTVbJKrmOv9jIxmvIr2Sqag+RfFGTKic8HFi1Sj05iGN0wo5k9f+FC9XHmtHv3bmRmZmLixIl6rSVDhw7F6tWruSDz/PlzpKamoqCgANevX8fChQtx9uxZ7NmzB3w+H3///XeZ5zIUZN5//3288847cHZ2Nm/lCCHEymg+/DVh5vMun+Pzg59j+bnl6NmwJ26k30C7X9rhzvM7KFIUGTwHAwa+zr5o6dZSJ6y0cGsBN1s3s5e5tBYi6iNTwwwZoh5iPW2absdfb291iKmModerV69Gnz599IIHoA4fCxYsQE5ODgCgT58+ANQLLPr6+qJnz55YuXIlmjRpYvS5rl69CkdHR519AoEAbm7m/+UghJCahGVZFCoKkSfLQ640F5kFmbiVdwuCJAGKlEXIk+UZvsn1tzmIHBAeF84FGgA4cv+IzvOJ+WI0q9OMa13RhJVmdZrBVmi9ix9TkKmgIUOAwYPVo5OePlX3iene3fwtMRr//PNPifs6duzIdeYtayi2Kecq63zt27c36vkIIcRSVKwK+bL8EsNFriy35OBRyo2Fgf/77la8vJ29O+uElZZuLdHQuSH4vKqdNbcmoCBjBnz+yyHWhBBCKkahUpQrVJQWRgrkBZVaZnuRPeyF9mDkDDxcPOAgdlBv09yE9rr3i9223NiCX87/AhFfBJlShgFNBlhsXpaahoIMIYSQcpMpZS+DhFQdJLIKsnAm+wyyrmcZvsRi4NKK9uOlSmmllZfH8PRChIPIodSQUdbNVmgLHsODXC5HbGwsQkNDTZpfKyY+Br+c/4XrQKvp6AtYps9JTUNBhhBCylDRIbLVAcuyKFKU0m+jnJdY5KpSpidPrliZBTyBUSHDlCAiEUi4ebSqA+3RSZr3V/EOwBRmSkdBhhBCymDsEFlzUbEqFMgLzH55RcWqyn7ycpIIJFxYsBPaQZGvgLeHNxwkDmVeWtG7DPPvTcQXlf3ENZz2UGZtlhrKXBNRkCGEkDIY+gtZE2IigyIxrdM0pOSm6F0iyZPlIbswG2fTz+LKiSvcCJeSLq1oHpsvz6/U+tgKbc16acVeZA8B7+XHSXkvsVij6jaUuSaiIEMIIWWQKWXo0qALunh30RkiK+AJEBkficj4yLJP8sT052XAGBUiTAkitkJbGvlCahUKMoQQYkBKbgr2Ju7FnsQ9OJh0EHmyPL1jFKqX64zxGb7BSyS2AlvkZuSiacOmcBQ7mnRpxUZgU636cxBSHVGQIYQQqKeAP/PkDGITYxGbGItLqZd09nvYeaC+Q31cSr0EIU8IuUqOTzt9iq+6fwUHkQNEfJHB0EGXWQipXBRkCCFW63nBc+y/tx97Evdg3919OmvWMGDwav1XMbDpQIQ2DUVsYiwi4iL0hsi6SFyoLwMhFkRBhhBSo5kyNJplWVxOvYzYxFjsSdyDM0/O6IzkcZY4I6RxCEKbhqJ/k/7wsPPgzqMdYgAaIktIdVG+pS+JxY0bNw4Mw4BhGAiFQjRq1AhffPEFiopeLiqm2X/69Gmdx0qlUtSpUwcMwyAuLo7bHh8fj169esHV1RW2trZo2rQpxo4dC5lMBgCIi4vjzskwDDw9PTF06FAkJSVVSZ0JMUQzNDomPkZnu6bFRKFSYOetnfjPrv+g/k/18crKV/DNkW9w6vEpqFgV/D38EdY1DEfHHUX6zHRseXsLxrQbw4UYoPQhstHB0TRElhALohaZCrD0JFn9+/fHmjVrIJfLceHCBYwdOxYMw2D+/PncMQ0aNMCaNWvQqVMnbttff/0Fe3t7vHjxshn95s2b6N+/P6ZOnYrFixfDxsYGiYmJ2LFjB5RK3f+kExIS4ODggMTERHzwwQcYNGgQrl69Cn6xBaZYloVSqYRAQG8zUnmKt4x80+MbTNs3DUvOLkEj50ZYcGKBzqRttkJb9PHrg9AmoQhtGooGTg3KfA4aIktI9UUtMhVQ1l+CfKZyhziKxWJ4eXmhQYMGePPNN9GnTx8cPHhQ55ixY8diy5YtKCws5Lb9/vvvGDt2rM5xBw4cgJeXFxYsWIA2bdqgcePG6N+/P1atWgUbGxudYz08PFC3bl306NED4eHhuHnzJu7evcu12OzduxeBgYEQi8U4fvw4pFIpPvnkE3h4eEAikaBbt244d+4cd77jx4+Dz+djz549aNu2LSQSCTp16oTr169XwqtGaiNNy0h4XDh40TwsObsEAJCclcyFGDFfjDeav4Hv+36PYa2HwcPOA9fTriPufhzOPD6Dq8+u4s7zO3iU/QgZBRnIl+VDqaKWFkKqO/pTWQvLsiYtLDaj8wzIlDKEx4VDppQhrFsY5h2fh2+PfYtvun+DGZ1nIF9m3MRWFV2C/fr16zh58iR8fX11tgcGBqJhw4bYsWMHRo0ahYcPH+Lo0aNYtmwZYmJeBjAvLy88ffoUR48eRY8ePYx+Xk3I0Vx+AoCwsDD88MMP8PPzg4uLC7744gvs2LED69atg6+vLxYsWICQkBDcvXsXzs7O3ONmzpyJRYsWwcvLC1999RUGDRqEO3fu0EgPYpRvenzDtcoYIlVKsSthF3Yl7DLpvEKeEDZCG9gIbCARSLjvDW4zcIyQEeLu87vIvJ4JB7GD3n6JQKJ3PiGf3vOEGIuCjJYCeQHsv7Mv12O/PfYtvj32bYn3y5I3Kw82ApuyD9Sye/du2NvbQ6FQQCqVgsfjYenSpXrHTZgwAb///jtGjRqFtWvXIjQ0FO7u7jrHvPPOO9i/fz+CgoLg5eWFTp06oXfv3hgzZgwcHR0NPv/Tp0/xww8/oH79+mjevDlOnjwJAIiOjkbfvn0BAPn5+VixYgXWrl2LAQMGAABWrVqFgwcPYvXq1fjss8+480VERHCPW7duHby9vfHXX3/h3XffNel1Idbp26Pq3zc+w4eSVaJnw57oWL8jCuWFKFIUoVBRqL5p35ertxUpirjvC+WFOpei5Co55FI5cqQ5FSvgI+MP5TP8EsOToeBTYrAq6XgD+0saPk5IdUdBpgbr2bMnVqxYgfz8fPz8888QCAQYOnSo3nGjRo1CWFgYkpKSsHbtWixevFjvGD6fjzVr1uDbb7/F//73P5w5cwZz587F/PnzcfbsWdStW5c71tvbW916VVCAdu3aYceOHRCJXq6J0qFDB+77e/fuQS6Xo2vXrtw2oVCIjh074tatWzpl6Ny5M/e9q6srmjdvrncMIYYUX3hPc79nw56Y12eeyedTqpQ6Yaes4FPa/nxZPh4+eQjHOo4oUhaVeA7tFZ+VrJJbsqCqMGBMCj6lHSOAADezb0KYJISDpORWqOq2gCOpmSjIaLEV2iJvlun/cWguJ4n4IsiUMnzT/RuEdQsz+blZljXpMXZ2dmjSpAkAdb+Xdu3aYfXq1Zg4caLOcXXq1MHrr7+OiRMnoqioCAMGDEBubq7Bc9avXx+jR4/G6NGjERMTg2bNmuGXX35BVFQUd8yxY8fg6OgIDw8PODg4GCwXIVWlMlYP5vP4sBPZwU5U8feysRPiqVgVpAqpWcKTKcezUP+/w0J9ad2Uy+tlMmL1a4lAYnJ4qmgrFI+h7qG1CQUZLQzDmPwfV0x8DL499q3eX4Iivsjk/zxNDTLaeDwevvrqK8yYMQMjRozQ66A7YcIEhIaG4ssvv9QbXVQSFxcX1K1bF/n5uv18GjVqpNO3pTSNGzeGSCTCiRMnuP47crkc586dw/Tp03WOPX36NHx8fAAAmZmZuHPnDlq2bGnU8xDrVVtWD+YxPPWHrdAGMO0qc7mxLAuZUmZ6UCojPBXICvA04ykk9hKDrVDaP5MiRRGKFEXIQlbVVBq6/Z7KDD5GBCXNNiGESCpIQsLzBDhIHHRbqXjV9+PW0iNwK6r6vrI1QGX8JVgR77zzDmbOnIlly5bh888/19nXv39/pKenl9jf5ddff8Xly5fx1ltvoXHjxigqKsL69etx48YNLFmypNxlsrOzw0cffYSZM2fC1dUVPj4+WLBgAQoKCvRajqKjo1GnTh14enri66+/hpubG958881yPzexDjQ0uvwYhoFYIIZYIDbrectqhZIr5eUKTwb3G3l8pfR7Kskd/U3a/Z7MEZ6M2W9svyfNCFxA93dG+zOuOqMgUwHV7S9BgUCAKVOmYMGCBfjoo4909jEMAzc3txIf27FjRxw/fhwffvghUlJSYG9vj9atW+Pvv/9GUFBQhco1b948qFQqjB49Grm5uejQoQP2798PFxcXqFQqneOmTZuGxMREtG/fHv/8849O3xtCSO0g5Ash5AvhKDb8h1VlKN7vyahWpnKEp6y8LLACtlr1ezIm+AR4BSA8Lhz77u3Dl12/xJXUK3p/qFdXDFuR6xk1QE5ODpycnJCdna3XGlFUVITk5GQ0atQIEonEQiV8SaVSIScnB46OjuDxrOMarkqlQmxsLAYNGoTMzEyjL1lVt5+dqaxxIUFrrDNgnfW2xjoD+vUu3u+pQq1QJlzyMxdjQkxl/qxL+/zWRi0yhBBCSCWwdL8nQ8FHe9uJhyew6uIqg+GnPP08LYWCDCGEEFJLaPd7cpY46+1XqBT4+/bfWHJ2CY4/PM5t79KgC7wdvPHnzT+5Ebgx8TE1IsxYx/ULUq1169YNSqXS6MtKhBBCTJNZmIkfTv6Axosb451t7+D4w+MQ8AQY6T8SZ/9zFv0b98efN/9EdHA0pN9IuSU/ii/BUx1RiwwhhBBSg5U2fHra3mk4+egkbmbc5OYIcrN1w4eBH+KjVz9CPYd61W4ErqkoyKBi87cQy6CfGSGEqBUfPs2yLA4mHcSU2ClIfJHIHefv4Y/pnaZjeJvh6n47/6puI3BNZdVBRtPDuqCgQG8COVK9FRSo/7KwphERhBBiiHbrycWnF5HwPAG3Ml4u7/JG8zcw/bXpCG4YbHBemZo+F5NVBxk+nw9nZ2ekpaUBAGxtbS267odKpYJMJkNRUZFVDb82pc6aNZ7S0tLg7Oxs9CzFhBBSm80Omo2krCSsvbyW28Zn+FjQdwE+CPwA9qLyLYhcE1h1kAEALy8vAODCjCWxLIvCwkLY2NhYzUJq5a2zs7Mz97MjhBAC/NjvR6y/sh4qVj3RqJJV4rMDn2HW4VkI8g3CwKYDEdo0FE3rNLVwSc3L6oMMwzCoW7cuPDw8IJfLy35AJZLL5Th69Ch69OhhNZdMylNnoVBILTGEEFLMsrPLoGJV3PDpjvU7Ii0/Dfez7uNg0kEcTDqI6funo6lrU4Q2DcXApgPRw7eH2ZeoqGpWH2Q0+Hy+xT8c+Xw+FAoFJBKJ1QQZa6wzIYSYW/GRR5r7UcFReLf1u9hzZw9i78bi6IOjSHyRiEVnFmHRmUWwE9qhj18fhDYNxYAmA9DAqYGlq2IyCjKEEEJIDVbW8GkGDGYHzcZnXT5DjjQHh5IOITYxFrGJsXia9xT/Tfgv/pvwXwBAW8+2CG0SioHNBqKTdycIeIJSh3fPOT4Ht5/eRihCq67CxVCQIYQQQmowU4ZPO4odMaTlEAxpOQQsy+Jy6mXEJsZiT+IenH58GlefXcXVZ1cx78Q8uEhcENIkBDKFDDtv79Q5J6AOUFFHozDca3gV1LJkFGQIIYSQGqy8w6cZhkFA3QAE1A3A1z2+RkZBBg7cO4A9iXuw7+4+vCh8gS3Xt3DHh8eF48j9I1gauhQ7bu5AeFw4InpEICAnwJzVMRkFGUIIIcTKqVgVZEoZ/Fz8MLj5YLTzbIftN7fjXMo5neOO3D+C1stbA1Cvjh3WJQyxsbGWKDKHggwhhBBSy+VIc/Aw+yF3e5T9CA9zXt5/kvMEcpXxI3c1q2NberQvQEGGEEIIqdHkSjme5D7RDSnZD3WCSo40p8zz8Bge6jvUh4+TD3ycfNDAsQH3vY+TD7be2Irvjn+nszp2WJewKqhh6SjIEEIIIdUUy7J4Xvi81NaUp7lPwaLs9edcJC46waR4UKnrUBcCnuFYEBMfg++Of6c3vFupUiIA1EeGEEIIqRHMPRS5UF6IRzmPSmxNeZT9CIWKwjLPI+KLdIJJ8ZDSwKlBuZcpKGt493Cv4TT8mhBCCKkJiq80rWFoKLKKVSE1L7XUSz4ZBRlGPa+nnWeprSnudu7gMZWzRl9pw7uVKiVuJ9yulOc1FgUZQgghxEjaLRFylRzvtn4X84/Pxx/X/kC3Bt2QkpeC3ht641HuI6M70NoJ7UoNKd6O3hZdRqC04d1fd/sasTk0aokQQgipMWYHzUauLBcxR2MQczSG23780XH1N5kvjy3egdZQUHGWOFvNQsGVgYIMIYQQYqLPu3yO709+r7NNwBOgj0sfjOg2An6ufmV2oCXmUTkX1AghhJBa7NfzvwIABMzLkKJQKXDg+QHsvL0TKlYFb0dvCjFVgIIMIYQQYgLtUTzycDmigqMAAI2dG0MFFf5O+Bs91vZAh1UdsP7KekgVUguXuHarNkFm3rx5YBgG06dP57YVFRVh8uTJqFOnDuzt7TF06FA8e/bMcoUkhBBi1QwNRQ4PUt+/l3UPoXVC8Z/2/4GNwAYXn17E2L/HwnehL6Ljo5GWn4bIuEjExMeUeO7IuMgqrE3tUC2CzLlz5/Drr7+ibdu2Ots//fRT/PPPP9i2bRvi4+ORkpKCIUOGWKiUhBBCrF1pQ5EjekTAQeCA5aHL8ejTR/iu93eo71Afz/KfISIuAg1+boBdCbsQHheuF2Y0AYnP8KuyOrWCxYNMXl4eRo4ciVWrVsHFxYXbnp2djdWrV+Onn35Cr169EBgYiDVr1uDkyZM4ffq0BUtMCCHEWkUGR5a4ovTX3b7G8LrqeWTq2NZBWLcwJE9LxpahW9DJuxNkShkupV4CoB6+PWLHCChVSoOtPMR4Fu+FNHnyZAwcOBB9+vTBt99+y22/cOEC5HI5+vTpw21r0aIFfHx8cOrUKXTq1Mng+aRSKaTSl9cjc3LU60vI5fJqsbhVaTTlq+7lNCdrrDNgnfW2xjoD1llva6wzUHK9hzQfgiHNh+Dsk7NYcm4JdtzeAYVKgc3XN2PL9S1gwSKiRwTCuoTVuNesMn/Wxp7TokFmy5YtuHjxIs6dO6e3LzU1FSKRCM7OzjrbPT09kZqaWuI5v/vuO0RFReltP3DgAGxtbStc5qpw8OBBSxehylljnQHrrLc11hmwznpbY52B0us9mD8YqU6piM+MBwCwYCFgBAjICUBsrGUnlquIyvhZFxQUGHWcxYLMo0ePMG3aNBw8eBASicRs5501axZmzJjB3c/JyUGDBg3Qr18/ODo6mu15KoNcLsfBgwfRt29fCIVCSxenSlhjnQHrrLc11hmwznpbY52B0uutYlVYf3U9vjnyDdIK0rjtQp4QcpUclxwv4etuX1d1kSusMn/WmisqZbFYkLlw4QLS0tLwyiuvcNuUSiWOHj2KpUuXYv/+/ZDJZMjKytJplXn27Bm8vLxKPK9YLIZYrD+Vs1AorDG/UDWprOZijXUGrLPe1lhnwDrrbY11BvTrferRKXyy7xOcTzkPAKhjUwfPC5/rrSTN5xlejLImqIyftbHns1iQ6d27N65du6azbfz48WjRogW+/PJLNGjQAEKhEIcPH8bQoUMBAAkJCXj48CE6d+5siSITQgghOkpbDXvmwZnYf3c/rqWpP+scRA7o0qAL9t/bX+JK0tr3iXEsFmQcHBzQpk0bnW12dnaoU6cOt33ixImYMWMGXF1d4ejoiKlTp6Jz584ldvQlhBBCqpL2athhXcIAAEWKIgzYPACHkw8DABgwGN9+POb2nosV51ega4OuBodvA+rh3cQ0Fh+1VJqff/4ZPB4PQ4cOhVQqRUhICJYvX27pYhFCCCEAdFtTlEolpFlSjF88HplF6pUjO3t3xuIBi9GhXgcApa8kTS0x5VOtgkxcXJzOfYlEgmXLlmHZsmWWKRAhhJBaR66Uo0hRhEJFIQrlhShUFKrv//t9obzQ+P3/3vdz9kPUsZcjZh1EDlg+cDlG+o+kla0rWbUKMoQQQqwHy7KQKWUVCxLa+408vrIv3/AZPlI+S4G9yL5Sn4eoUZAhhBAClmW5D/uKhooCWQHuP7mP5VuWo0hZVOrxLFiL1lvMF8NGaAMbgQ1shDaQCCTc9zaCf+9r9he/r3X8vrv7sP3WdggYARSsAj+f+pkuFVURCjKEEFLNqFiV0aGhzKBhZDApUhSZvyLZxh/KgCk7SGjvNyZ4lLFfLBCDx1R8pZ6Y+Bhsv7UdET0iEJATgEuOl2gEUhWiIEOIFStt6GhMfAyUrLLUzonWQKFSVLh1IuFRArbt2gapSmpUqJApZRatM5/hmxYMit0X8US4d/seOgR0gL3Y3qigIeKLamRfEu11ksK6hCE2NhZfd/safB6fwkwVoSBDiBXTHjqq/Z+t9n/O1QXLspCr5BXvR6HVUmHMOczWn+J5+R4m5AlLDAGmXPowJZgI+RWb2EwulyM2Ixah/qG1fkI87dWwtdcGouHUVYeCDCFWzNBEXMasxKvpT2FKkMiT5uHKsys4E38GMpXM4MiP0s5XpCiCilVV2WtjSHn6U4j4IjxKeoR2rdrBTmxncqjg8/gWrTMpHQ2ntjwKMoRYudlBs8GCRXhcOCLjI6FiVWjs0hgHkw5i151dBoNJhfpTPK14mWtSfwq5XI7YgliEdqr9rROEWAIFGUIIRrcdjYi4CK7F417mPdzLvFdlz89n+HCxcYGLxAWuNq5wtXHVvy9xgYuN+r6T2EkvbEgEErN03CSE1CwUZAgh+OPqHwDUgULJKtGlQRcEeAWUOvLF0LbyDqVVskpkFGQgoyCjQvUQ88Wm9RExQ58SuvRDiGVRkCHEyhXvE6O5379xf5Ou8ZfVGTe3KBfHTx9H6/atIWflZhs2rFApuDJIlVJIlVJkS00Y91tBAp5AJ9gUDzsSvgSZ6Zn4c9efsBPZmSU8CXiCGjnCh5DKQEGGECtmqGNveVfiZRgGIr4IIr4ITnDS2y+XyyG9JUVoS/P2FdEeHm3u2WGNGR6tUCmQK8tFriy31HKeyj5ltjrzGJ5Jwccc4ammDo8mtR8FGUKsmPbQUW01aeiogCeAg9gBDmKHKntOpUpp9Cy4+dJ8nL98Hn7N/SBTyco9tb52B2sVq0K+PB/58vwqqzMDRifslBZ8xDwxnj15hrhDcdxIrTLDloFt5pqwrjLRXEyWR0GGECtGQ0fLh8/jw05kBzuRXZnHyuVyeDzxqPCoJRWrglQhNftih2WdQ9PviQXLPc5Y+57vK3d9NbSHvJdncr7ytEKZ0u9Jey6msC5h3PbqOBdTbUVBhhBCagAew1N/6Apt4AKXKnlOzaKOpoanfGk+rt26hvqN6us+vhyTEGr6PWUhq0rqDJQ+CaGhMNSpfieEx4XjcPJhDBIPwpzjcxB1NKrUuZiI+VCQIYQQYhDDMBALxBALxAb7PZVELpcjNisWob3K1wpV0WUhTO00XigvhFz1clZeuUoOuVSOHGmOSeWOfxCPeMQDd0AhpgpRkCGEEFKtWLrfk6nhKVuajZ9O/cRdhhPxRRRiqhAFGUIIIVbPlH5PxWmHGAEjgEwpQ0x8DIWZKkJBhhBCCCmn9Px0fHX4KwDAG83ewATbCbjkeIlWvq5CFGQIIYQQIxUfbh26KRRSpRR17euivWd7bL6zGRtCN4DPM7yyPDE/CjKEEEKIkbSHWw9uMRjnU84DAEKbhiL6WDSGew0HULPmYqrpKMgQQgghRtKe+XrN5TUAgNburbH60mpE9IhAQE6A3rGkclXvKRMJIYSQaub1Zq/D18kXyVnJAIAb6TcQHRyNr7t9beGSWScKMoQQQogR0vPTMemfSQhcGYgH2Q+47TTc2rIoyBBCCCGlkCvlWHh6IZouaYqVF1eCBQt/D38A6hCjGW5NLIP6yBBCCCElOHDvAKbvm45bGbcAAAFeAXil7itYfWk1N3uvZl0lpUqJAASUcUZibhRkCCGEWKXSVq6evm869t7dizvP7wAA3GzdMLfXXKTkpiAyPlJnCQLtDsDDvYYjFKFVVwlCQYYQQoh10h5KrQkjudJchG4KxfGHxwGol0uY8uoURARHwFnijMi4SIPrKM0Omg2lSonbCberthKEggwhhBDrpN2SwoJFQ+eGmBw7GXmyPABASOMQ/BzyM1q6t+QeExkcWeL5vu72NWJzYiu1zEQfBRlCCCFWSzvMaAtuGIyo4Cg0rdPUEsUiJqBRS4QQQqza7KDZEPKEOtvi7seh0+pOcJnvggEbB2D+8fk48/gM5Eq5hUpJSkItMoQQQqxaTHwM5Co5N5R6QJMBEPFFOPrgKDKLMrHv7j7su7sPAGAntEM3n24IbhiM4IbBCKwbCCFfWMYzkMpEQYYQQojV0gydLj6UOjo4GjuH7cS1Z9cQdz8OcQ/iEH8/HplFmdh/bz/239sPQB1suvp0RbBvMLp5d4OCVVi4RtaHggwhhBCrVDzEAPp9ZmYHzUY7r3aY1mkaVKwK19Ouq4PN/TjEP4jHi8IXOHDvAA7cOwAAEPPE6J7THT0b9URww2B0qNcBIr6Ie87ShnzHxMdAySpL7VBM9FGQIYQQYpWUrLLEodSa/dp4DA9tPduirWdbfPLaJ1CxKtxIu6HTYvO88DkOJR/CoeRDAABboS26NOiCYF/1pSgAekO+Ad1QRUxDQYYQQohVKq3lw5i1k3gMD/6e/vD39MfU16ZCKpPi152/gvVlcezRMcQ/iEdGQQYOJR3CoSR1sLER2MDP2Q/hceF4kP0Ay0KXYcGJBXotQ8R4FGQIIYQQM+AxPPja+CK0QyimdVZfirqZfhPx9+MR90B9OSqjIANJWUkAgNWXVmP1pdUAgFH+oxDWLcySxa+xKMgQQgghlYDH8NDGow3aeLTB5I6TwbIsbqbf5PrXbLu5jTv2j2t/YN+9fXin1TsY3mY4uvp0BY+hGVKMQa8SIYQQUgUYhkFrj9aY3HEyt3q2Zv4aW6EtMgoysOL8CvRY2wMNFzbEzAMzcenpJbAsa8liV3sUZAghhJAqpN2xVzZbhujgaBTICzCm7RiMaz8OjmJHPMp5hB9O/YBXVr6ClstaIiouilvAkuiiIEMIIYRUkZKGfEcHR2P91fXwc/bDs8+fYce7O/B2q7ch5ouR8DwBkfGRaL60OTqs7IAfT/6IxzmPuXNGxkUiJj6mxOeLjIusiqpZjMlBZt++fTh+/Dh3f9myZWjfvj1GjBiBzMxMsxaOEEIIqU1KG/IdHRwNJauERCDBkJZDsO2dbUibmYZ1b65D/yb9wWf4uPD0Aj4/+Dl8fvZB8Npg/Hr+V0gVUoTHheuFGU1o4jP8qqxilTO5s+/MmTMxf/58AMC1a9fw2WefYcaMGThy5AhmzJiBNWvWmL2QhBBCSG1g6pBvR7EjxrQbgzHtxiA9Px3bbm7D5uubcfzhccQ/iEf8g3gIeAI0c22G8LhwyJQyxPSKMdjyU1uZHGSSk5PRqlUrAMCOHTvw+uuvY+7cubh48SJCQ0PNXkBCCCGEAO527vj41Y/x8asf42H2Q2y5vgXrrqzDzfSbuPNC3X/m22PfYt6JeVCoFFYRYoByBBmRSISCggIAwKFDhzBmzBgAgKurK3JycsxbOkIIIYQAAFiWRXJWMk4/Po0zj8/g9JPTSHyeqHecQqWAiC+yihADlCPIdOvWDTNmzEDXrl1x9uxZbN26FQBw584deHt7m72AhBBCiDXKlebiXMo5nH58mrulF6TrHedu645O3p1QIC/A4eTD3CreMfExVhFmTA4yS5cuxccff4zt27djxYoVqF+/PgBg79696N+/v9kLSAghhNR2KlaFW+m3XoaWJ6dxI+0GWOjOISPkCRFQNwCd6ndCJ2/1raFzQ3x79FuDq3gDxi23UJOZHGR8fHywe/duve0///yzWQpECCGE1BTlXc06PT8dZ56c4YLL2SdnkSvL1TvO18mXCyydvDuhvVd7SAQSvecxZhXv2qpCSxQUFRVBJpPpbHN0dKxQgQghhJCags/wubAQ1uXlWkk6k94pZbiSeoVraTn9+DSSMpP0zmUntMOr9V/lWlte834NXvZeZZbB1FW8axuTg0x+fj6+/PJL/Pnnn3j+/LnefqWydr9ghBBCiIZ2y4dSpUR7tj2+OPQFFp5diM7enbHv3j7MOTYHUqVU77Et3VrqtLa0cm8FAc/09oWKruJd05n8in3xxRc4cuQIVqxYgdGjR2PZsmV48uQJfv31V8ybN68yykgIIYRUW7ODZoMFi4i4CJ3tpx6f4r53tXFVB5Z/W1terf8qnCXOVVzS2snkIPPPP/9g/fr1CA4Oxvjx49G9e3c0adIEvr6+2LhxI0aOHFkZ5SSEEEKqrXdbv6sTZALrBuq0tjR2aQyGYSxYwtrL5CDz4sUL+Pn5AVD3h3nx4gUA9bDsjz76yLylI4QQQmqApWeX6twf3HywVVzWqQ5MXmvJz88PycnJAIAWLVrgzz//BKBuqXF2djZr4QghhJDqLiY+BsvOLQMAOAmcENEjwuDaR6RymBxkxo8fjytXrgAAwsLCsGzZMkgkEnz66aeYOXOm2QtICCGEVFc91/VEeFw4Jr86mdv2dbevER0cjfC4cPRc19OCpbMOJl9a+vTTT7nv+/Tpg9u3b+PChQto0qQJ2rZta9bCEUIIIdUaW8H9pMIqNI8MAPj6+sLX19ccZSGEEEJqlCPjjujMogsAc47PQdTRKKtZtNHSTL609Mknn2Dx4sV625cuXYrp06ebo0yEEEJIjTE7aDZ3aSlbkY2oo1GICIqgEFNFTA4yO3bsQNeuXfW2d+nSBdu3bzdLoQghhJCaZGYX3T6iP576EQM2DsD84/Nx+vFpyJVyC5Ws9jP50tLz58/h5OSkt93R0REZGRlmKRQhhBBSk6y/sh4AwIABCxZ5sjzsu7sP++7uA6BefqCbTzcENwxGkG8QOtTrACFfaMki1xomB5kmTZpg3759mDJlis72vXv3cvPLEEIIIdZC00cmokcEAnICcNHhIqKPRSO0SSjEAjHiH8TjReEL7L+3H/vv7QegDjZdfboi2DcYwQ2DKdhUgMlBZsaMGZgyZQrS09PRq1cvAMDhw4fx448/YuHChSada8WKFVixYgXu378PAGjdujXCw8MxYMAAAOpFKT/77DNs2bIFUqkUISEhWL58OTw9PU0tNiGEEGJ22otDhnUJQ2xsLL7p/g0EfAG3ffu723E97Tri7sch/kE84u/H43nhcxy4dwAH7h0AANgKbdG1QVcEN3wZbER8kYVrVzOYHGQmTJgAqVSKOXPmICZGPdlPw4YNsWLFCowZM8akc3l7e2PevHlo2rQpWJbFunXrMHjwYFy6dAmtW7fGp59+ij179mDbtm1wcnLClClTMGTIEJw4ccLUYhNCCCFmp73ytFz+sh+M9srTPIaHtp5t0dazLT557ROoWBVupN1A3P04xD2I44LNwaSDOJh0EABgI7DRabF5tf6rXLCJjIsEn+Eb7EwcEx8DJassdSHJ2qZcw68/+ugjfPTRR0hPT4eNjQ3s7e3L9eSDBg3SuT9nzhysWLECp0+fhre3N1avXo1NmzZxLT9r1qxBy5Ytcfr0aXTq1Klcz0kIIYSYS3lWnuYxPPh7+sPf0x9TX5sKFavCzfSb6mDzb6tNRkEGDiUdwqGkQwDUwaZLgy4IbhiMxzmPsfrSar3n0G4dsiblnkcmPT0dCQkJANRLFbi5uVWoIEqlEtu2bUN+fj46d+6MCxcuQC6Xo0+fPtwxLVq0gI+PD06dOkVBhhBCSK3AY3ho49EGbTzaYErHKVCxKtxKv8W12MTdj0NGQQYOJx/G4eTDAAABT33pKv5BPHYN34UfT/7IhRhrG/ZtcpDJz8/H1KlTsX79eqhUKgAAn8/HmDFjsGTJEtja2pp0vmvXrqFz584oKiqCvb09/vrrL7Rq1QqXL1+GSCTSW7/J09MTqampJZ5PKpVCKpVy93NycgAAcrlcp9mvOtKUr7qX05yssc6AddbbGusMWGe9rbHOgPnqzbIs7AX2aO3WGjYCGzRzaYa99/biUuol7hiFSgEAOJx8GI7fOULJKhHRIwJhXcKq9HWvzJ+1sedkWJY1aQLlSZMm4dChQ1i6dCk3n8zx48fxySefoG/fvlixYoVJBZXJZHj48CGys7Oxfft2/Pbbb4iPj8fly5cxfvx4nVACAB07dkTPnj0xf/58g+eLjIxEVFSU3vZNmzaZHLIIIYSQyiBVSZEmS0OqNBXPZM+QKk1Fqkz9/TPpM8hYWamPt+fbw1PkiaTCJLBgIWAE2N6uds3lVlBQgBEjRiA7OxuOjo4lHmdykHFzc8P27dsRHByss/3IkSN49913kZ6eXq4Ca/Tp0weNGzfGsGHD0Lt3b2RmZuq0yvj6+mL69Ok6az5pM9Qi06BBA2RkZJT6QlQHcrkcBw8eRN++fSEUWscwPGusM2Cd9bbGOgPWWW9rrDOgW2+BQIC0/DQkZyUjKSsJSZlJSM5KVt/PTEJKXkqp5+IxPPg4+sDPxQ+NnBuhkXMj+Ln4wc9Zfd/FxoVbCkHEF0GmlCGiRwS+7vZ1FdVWrTJ/1jk5OXBzcyszyJh8aamgoMDg8GcPDw8UFBSYejo9KpUKUqkUgYGBEAqFOHz4MIYOHQoASEhIwMOHD9G5c+cSHy8WiyEWi/W2C4XCGvMLVZPKai7WWGfAOuttjXUGrLPetb3OUoUUD7If4N6Le0jKTMLd53dxMukkvln7DZKzkpEvzy/18Q4iBzR2bQw/Fz80dlF/1Xzv4+RT6rwyMfExOus5aTr68nmGRzNVtsr4WRt7PpODTOfOnREREYH169dDIpEAAAoLCxEVFVVqwDBk1qxZGDBgAHx8fJCbm4tNmzYhLi4O+/fvh5OTEyZOnIgZM2bA1dUVjo6OmDp1Kjp37kwdfQkhhJSposOUWZbF88LnSMpUt6hoAktSlvr7xzmPwZayvDUDBt6O3uqw4vxvSHF9GVjq2NQBwzAm10t7dJKmbpqvmsUrranDr8lBZtGiRQgJCYG3tzfatWsHALhy5QokEgn2799v0rnS0tIwZswYPH36FE5OTmjbti3279+Pvn37AgB+/vln8Hg8DB06VGdCPEIIIaQsfIZv8INdOwjIlXI8zH6Ie5n3XgYWre9zpDmlPoed0I4LJo2cGqHgSQFe7/Y6mrs3h6+TL8QC/SsEFaU9d4027blrrInJQaZNmzZITEzExo0bcfv2bQDA8OHDMXLkSNjY2Jh0rtWrV5e6XyKRYNmyZVi2bJmpxSSEEGLltFspFCoF/D398euFX3Eo6RD8nP3w++XfERkfCRWrKvU89Rzq6V360XzvYefBtarI5XLExsaif+P+lXpJrTxz19Rm5ZpHxtbWFu+//765y0IIIYSYVfFLLhpJWUnc9xKBxGBIaezSGA2dG8JGaNof6aRqlSvIJCQkYMmSJbh16xYAoGXLlpgyZQpatGhh1sIRQgghFTU7aDaij0Zzc69oq2tfF2PajcHrzV5HJ+9OEPDKPU8ssRCeqQ/YsWMH2rRpgwsXLqBdu3Zo164dLl68CH9/f+zYsaMyykgIIYSUW0x8DBQqBbdWUa9GvdDZuzMYMHia9xTzT8xH9zXd4fG9B4bvGI4NVzYgPb9iU4mQqmNy9Pziiy8wa9YsREfrruUQERGBL774ghsqTQghhFha8RE+2vd3Dd+F/Xf3Y0/iHuy7uw+ZRZnYcn0LtlzfAgYMOtbviIFNByK0aSgC6gaAx5j8tz+pAiYHmadPnxpc5XrUqFH4/vvvzVIoQgghpKKMHaY8su1IKFQKnHl8BrGJsYi9G4vLqZdx5skZnHlyBuFx4fCy98KAJgMQ2jQUff36wkniBIBWoq4OTA4ywcHBOHbsGJo0aaKz/fjx4+jevbvZCkYIIYRUhCnDlAU8Abr6dEVXn66Y03sOnuQ8wd67e7EncQ8O3juI1LxUrLm8Bmsur4GAJ0A3n24Y2HQgnhc+x9KzSwEAYV3CuPNZ60rUlmBykHnjjTfw5Zdf4sKFC9zEdKdPn8a2bdsQFRWFXbt26RxLCCGEWEJFhinXd6yP/7zyH/znlf9AqpDi+MPj2JO4B7GJsUh4nqBemfp+HADAWeKM8Lhw3Eq/hTf5b3JLB1jjStSWYHKQ+fjjjwEAy5cv15ucTrMPABiGgVJpXZPyEEIIqX3EAjF6+/VGb7/e+CnkJ9x7cY+7BHUk+QiyirIAAJtvbMZmbAYAjPIfhbBuYaWclZiLyT2XVCqVUTcKMYQQQmqjxq6NMfW1qdg7ci+ef/Ec/wz/Bx8GfqhzzB/X/kC9n+rho90f4eiDo2VOukfKr0JdsIuKisxVDkIIIaTGsRPZ4fVmr6OeQz0A6mURAPXSBRkFGfjlwi8IWhsE34W+mHlgJi4+vQiWLXl9JmI6k4OMUqlETEwM6tevD3t7eyQlqWdHnD17dplLDhBCCCG1jaZjb0SPCOxotwMRPSKQL8/HmLZjMK79ODiKHfE45zF+OPUDAlcGouWyloiKi8Kd53csXfRaweQgM2fOHKxduxYLFiyASCTitrdp0wa//fabWQtHCCGEVGfao5O+7vY1AODrbl8jOjga66+uh5+zH559/gw7392Jt1u9DYlAgoTnCYiMj0Tzpc0RuDIQP578EY9zHgNQD+eOiY8p8bki4yKrqmo1hsmdfdevX4+VK1eid+/e+PDDl9cE27Vrxy0iSQghhFgD7SHecrmc2649xFsikOCtlm/hrZZvIUeag//e/i82Xd+Eg/cO4uLTi7j49CJmHpyJ7r7d4SR2wj93/tE5B0DDuUtjcpB58uSJ3hwygLoTsPYPkRBCCKntTB3i7Sh2xOh2ozG63Wik56dj+83t2Hx9M449PIajD44CAHgMD+Fx4bjy7ArWDF6DhacX6k3sR14yOci0atUKx44dg6+vr8727du3IyAgwGwFI4QQQmozdzt3fPTqR/jo1Y/wMPshtl7fis3XN+NS6iUAwI5bO7DjlnoNQwoxJTM5yISHh2Ps2LF48uQJVCoVdu7ciYSEBKxfvx67d++ujDISQgghtZqPkw9mdp2JmV1n4nbGbfx48kf8dknd71TIE1KIKYXJnX0HDx6Mf/75B4cOHYKdnR3Cw8Nx69Yt/PPPP+jbt29llJEQQgixGi3cWuDko5MAAAYM5Cp5iR2ASTlaZACge/fuOHjwoLnLQgghhFi9if+diJsZN8GAwZUPr+Dv23/rLHJJdJUryBBCCCGk4oqvnh0VF4XfL/8OAOhQrwN23NrBdSimMGMYBRlCCCHEQvgMXyegXHh6AQAg5otxLuUcBjUbxO0DdFfsJmoUZAghhBAL0QSU8LhwSJVSnHlyBgAgVUr1RipRS4xhFGQIIYQQC9IOMxqDmg3C0FZDoWJV4DEVWhax1iv3qyOTyZCQkACFQmHO8hBCCCFWZ3bQbJ3A8s+df9B6eWu4zHdBvw39MPt/s7Hnzh5kFGRYsJTVk8ktMgUFBZg6dSrWrVsHALhz5w78/PwwdepU1K9fH2FhYWYvJCGEEFKbxcTHQMWqIOAJoFAp0NCpIdIK0pAjzcHBpIM4mPRypHAT1ybo5N0Jr9V/DZ28O6GtZ1uI+KJSzl67mdwiM2vWLFy5cgVxcXGQSCTc9j59+mDr1q1mLRwhhBBS22mvoySfLUd0cDTuZ9/HF12+wKVJl/DLwF8wrv04tHBrAQC4++Iu/rj6B6bunYpXV70Kp3lO6PZ7N3x+4HNsu7ENj7IfgWVZC9eq6pjcIvP3339j69at6NSpExiG4ba3bt0a9+7dM2vhCCGEkNpMO8Ro+spo95nhMTzMDpqNSR0mAQAyCzNx9slZnHlyBqcfn8bpx6eRWZSJE49O4MSjE9x56znU02m1CawbCDuRncEyFB8CXrx8SlZZ6ppSlmZykElPT4eHh4fe9vz8fJ1gQwghhJDSaa+era2k4dYuNi4IaRKCkCYhAACWZZH4IhGnH5/GmcdncPrJaVxJvYKU3BTsvLUTO2/tBKAe5t3Ws61OuGlapyl4DE9vCLhGTVlx2+Qg06FDB+zZswdTp04FAC68/Pbbb+jcubN5S0cIIYTUYqaunl0cwzBoVqcZmtVphjHtxgAACuQFuJByQd1i80TdapOSm4JLqZdwKfUSVpxfAQBwkbjgNe/X0Kl+J4xuO1onzBhqKaquTA4yc+fOxYABA3Dz5k0oFAosWrQIN2/exMmTJxEfH18ZZSSEEEKIkWyFtuju2x3dfbtz2x7nPOYuRZ1+fBoXnl5AZlEm9t3dh31393HHhceFIyo+qsSWourI5CDTrVs3XL58GfPmzYO/vz8OHDiAV155BadOnYK/v39llJEQQgghFeDt6I23W72Nt1u9DQCQK+W4+uyqTqvN3Rd3AagvZ4n4ohoRYoByTojXuHFjrFq1ytxlIYQQQkgVEPKFCKwXiMB6gZiMyVCxKtT/qT5S81LBY3iQKWWIiY+pEWHGqCCTk5Nj9AkdHR3LXRhCCCGEVL2hW4ciNS8VYr4YDz99iF/P/1pjFqk0Ksg4OzsbPSJJqaQFrQghhJDqqvhw62/+9w3+TvgbABDUMAjLzy2vUStuGxVkjhw5wn1///59hIWFYdy4cdwopVOnTmHdunX47rvvKqeUhBBCCDGL4sOt4++rB+q42rjiwL0D6NagG7cPqP4rbhsVZIKCgrjvo6Oj8dNPP2H48OHctjfeeAP+/v5YuXIlxo4da/5SEkIIIcQstCfcyyzKxLmUcwCAF4UvauSK2yZ39j116hR++eUXve0dOnTAf/7zH7MUihBCCCH6VKwKMqUMUoUUUqUUUoVUff/f70vaVvwxPIaHIN8g/Hz6Z+7cUcFRNSK4FGdykGnQoAFWrVqFBQsW6Gz/7bff0KBBA7MVjBBCCLEUlmXLDAPF9+dL83H+xXmkXEqBglWU/phyhhCFSlEp9RXyhAgPCq+Uc1c2k4PMzz//jKFDh2Lv3r147bXXAABnz55FYmIiduzYYfYCEkIIqb1YloVcJTepNcGYUKGzvxznkKvk5a/UQ/O9PmUR8UUQ8UUQ88UQC8QQ88Xq+/9+LxaI9faLBWKIeCJcTbuKs0/OQsATQK6S15jh1sWZHGRCQ0ORmJiIFStW4NatWwCAQYMG4cMPP6QWGUIIqaZYloVCpSh/GCjrMVr3i+RFePLsCb5f/z3krLzUc8iUMku/NEYR8oRlBgQRT4TsF9moX7c+bIQ2L0OFCSGj+P7SHiPii8q9xmFMfAx+u/Qb1ydGsyQBUDP6xWgr14R43t7emDNnjrnLQgghNR7LslCySu6DOq8oD2myNNx5fgcqRmVUgChPC0NZ55ApZWDBVu2LkWf6QwQ8Qfk+3HmmBQSDrRQlPEbEF4HH8Mosu1wuR2xsLEJDQyEUCsvxglWNslbc1r5fE5QryBBCLK/4XBDaYuJjoGSVpS5IVxsoVcoKtTCU+uFfgXMYDAw3q/71KQ2f4Zf/w72MgCCAADev38Rrga/BVmRrUgsDn8e39EtT65m64nZ1R0GGkBqq+FwQGtp/bZmLilVVKCDIlDIUyApwLfUazsSfgYJVmNzCYGh/TfgPlwEDISOEjcimXJcPKqOFQcwXV2pgkMvliH0Si9AW1btlwlpVdMXt6oaCDCE1lHZTsFQpRVPXpvjzxp+IvRuL3o16Q66SI+xQmOH+CSaGELOOlEg136mKK+uDvLwtDKYEhOL7WSVbIy43EFJTUZAhpAYrfl1b43DyYRxOPmyJIumwF9nDUewIJ7ETHEQOkOXK0Lh+Y7jYuMBR7AhHsWP5WikM7BfwBOXu+FiZ5MoKjH4hhJSp3EEmPT0dCQkJAIDmzZvD3d3dbIUihBhvdtBsxByNgVwlBwMGPXx7oEhRVOJNqpRWWdnyZHnIk+UhJTeF23b59mWdYyQCiWk3vonHl3KryKgPQkj1YHKQyc/Px9SpU7FhwwZugUg+n48xY8ZgyZIlsLW1NXshCSEli4lXhxgRXwSZUobejXqXep1bMzNoaWGnIjepUlrivgJpAWSs7nBbzT5LEfPFZgtGhm4CCJBUkITbGbfhYOOgs0/MF1OQIqSCTA4yM2bMQHx8PHbt2oWuXbsCAI4fP45PPvkEn332GVasWGH2QhJCDCs+jNKYuSB4DI/7IK1KmqGpAwYMAMtjzReelKWEKoV+qCpUFOqUS9PZOFuaXbkvwB3Dmw0FKbGglHBlxhYpsUBs1LBiQqozk4PMjh07sH37dgQHB3PbQkNDYWNjg3fffZeCDCFVpKbOBcEwDEQCdd8WJzhV+fNrZpKtrBYpQ7fs/GxAoG59KpQX6gzPrrIgVQIRX2R88DGy9UoAAa7lXIPNfRvYS+xLPV9tG269+elmXDp+CZE9I/X2Wcu0CFXN5CBTUFAAT09Pve0eHh4oKCgwS6EIIWWrbXNBVBWGYbhp3R3FjpX+fMUnSdPMsGvWsFRKq5Shm4pVceWTKWWQKWXIkeaYv/JJZR8i5AnN07pUzkuE5g5SPIaHqKNR4PP4lT4tAlEzOch07twZERERWL9+PSQSddN0YWEhoqKi0LlzZ7MXkBBiWG2bC8JaMAwDIV8IIV8IB7GDRcpg9iBV/PKdvBDPnj+D2E6s12eqUFGoE6TkKjnkMjlyZbkWeS0EPIFp4aeUS3tCRggvkRfeafkOwuPCkZSZhO/7fY8V51botZ4S8zE5yCxcuBD9+/eHt7c32rVrBwC4cuUKJBIJ9u/fb/YCEkIIMS8BTwB7kT3sRfaVcv6ypurXBClDfZiqokVKe14khUrBja4zt7VX1mLtlbUAQCGmEpkcZPz9/ZGYmIiNGzfi9u3bAIDhw4dj5MiRsLGxMXsBCSGE1C6VHaTKolAp9EJUaaPtjL0VyAvwOPUxHJwdcDblLLcgpogvohBTiUwKMnK5HC1atMDu3bvx/vvvV1aZCCGEkEoj4AkgEAlgJ7Iz63k1LVF12tVB93XdAaj7AMmUMsTEx1CYqSQmjbsTCoUoKrLcfA+EEEJIdaZiVXhv53sAgACvAMhmyxAdHI3wuHDExMdYuHS1k8mXliZPnoz58+fjt99+g0BAKxwQQgixXsVXof/+/vd4kvsEIr4Iffz6IDIukuuYX52nRajJTE4i586dw+HDh3HgwAH4+/vDzk63aW7nzp1mKxwhhBBSnWmvQj+1w1Rczr0MAOjh2wPfn/yeG25N0yJUHpODjLOzM4YOHVoZZSGEEEJqlNlBs6FklQiPC8eBewdQqCqEs8QZh5IO6Y1UopaYymFykFmzZk1llIMQQgipMBWrQqG8EIWKQqO/aua+0dlnwuM0rSzHHx0HAGQVZdFw6ypUrk4uCoUCcXFxuHfvHkaMGAEHBwekpKTA0dER9vaWGU5HCCGkemFZ1nBIKOWrZtK88gYLzZBnS6Lh1lXL5CDz4MED9O/fHw8fPoRUKkXfvn3h4OCA+fPnQyqV4pdffqmMchJCCKkguVJuUktFRYJFvjQf8stynXWlqpqQJ4SN0AY2Apuyv/77vUQgMe74Yl9/Pv0zYo7GQMAIaLh1FTM5yEybNg0dOnTAlStXUKdOHW77W2+9RXPLEEKIkcpzCcRgsDDhcZbsaMpjeKYFhAoGi8pYR6kkMfExiDkag4geEQjICcAlx0s0QqkKmRxkjh07hpMnT0IkEulsb9iwIZ48eWLSub777jvs3LkTt2/fho2NDbp06YL58+ejefPm3DFFRUX47LPPsGXLFkilUoSEhGD58uUGF64khFRM8aGk2mrzyr0sy0KqlFZK34oCeQHSM9MhSBbo7Jer5Bats9EBoVg4MCZICCDA6WOnEdo3FI62jup1iHhCMAxj0TpXBu3FIMO6hCE2NhZfd/safB6fwkwVMTnIqFQqKJX6qf7x48dwcDBtAbT4+HhMnjwZr776KhQKBb766iv069cPN2/e5IZ1f/rpp9izZw+2bdsGJycnTJkyBUOGDMGJEydMLTohpAzaQ0kttXKvZnVoU1sqKtpps9JJS95VnksgpgSL4l/FfHGlhgq5XI5kcTI87T0NrrVUm2ivQi+XvwynNNy66pgcZPr164eFCxdi5cqVANQruebl5SEiIgKhoaEmnWvfvn0699euXQsPDw9cuHABPXr0QHZ2NlavXo1NmzahV69eANSjplq2bInTp0+jU6dOphafEFIKzX++2mEmKi4KkfGRCOsahnHtx+HO8zvlChb5snwkP0rGr1t/RZGyhH4X/37VXh25qpX3EkhJwULICHH1wlUEdwuGg8TBopdAiPnRKvSWZ3KQ+fHHHxESEoJWrVqhqKgII0aMQGJiItzc3LB58+YKFSY7OxsA4OrqCgC4cOEC5HI5+vTpwx3TokUL+Pj44NSpUwaDjFQqhVT68k+fnJwcAOq/ELTTcnWkKV91L6c5WWOdgepd77AuYVAoFQiPC+cCDQDMOzEP807Mq/gTZJt2OHcJpHifiZL6UPwbDrRDhaFjDJ3LRmADAU9g1tYKuVwO9g6LVzxeMdg6oVKqoFJaLrhVhur8/q5M1ljvyqyzsedkWJY1uUu5QqHAli1bcPXqVeTl5eGVV16p8OrXKpUKb7zxBrKysnD8uHos/qZNmzB+/HidYAIAHTt2RM+ePTF//ny980RGRiIqKkpv+6ZNm2Bra1vu8hFiTWQqGd69+q5Fy8AHH7Z8W4h4IogYEYQ84cuvhrZpfS1rv/ZxQkao97U29uUgpKYpKCjAiBEjkJ2dDUdHxxKPK9c8MgKBAKNGjSp34QyZPHkyrl+/zoWY8po1axZmzJjB3c/JyUGDBg3Qr1+/Ul+I6kAul+PgwYPo27dvrb+urGGNdQaqf73nHJ8DQN13Q66S4z/t/4P3Wr+HImURihSl3JRFkCqk3H3N5SWpQt2R9tmLZxDbiSFVSrnjNMcU7/yqhBK5ylzAAl0MxHwx11ojEUggFoi5Vh4JX8Jt02794Y7jS3S2CRkh7ty8g44BHWEnsdN5vPZzaG4CXs1fw666v78rizXWuzLrrLmiUpZy/cakpKTg+PHjSEtLg0ql2yT6ySefmHy+KVOmYPfu3Th69Ci8vb257V5eXpDJZMjKyoKzszO3/dmzZ/Dy8jJ4LrFYDLFYrLddKBTWmDdWTSqruVhjnYHqWe+Y+BhEHY3iOjBqOvr6OPtU6Jq/XC5HbGwsQkNDDdZZqVJCqpTqhSPN0OGSbpogVJFjCuWFOvOdSJVSSJVSZEtNvA5WmvvGHcZn+DrBRnOJrPi24sGq1GMMBKaSbuZsjaqO7++qYI31row6G3s+k4PM2rVrMWnSJIhEItSpU0fnTc8wjElBhmVZTJ06FX/99Rfi4uLQqFEjnf2BgYEQCoU4fPgwt75TQkICHj58iM6dO5tadEJIGbRHJ2lCi6EOwJWBz+PDlmcLW2HVXwJmWRZylbzMsFOesFQoL8STZ09g62RrMKgVn41WySqRL89Hvjy/yl8H4GVrVImBqHhg4uvvFzJCJGYk4vm157AX2xsdqszdP6kmstYpECrC5CAze/ZshIeHY9asWeDxeBV68smTJ2PTpk3473//CwcHB6SmpgIAnJycYGNjAycnJ0ycOBEzZsyAq6srHB0dMXXqVHTu3JlGLBFSCbSHkmqr7UNJGYaBiC+CiC+Co9i8l6DLaokC1JPjSRVSo1qOKtz6VGx/pbZGPTbtcB7DM7r1yEZooxeiTGrJKvY8YoEYPKZin2nmUB2mQKhpTA4yBQUFeO+99yocYgBgxYoVAIDg4GCd7WvWrMG4ceMAAD///DN4PB6GDh2qMyEeIcT8aCipZfAYnnrUlLD8AybKSzNvj6mX4krrJ5UvzceDJw/g7OZcYiuUobWRVKwKBfICFMgLqvx1ANRrJJXnkpzmGCFPiKT0JDy5+AR2YjujA5X2hIGGWkANtZSSl0wOMhMnTsS2bdsQFhZW4Sc3ZsCURCLBsmXLsGzZsgo/HyGEEF0Mw0DIF0LIF8JBbNqkpiUxphVKQ9MaVa6+T4YCldLIwPXvc2jPWSRTyiBTypAjNa6TaUlWP1lt8mM0rVGam4vEBeFx4YiIiwALlkJMKUwOMt999x1ef/117Nu3D/7+/npv0p9++slshSOEEFK7VbfWqPJ0FNd8XyAvQPLDZLh4uECmkpUaqAoVhUa1RrFgIeAJKMSUolxBZv/+/dx6SMU7+xJCCCE1gblbo0pqiWJZFkmZSbiUegkXn17kvqblpxk8T2OXxpAIJLiRfoObAoFW0y5ZuWb2/f3337k+LIQQQghRU7JK3Ei/gesZ17nQcunpJYOdp3kMDy3dWuKVuq/glbqvIMArAO292mPxmcU6fWI0fWQA6qtmiMlBRiwWo2vXrpVRFkIIIaTKVHSos1QhxfW061wLy4WUC7j89DJkV2R6x4r4IrT1bIsArwAutPh7+utNN2DJKRBqKpODzLRp07BkyRIsXry4MspDCCGEVAlThjrnyfJwJfUKF1ouPr2IG+k3oFAp9M5rJ7RDQN0AndDSyr0VhPyyJ3iz1ikQKsLkIHP27Fn873//w+7du9G6dWu9zr47d+40W+EIIYSQylLaUOdx7cbBRmiDETtG4OLTi7jz/I7OfDsarjauXFhp694WOQk5mPjWRIhF+jPMG4OmQDCdyUHG2dkZQ4YMqYyyEEIIIVVKO8xExkdyw7HXXlmrd2w9h3pcaNF89XHy4Qa6yOVyxD6IrRYT61kTk4PMmjVrKqMchBBCiEUE1gsEAJ05Zfxc/PRCi6e9p6WKSEpR85dZJYQQQsrpl/O/4OM9HwMAGDBgweKrbl9hTu85Fi4ZMZbJQaZRo0alzheTlJRUoQIRQgghlU3FqvDV4a8w/8R8AECAVwDO/OcM5h2fh/C4cEgEEuqTUkOYHGSmT5+uc18ul+PSpUvYt28fZs6caa5yEUIIIZWiSFGE8f8djy3XtwAAejXshUNjDpW41hGp3so1/NqQZcuW4fz58xUuECGEEGIOhuaJeVH4AoO3DMbxh8cBAENaDMGOYTt0HkdDnWsWs3WtHjBgAHbs2FH2gYQQQkgV0MwTExMfAwBIykxCl9VduBAzrt04vRCjMTtodqlDoUn1YbbOvtu3b4erq6u5TkcIIYRUiPZlolsZt3Ao6RDSC9IBAJNfnYyloUstWTxiJiYHmYCAAJ3OvizLIjU1Fenp6Vi+fLlZC0cIIYSUh1KlxNEHR/Eo5xEkAgk2X9/M7fu8y+f4vu/3FiwdMSeTg8ybb76pc5/H48Hd3R3BwcFo0aKFucpFCCGEmIRlWZxPOY/N1zdj642tSMlN0TtGxBdRiKllTA4yERERlVEOQgghpFxupd/C5uubsfn6Ztx9cZfb7ixxxtCWQ6FUKbH2ylqI+CLIlDLExMfQaKRahCbEI4QQUuM8zH6ILde3YNO1Tbjy7Aq33UZggzeav4ER/iMQ0jgEC04s0FlNWrOWEkBDq2sLo4MMj8crdSI8AGAYBgqF/kqghBBCSFkMDZfWiImPQY40B41cGmHz9c3cyCMAEPAE6N+kP4a3GY43mr8Be5E99xjtEAMYXiiS1GxGB5m//vqrxH2nTp3C4sWLoVKpSjyGEEIIKY1muDTwMmDkSHMw/u/x2Hl7J7eEAKBeTiCoYRCGtxmOoS2Hoo5tHb3zKVmlTojRoHliahejg8zgwYP1tiUkJCAsLAz//PMPRo4ciejoaLMWjhBCiPXQbi25++Iu8uX5+G/Cf6FQqVv6WbDoUK8DhrcZjmGth6G+Y/1Sz1faPDDUElN7lKuPTEpKCiIiIrBu3TqEhITg8uXLaNOmjbnLRgghxMrMDpqNF4UvsPDMQr19fi5+eMXrFciVcpx8dBKNXRvDz8UPzhLnKi8nqT5MCjLZ2dmYO3culixZgvbt2+Pw4cPo3r17ZZWNEEKIFZrbey4Wn10MFavbXSEpMwkrM1fqHe9q4wo/Fz/4ufihsUtjne+9Hb3B5/GrqujEAowOMgsWLMD8+fPh5eWFzZs3G7zURAghhFTUDyd/gIpVccOlP+/yOQY3H4x7L+4hKTMJSVlJ3PfP8p/hReELvCh8gfMp+uv9CXlC+Dr76gUczfcOYgcL1JCYk9FBJiwsDDY2NmjSpAnWrVuHdevWGTxu586dZiscIYQQ61J8pJHmvqPI0WC/lnxZvjrcZCbhXuY9ne/vZ92HTCnD3Rd3deaX0eZu6264Nce1Meo51AOPMduShKSSGB1kxowZU+bwa0IIIaS8yjNc2k5kB39Pf/h7+uudT6lSIiU3RS/gaL7PKMhAekE60gvScebJGb3Hi/liNHJppA43zn5cnxzNzVZoW2adyhpSrmSVtDhlBRkdZNauXVuJxSCEEGLtzD1cms/jo4FTAzRwaoDghsF6+7OLspGclawOOP9eqtIEnQfZDyBVSnE74zZuZ9w2eH4vey+dlhwfRx+k5aUhIC8ADZwbgGEYg0PKAd3QRiqGZvYlhBBSLVT1cGkniRPae7VHe6/2evsUKgUeZT8q8bJVVlEWUvNSkZqXipOPTuo8dtbiWbAR2HAtN528OyE8LhwJzxOwqP8iLD+3XK/liZQfBRlCCCGkGAFPgEYujdDIpRF6o7fe/szCTJ2Ac+/FPdx7cQ83nt5AhjwDhYpC3Ei/gRvpN7jHbLy2ERuvbQQACjFmREGGEEIIMZGLjQsCbQIRWC+Q23b/xX0s/u9iZDhl4K+Ev5AnyzP4WBFfRCHGjCjIEEIIIeXwOOcx4u7HIf5+POIexOmNjOIxPAR4BSC4YTCe5j7FpuubaAXuSkBBhhBCCDHCo+xHiH8Qj7j7cYi7H4d7mfd09vMYHvwkfhjUdhB6+fVCN59ucJY4IyY+Bj+e+pFW4K4kFGQIIYRYBVOHQj/KfsSFlrgHcUjKTNJ5DI/hIbBuIIJ8gxDcMBiv1X0NJ/53AqG9QyEUCrnz0grclYuCDCGEEKtQ1lDoGZ1nYP2V9erLRQ/iSwwuwQ2DEdwwGF0bdIWTxInbL5fL9Z6TVuCufBRkCCGEWIXiLSFj2o3Bp/s/xV+3/4KzxBk/nfpJ53g+w0dgvUAE+/4bXHy6wlHsaNJz0grclY+CDCGEEKuhHWY0gQYAsoqyuO99nHwwuu1ovNfmPTSv0xxCvrCqi0lMQEGGEEKIVZkdNBvRR6OhUCkM7n+Y/RBzjs3BnGNzwGN4qOdQDz5OPvBx8kEDxwbc95r7rjautISPBVGQIYQQYlVi4mOgUCm4odCj245Gd5/ueJj9EA9zHuJh9kM8yn6ERzmPIFPK8DjnMR7nPNabwVfDVmirDjUODcBms7h47CIauTbiwo63ozckAkkV19J6UJAhhBBiNUpaXbupa1PE9IrROVbFqpCWn8YFm4fZD/XCzrP8ZyiQF+isyXTo2CG95/Ww8yi1VcfT3pNW2i4nCjKEEEKsgqlDoXkMD172XvCy90LH+h0NnrNIUYTHOY/xMPshkl8k4/D5w7DxssHj3Mdc8CmQFyAtPw1p+Wk4n3Le4HmEPCEaODUwGHQ02xzEDuWqd21fgZuCDCGEEKtQGUOhJQIJmrg2QRPXJpB7y+H22A2hoS/nkWFZFplFmVyo4Vp2tFp1nuQ+gVwl5xalLImzxLnUVp16DvUMdkyu7StwU5AhhBBiFSwxFJphGLjauMLVxtXgKtuAeqXtlNyUUsNOZlEmsoqykFWUhavPrho8T0kdk9t5tcNHHT5CeFw4WLAIDwo32DpVU1GQIYQQQixIwBNw4aMkudJcPMp5pBt2/g06D7Mf4nHOY6M6JkfERSAqPgoqVlUrQgxAQYYQQgip9hzEDmjl3gqt3FsZ3K/dMbmkVp1n+c+4Y4U8Ya0IMQAFGUIIIaTGM6ZjcsSRCEQfVfeHkavkiIqLQkRwRFUWs1LQWC9CCCGklouJj0H00WjM6jYLdWzqAAAi4yMREx9TxiOrPwoyhBBCSC2m3bF3bu+5eK3+awAAG4ENwuPCdcJMTHwMIuMiLVTS8qEgQwghhNRixYeday49FSoK0cm7EzfsXBN4+AzfYmUtD+ojQwghhNRixYedRwRHIDkrGeuurMPZJ2exZvCaGj0cm4IMIYQQYmXWvrkWpx+fRsLzBLRe3rpGD8emS0uEEEKIFZr22jQA6uHYIr6oRoYYgIIMIYQQYnXyZHn44tAXANRLGMiUsho7gomCDCGEEGJlXt/0OvJkeXCRuCD/q3xEB0frjWCqKaiPDCGEEFKLFV/9+rP9nyH+QTwAIKRxCL47/h3XIdjQ4pLVHQUZQgghpBYrvvr1vnv7AACNnBthy40t3OrXFVkF3JIoyBBCCCG1mCaghMeF40H2A9xMvwkGDJKzkvVGKtWklhgNCjKEEEJILaRQKfA09ykeZj9E0zpN0devL1ZfWg0AYMHW2OHWxVGQIYQQQmoYlmWRVZT1crXrnEfc95r7T3KelHiZqCYPty6OggwhhBBSzUgVUjzOeVxiSHmY/RB5srwyzyPgCeDt6A0fJx9kFWbhatpVCHlCbrh1bQgzFGQIIYSQKsSyLNLy0wyGFM221LxUo87lZusGHycf+Dj5oIFjA+57zX0vey/weXy9JQg094Ga2S9Gm0WDzNGjR/H999/jwoULePr0Kf766y+8+eab3H6WZREREYFVq1YhKysLXbt2xYoVK9C0aVPLFZoQQggpRZ4sD6lZqSW2pjzKfgSpUlrmeSQCyctg4uiDBk66QcXb0Ru2Qtsyz2NoHSXtDsDa902hVALx8QyOHq0POzsGPXsCfAusN2nRIJOfn4927dphwoQJGDJkiN7+BQsWYPHixVi3bh0aNWqE2bNnIyQkBDdv3oREIrFAiQkhhNRUxedT0RYTHwMlq9RbYLE47Q60hlpTkjKSkHs5t8yyMGBQ16Fuqa0pbrZuYBimvNXlFF/9WqMiw6137gSmTQMePxYA6ICffgK8vYFFiwADH+eVyqJBZsCAARgwYIDBfSzLYuHChfjmm28wePBgAMD69evh6emJv//+G++9915VFpUQQkgNV3w+FQ1Ni0VUcBQyCzNL7ZdSWgdabY5ix1JbU+o51IOIL6q0umorLZyVpyVm507g7bcBltXd/uSJevv27VUbZqptH5nk5GSkpqaiT58+3DYnJye89tprOHXqFAUZQgghJtG+nJIry4WLxAU7bu3AhacX4G7rju9Pfo+IuIgyz6PdgVY7qNSzq4f7V+5jxMARcHNwq+zqWIRSqW6JKR5iAPU2hgGmTwcGD666y0zVNsikpqo7Onl6eups9/T05PYZIpVKIZW+vPaYk5MDAJDL5ZDL5ZVQUvPRlK+6l9OcrLHOgHXW2xrrDFhnvatzncO6hEGpUiLqaJTO9vSCdO57d1t3eDt6qy/3/BtSvB28uUs+nnae4PP0P6XlcjkO3jkIW75ttay7OcTHM/9eTjKMZYFHj4AjRxQICjKQdkxg7GtYbYNMeX333XeIiorS237gwAHY2pbdKao6OHjwoKWLUOWssc6AddbbGusMWGe9q2udAxAAPvhQQn2J6B3Pd9DGvg3chG5wE7lBzBO/PFgB4Ln69vzff2WprvU2h6NH6wPoUOZxe/deRn7+kwo9V0FBgVHHVdsg4+XlBQB49uwZ6taty21/9uwZ2rdvX+LjZs2ahRkzZnD3c3Jy0KBBA/Tr1w+Ojo6VVl5zkMvlOHjwIPr27QuhUGjp4lQJa6wzYJ31tsY6A9ZZ7+pe5znH50AJJRgwYMHimuIaNg7bWOHzVvd6m4OdHYOffir7uAED2iMoqF2FnktzRaUs1TbINGrUCF5eXjh8+DAXXHJycnDmzBl89NFHJT5OLBZDLBbrbRcKhTXmjVWTymou1lhnwDrrbY11Bqyz3tWxzjHxMYg6GoXo4Gi82eJNtPulHW4/v41JsZPw++DfzfIc1bHe5qBUqvvAuLoCL14YPoZh1KOXevYUVLiPjLGvIa9iT1MxeXl5uHz5Mi5fvgxA3cH38uXLePjwIRiGwfTp0/Htt99i165duHbtGsaMGYN69erpzDVDCCGEGKP4fCo7bu1Ah3rqyyRrLq9BVFyUzrGRcZEWKmn1s3Mn0LAh0KdP6SEGABYurNr5ZCwaZM6fP4+AgAAEBAQAAGbMmIGAgACEh6uHx33xxReYOnUqPvjgA7z66qvIy8vDvn37aA4ZQgghJis+nwqf4eNcyjlIBOrPlPMp5wG8DDx8xgKzu1VDmuHWjx+Xfpy3d9UPvQYsfGkpODgYrKExXP9iGAbR0dGIjo6uwlIRQgipjYrPp1J8dtszT85g1qFZmHdiXq1ZGbqiShturcbCwUGG7dv56N274peTysOiLTKEEEKIJc0Omo2IIPXcMekF6Zh3Yh5aubdCa4/WKFIUWbh0lrdlS1ktMQxyc8Xg8SyzPAFAQYYQQoiViwyOhJD3smPpzfSbGPrnUHj+4Inx/x2PA/cOQKFSWLCEVePPP4HRo4HY2Jfbnj0z7rFPn1ZOmYxBQYYQQohVi4mPgVwl55YM6NqgK7wdvZEjzcHay2sR8kcI6v9UH1Nip+Dko5OldomoCXJzge++A8aO1b1kdPQo8McfwP/+93JbKbOd6NCaJaXKUZAhhBBitbRHMkm/kSI6OBonHp3A+6+8j6PjjuLDwA9Rx6YO0vLTsOzcMnT9vSsaLWqEsENhuJJ6pdJCjVIJxMUBmzervypNX9cRAHDhAhARob5EpCEUAuHhwPr16ll4Nd56C4iOBoYOfbktKEjdibektSsZhoWbWwG6dbNcuKMgQwghxCoVH44NqPvMRAdHIyIuAnH347Di9RV4+tlTxI6Ixei2o2EvsseD7AeYf2I+2v/aHm1WtMG3R7/FvRf3AACbn27GnONzSnw+Y4Z0a4Y69+wJjBih/tqwoXp7SVgW2LoV+PJLIDPz5fZjx9ThRDvISCTAjBnAggWAjc3L7b17A7NnA507v9zG56tXtAb0w4zm/sSJ1y3WPwaoxhPiEUIIIZWp+HBsDc19zSrXQr4QA5oOwICmA1AgL8CeO3uw+fpm7Encg5vpNzH7yGzMPjIbr9Z7FcoCJbYe3Qo+j29whe3o4NJH4RqzsnTnzsD+/YBAAIwapd7PMMCsWUByMhASAvTqpd7evTswbpw6DGmbP9/412nIEPXzTpum2/HX2xv44QclxOKnAAKMP6GZUZAhhBBilYoPx9ZW0tBrW6Et3mn9Dt5p/Q6yirLw162/sPn6ZhxOPoxzKee448LjwnHh6QWse3MdFp9ZrNfyY4ixK0svWQKMHw+0bv0yyADA8OHq1hg3rYW3AwOBNWtKfEqjDRmiXtH62DF1x966ddUhSaVidToHWwIFGUIIIbUCy7JQqBQoUhShSFGEQkXhy+/lL78vvq+s/cYcq2JVeuX5b8J/4TLfBSxYo+alOXas9KHOmpWlX7xQ91159dWXAQcA5hi+omU2fD4QHKy7TaVf7SpHQYYQQohZyZVyFCoLkZ6fDiWjLDUIVEWgsAQxXwypUgoWLER8kVGT6xk7hHnGDN1+MI8fA56e6k681oiCDCGE1EIKlcKkVohSQ4KyjIBRbJ+mbwmuWfY1EPPFkAgkkAgksBHacN9LBBLYCMq4r3V8afu09/NZPuIOx2HwwMFYcGoBwuPCIeKLIFPKEBMfU2aYMXYIc9u2uvffeAO4dQvYs+dl3xiVCuBZyXAeCjKEEFJJFCoF8mR5yFHk4FHOIyihNL0VQrNPadolEi5MWJh2mCgrUBgbGIzZLxaIwWOq9pNcLpdDzBPjuxPfcStszw6azXX0BUruewOo+5x4e6s79hrqJ6NZWfrAAe3nVF9uKioCmjV7uX3DBuCbb4AJE4CoKP1zGUOp1O8TY8nRSSWhIENILRYZFwk+wzf4n2dMfAyUrLLUDo+1gXafiYpc1ihPnwudMHHdcq+BiC8yrcWhAoHCRmCj0zIhFoktV3EL2Jq6FZsvb9Yb0g2gzDCjGer89tvq0KIdZrRXlhZrvaRCoXr23cREdcjROH1afcmpoODlNpVK3WLTurW6P42zc8n12LnT8CilRYuqflHIslCQIaQW4zN8g/95GjsU1FyUKiXXMvE457G634QJlypKCxRlhZPqMrV8WWGisi53WLJloqqftzpQsSpE9Igoc0h3SUob6rxwoeEQweMBzZvrbvvhB/UoJg+Pl9sSEoD4eODs2ZdzwwDAxo1AUhLw5puAv79xQ8CrU5ihIENILab9l6CKVeHzLp/j26PfYt6JeZj22jS81fItnHtyrvz9KIw8VidMWLhlwtQWh4pe7hCwAhw+cBivD3wdQmvtjWlFhtcdjtBuoQb3GbuadklDnU25rGNnB/ToobutXj31ekqpqeo5aDTWrQMOHgTc3YFWrYwbAj54cPW5zERBhpBabnbQbKTkpiAyPhKR8ZHc9kVnFmHRmUUlP7CSaMKEXmCoQOuEMeeyRMsEoG6dsMaWCVIxhoY6V5STE/DOO/rb33tP3XLTvbt6dmBjhoAfO2b+8pUXBRlCrMCYdmPwy4VfLF0MAOrLXZobj+FxN0brHwCwmn+s+qZiVTo3pUqpc1OoFNxNrpTrPI/muUR8EZiSFo0hxIoolepLTYWF6g7BEyaoQ8qrrxr3eEuudl0cBRlCrMChpEMAwA0FndpxKsa3H69zWcjQTaqUlnmMMefQVqgoRKGi0BIvAwDotNQYdeMb3i4WiI16PJ/lI0+RhyJFEQQCAQUpUuWkUuDGDcDP72UH3z/+UC9dEBSkXpQSUF82atMGOHeuhBNpseRq18VRkCGkliu+MJ7mvrutu9HX7CtCxaogU8qQW5iLPfv3oGtQVygZpemBSCHVGYZsyk2boW1V4t++QcWHI1fmrfhzWeryGimbuYY65+erL/20aPFyW/fu6nCyY8fLTroBAep+NLa2uo8/eRJo1KjsIeDdu5tetspCQYaQWqyk1X2BsoeCmguP4albJiR8uAhd0NC5YZV2emVZFjKlrMItSxVppWLx8hNBqpRCqpQiW5pdZa+BNu0+ShVpkSq1FQp8PCp6hOSsZDhIHChIaTE0JQI31NkvBuApgbhIo4Y6a2b3dXFRf71wQX1pqF493X4ubdsCd+/qzgbcpg2Qna0flgQC44aAV5eOvgAFGUJqNWNX963NGIaBWCCGWCCGE5yq/PllMhl27dmFnn17lqslqqKhqlBeqBOkZEoZZEoZcqQ5lV/52/qbigepqm6h4vMs+wlcfEoEbqhz9xigVzjwP/WUCMWHOmdk6C4G+fHHwIoV6lWsv/hCvU0zBFulAnJyAEdH9f3Fi4FVq14GEaD0WX/LMwTckijIEFKLlWd1X2JeDMNAyBPCUexokeHXxRdSNMut2OU97rKf1i2nIAcqnkpv/aMqDVIGCHnCCl2eK+0mgAC38m7B66kX7CX2Bo/RnRIB+G3abN0Qc3T2vz83dfD45BN1aElLA3Jz1ZeDAMDHR/314cOXdbO3V0+O5+6uW+fil4+MYY4h4FWFggwhhNRiDMNAyBdCyBfCQexQJc8pl8sRGxuL0NBQCIVC8wcpE1uptOcxkqvkkMvkyJXlVt4LcLfkXQKeABKBBLZCW0TGhwMTIgGeSifEaLCsumXG2Vkdam7fBgID1fs++ACYNOnlZSWN4iGmIipjCHhloCBDCCGkUgl4AtiL7GEvsrfI8ytUCoOtRuZqkdK+jPci+wX4Yr5OoJKr5DplyZPlvSwcTwUoRHohRltWFrB06csQI5OpRyJ5eVXSC1bDUJAhhBBSqwl4AghEAtiJ7Cr1eYq3RClVShx9cBQbrm7AtpvbdAKMi8QFmUWZgFIICGRAj5hSw0yjRi+/v3AB6NJF3WH3mtYK40lJ6n40mr4x1oKCDCGEEGImLMviXMo5bLu1DVtvbMXTvJczx9W1r4thrYehQFGAlRdWIjIoGr+Nno3Hjf/tIwPohBmGAerXVy8foL0g5IMH6s669erpPvewYcD588A//wCvv67e9uKFusNuixaASFSxuhkaIl4dUJAhhBBCSmDsCvK30m9hw5UNWHNrDVKvpHLHuEhcMLTlUIzwH4Eevj0w99hcLIxbyI0m9F8EvP32bPW4Mq0woxlhtGiR7pwwgHpJgcGDdYdTs6x6pBIANGv2cvuePcCYMeq+LkeOvNx+7Jg6JDVsWPoIJo2SVsP+8UdGZzVuS6AgQwghhJSgrBXk+/r1Rftf2uPKsyvcPluhLd5o/gZGtBmBkCYhEPFfNoUUnxLh5VDn2XjMQj2PDMoe6mxjo75pMIx6yYEXL17O3guoRzo5OakXg9RgWeCNN9R9by5dAtq3V29PTFSPgmrXTneod2mrYb/3Hh9ffFEXoYbXyawSFGQIIYSQEhSfQHJSh0mY8N8J2JO4BwBwMOkgAPWw7n6N+6G5rDlmvzMbznbOBs9naEqEl0OdZ6sv20SUf6izq6vu/Y8/Bj76CCjSmsw6Jwfw9VV3Gm7Z8uX2jRuBqCj1ukurV6u3KZXA+++Xvhr26tVtEBkJWGpxdwoyhBBCiAEypQy3M27Dz8UP3X26IzwunAs0AMCAQXDDYAxvMxxDWw2Fg8ABsbGx5epUXJlDnRlGt/XGyQm4fFkdUrTDkq0t0KSJeiZgjd271a08JWFZBhkZtjh+XIE+fcxedKNQkCGEEGLVVKwK97Pu49qza7iedh3X0q7hWto13Hl+R2cOGg0GDH7s9yPebf0u6jvW57bL5XK9Y6uz4i0+X3yhvmm3viQnG3cuS66GTUGGEEKI1UjLT8O1Z+qgogktN9JuIF+eb/B4J7ET/D39IVVIcS7lHIQ8IeQqOfJkeTohprZ4+FB9WamoSL38gab/TFksuRo2BRlCCCG1Tp4sDzfSbqhbV55dw/X067j27BrSC9INHi/mi9HSvSX8Pfzh7+GPNh5t4O/pj/oO9fHt0W8NriAPVK+lPsqzgvaLF+rHaWYEzsgAoqPVSyFER6vP4e1d2mrYLOrUKUS3bhbqIAMKMoQQQizE2KHNpZEr5Uh4nqBuXdEKLMlZhq+JMGDQ2LWxXmBp4toEAp7+R2J1WEHeGCUNjy5tBe3ISCAmBggLA+bMUW8LCAAmTgS6dVMHFz6/7NWwJ068Dj4/oFLqZQwKMoQQQiyirKHN0cHR3DaWZfEg+wEXWDSXhm5n3NZZAkBbXfu66qDi4Q9/T3VoaeXeCrZC41dRrAkryJc2PPrtt4Ft29QjivbsAebOBerUUe9v0kS9UvadOy8fwzDAb7/pnqe01bB/+EEJsfgpAAoyhBBCrIyhlg1NiBnffjycJc744J8PcD3tOq6nXS9xoUcHkYNeYGnj0QZutm4GjzdFdV9BXqlUB4zShkd/+ql6pNL160BQEDBihHr/4MHA/fvqodhlKWk1bJWKRWysWatkMgoyhBBCqoxCpUB6fjpS81LxLP8ZGjg1QF+/vgiPC0dEXARY9Ry3WHN5DdZgjc5jhTwhWrq35EKL5quPkw8YzXUOK3P4sG4rSXEsCzx6pJ4ALzhYd2I8Bwf1zViGhoirVKaUtnJQkCGEEFIhSpUSGQUZeJb/DKl5qXiS/QTxafGIPxyPtII0bvuzvGfIKMjgwkpx2tv9XPxetrL8G1qa1WkGId9ynUotRalUr6GUlKRenkCT2b7+Wn2pyBhduwLDh1deGS2JggwhhBA9KlaFF4UvuACiaUHR+frv9vSCdKhYA3+apxg+N4/hwcPOA552nvCy98Kz/Ge4nHoZAp4ACpUC33T/BjG9Yiq3gtXUsWPArl3qYc8jR6q3KZXq1a5VKqBnT8DLS73dzYQrZ5YcHl3ZKMgQQoiVYFkWmUWZ+sEk7xlS83UDS1p+msHJ4ErCgIGbrRu87L3gYesBRbYCrzR7BfUc63GBxdNe/bWOTR38v707D4uq3v8A/h6GmWHYQVYVBMMFl0xcENTQC0pWSmrlTUrI4rmaXjWvipia4u2232t1e+p2U7Bc85emlblg4kKkqOFSyCYJKUghyr448/n9MXeODMwMiwPDzHxezzOPnu85c+b7mcORj+e7ia1U44KbjwpSb0vF0m7RB8VQysuB2tp7K1YrlUBkJJCXB/z4I+DpqSrPyADeeUe1krU6kZFKgdGjVR12q6runTM2VvWEZvRofcOjVZ1yu8tK1Z2BExnGGDNhRISK+gqtT0q0PUHRNcJHlx7yHkICIiQkzRITTztPuNu5C8OXGxsbceDAATwa/igkehbgMdbQ5o7Mt9JWly654cYNEWbPVnWwBVTDl5csUSUdO3aoyqysVIs8FhWpmozUiUxoqKrzbmio5nnT01t+lovLvfPrGx69caPh4uuOOJFhjLH7pG8+lNdOvYYrxVfwKNq+PDARoaqhqk2JSUlVCeoV9e2qr7ONc6uJiZe9F9zt3DVWbjY0Ywxt7sh8K2rqUUAAcOYMkJQE+PkB8fH3jtm4MQhlZdYICgKCg1Vlvr6qP+/c0Tzff/8L2NsDQ4feKxszRvVqD33Do/WtoG0uOJFhjLH7pG8+lPUn1uMZL1Uvy5rGGu2JiZamnZrGmnbVwVHmqJmQ2LVMTDztPeFh5wEbaxvDBX8funpoc2vzrXzxhaqZprpac1XoadOAH34ADhxQ7QdUT1I+/liVdDRNZB588HfI5b1hbW0llE2ZojqnbbPpayIjDRebruHR5vwkRo0TGcYY6wAiQmVDJcpry/F4/8dxtfwq1qauRcaNDIzqOQrf5HyDMzfOwMfRB6m3UuH6jiuqGqpaP3ETdhI7rU9KtD1BkUvkrZ/QgrVlvpV584CyMiAkRJW4qN2+rSq/evVeIhMUBKxerfk0BQAWL/4Jjz7qDYnkXiJj00V5Y2euoN2dcSLDGLNoCqUCt+tu41btLZ2v8rpyrWXaOsN+nfM1vs75WtguqijS2G9jbdOmZh1Pe0/YS+07PX5LcfJk6/OtlJWp/p6eDjQ0qDrZAsC//qXqaBsQcO94f3/V9P7M+DiRYYyZhbq7dSivbZlw6EtGbtXewp36O62fXA+ZWAZXuavwSitKg5KUEIvE2PjIRvSw6YGCSwWICo+Cj4sPHKQOFjt5mzEVF7f9WAcHVeKilpKimsclLg6YPNnwdWP3hxMZxli3oe7k2t6nI7dqb6H2bu19fbaD1EEjIVG/XGxctJa7yl3hIneB3FouJCYbjm/AycKTkIqlaFA0oLy2HH8Z/hccKDigmsxNzwge1rnaOo9KbKxqiHTTXDMlRfV6tEl/7bw8IDwcGDFC1fdGrb7eSmvzFes8nMgwxgxOW3NNaVUpTv1+CudOnkNFQ4XOJKU9c5c0ZyWy0p946NjnbON83zPG6poPRaFUYLgRF9RjKuPHq0bxtDbfyqeftuwg+8orqiSm6VwsWVlAYeG9IdBqb745GvPnW2PTJuCJJ1Rl1dXAzZuqNY062vm2M4eMmzpOZBgzEfqG+G44vgEKUugdBdIRndJcc731z23eXNPWhMRB5gArkVXrH2Bgrc2H8ozXM+0afs0MTyzu+HwrEya07EQ7YYIqsahvNvL9+nV73LolgqvrvbJTp4BHHgGGDwfOn79XfvIk4OgIDBwIyGS6634/Q8YtAScyjJkIfUN81b9EtWmtuUZXMmKI5hpHmaOQeLjYuKDudh0G+w+Gm52b3oTE1Ebg6JsPRaFU4Er2FSPVjDVlyPlWHByAceNalr///jH4+0di8OB7T/hu3lQlKn37ah774otATg5w5AgQEaEqy80FTpxQJT1BQa0PGf+//+NkhhMZxro5hVKB6sZqvBD0Aspqy7A2dS2u3bmGmYEzsemnTfgy60tM9JuIstoyzNk7p1Oaa9rUX6TZvubNNcJsr1P0z/ZqivQ9CXtl3Cs4UHGg6yrD9Ors+VZkMgUeekizs/CcOarlBior75UplarZfEtLNeesOXwYWLgQmDoV2Lu39SHjS5ao4rHkZiZOZBgzACJCg6IB1Y3VqGqoQnXD//7UsV1RV4Gff/sZ+77dh1pFrc73VDdWo+5uXYvP2/TTJmz6aZOwfezXYzj26zG9dZSJZehh26PdCYmxmmsY6yzGmG9FLAacne9tW1mpnrw0T1K8vFQjo8aNa9uQ8aIi1XGWOH+MGicyzKIoSYnaxlohYWgt4Wi63doxHZpO/Y+2HyoWiWEntYO91B7FlcUgEEQQ4clBT7YpKTG15hrGLEHzkfgzZ6peABAT07ZztGdouTniRIZ1S3eVd/UnFa0lIDqOqW6s7vS6y8QyIeGwk/zvz2bbcrEcJUUleHDgg3C0cdR6TNNtO6kdZGIZRCKRxurADYoGDPUYalarBDNmiYhUc9UMGQLI//d/Dg+Ptr23rUPLzRUnMqzDiAj1ivo2PdXQta+qvgrXf7+OlUUrhace1Q3V7V4EryN0JQwayURbjmm2T70CsD5Cf5Gx7esvomuIL9A5a9MwxjqmvcOlIyKA778Hdu9WdeIFgIQEYMsW4I8/9A8Zbzos3BJxItMOxhj+aghKUqKmsabVpKKtTzWabitJaZhK6hgcY21lrfOphkYC0ZZjmvxdLpGbXL+P1ob4Nt1mjBnP3r0i/O1vuodLX7sGHDwI/OUv9/aPHAn8+KPme1xdVQtTdmTIuCXhRKYdOjr8ta0aFY2ouluF3yp+QwM1tKsZRV+S0t5VdDvCxtqmRQKhkUxItCcZMisZrly4grDQMDjbOrdIQKRiaafX3VToG+Kr3s8YM670dG+89ZZY53DprVuBF14A6uqA0NB7i06uWAGsWQPYN1tey5BDxs0VJzLt0PR/v3V36xA3Ig7v/vAu/p3xb8Q+FIthXsOw49IO3QlIK309GhQNqg+63Dn1F0HU+hMLHQmHvmYVO4kdxFYd+y9BY2MjDvx6AGF9wsxuSK6h6Xvax09iGDM+hQL49NOheodLr1wJTJkClJcDNU3+j9mjh+7zdvaQcVPHiUw7NU1m/nHqH0J5cmYykjOTDfIZEitJq51FdT750JOANF0ThjHGmGGdOiVCWZnu0YHq4dJJSap1mtrDGEPGTQUnMh2wJmwN1h1fJ/QP8XP2M0hnUSmkOHH0BKIej+KnE4wxZmLaOgy6tLRz62FpOJHpgA3HN0BJSmH469yH5hrk0X5jYyMkVpzAMMaYKWrrMGhLHy5taKY1bKMbaNqxt351PRInJGJt6lpsOL7B2FVjjDFmROPGEXr0qIVIpKWTDFR9ZHx8eLi0oZlEIvPhhx/Cz88PNjY2CA4OxpkzZ4xSD13DXzmZYYwxJhYDL754CUDLGXt5uHTn6faJzK5du7B06VK8+uqrOH/+PIYNG4bIyEiUGqGRUd/w18QJiTz8lTHGLFxISDF27lSgVy/N8t69eaXqztLt+8j885//RFxcHJ5//nkAwMcff4xvv/0WmzdvxsqVK7u0Ljz8lTHGWGumTyfMnMnDpbtKt05kGhoacO7cOSQkJAhlVlZWiIiIQHp6utb31NfXo77+3vT2FRUVAFQdaRsbGzu3wvdJXb/uXk9DssSYAcuM2xJjBiwzbkuMGdCMWyIBxo69t0+pVL3MTWde67aeU0Skbeqe7uHGjRvo1asXfvjhB4SEhAjlK1aswPHjx3H69OkW71m3bh3Wr1/fonz79u2wtbXt1PoyxhhjzDBqamowe/Zs3LlzB46OjjqP69ZPZDoiISEBS5cuFbYrKirg4+ODyZMn6/0iuoPGxkYcOXIEkyZNsph5ZCwxZsAy47bEmAHLjNsSYwYsM+7OjFndotKabp3IuLm5QSwW4+bNmxrlN2/ehJeXl9b3yGQyyGSyFuUSicRkfrBMqa6GYokxA5YZtyXGDFhm3JYYM2CZcXdGzG09X7cetSSVSjFixAgcPXpUKFMqlTh69KhGUxNjjDHGLFO3fiIDAEuXLkVMTAxGjhyJ0aNHY+PGjaiurhZGMTHGGGPMcnX7RGbWrFn4/fffsXbtWpSUlOChhx7CwYMH4enpaeyqMcYYY8zIun0iAwALFy7EwoULjV0NxhhjjHUz3bqPDGOMMcaYPpzIMMYYY8xkmUTT0v1Qz/fX1vHoxtTY2IiamhpUVFRYzNA9S4wZsMy4LTFmwDLjtsSYAcuMuzNjVv/ebm3eXrNPZCorKwEAPj4+Rq4JY4wxxtqrsrISTk5OOvd36yUKDEGpVOLGjRtwcHCAqPm66t2MehbioqKibj8LsaFYYsyAZcZtiTEDlhm3JcYMWGbcnRkzEaGyshI9e/aElZXunjBm/0TGysoKvXv3NnY12sXR0dFibgI1S4wZsMy4LTFmwDLjtsSYAcuMu7Ni1vckRo07+zLGGGPMZHEiwxhjjDGTxYlMNyKTyfDqq69qXfTSXFlizIBlxm2JMQOWGbclxgxYZtzdIWaz7+zLGGOMMfPFT2QYY4wxZrI4kWGMMcaYyeJEhjHGGGMmixMZxhhjjJksTmSM7I033oBIJMKSJUuEsgkTJkAkEmm85s2bZ7xKGsC6detaxDRw4EBhf11dHRYsWIAePXrA3t4eM2fOxM2bN41Y4/vXWszmeJ3Vrl+/jmeffRY9evSAXC7H0KFDcfbsWWE/EWHt2rXw9vaGXC5HREQEcnNzjVjj+9dazLGxsS2u9yOPPGLEGt8/Pz+/FjGJRCIsWLAAgHne163FbK73tUKhwJo1a+Dv7w+5XI4HHngAGzZs0FgHyVj3tdnP7NudZWRk4D//+Q8efPDBFvvi4uKQmJgobNva2nZl1TrF4MGDkZKSImxbW9/78Xv55Zfx7bffYvfu3XBycsLChQsxY8YMpKWlGaOqBqMvZsA8r3N5eTnGjh2LiRMn4rvvvoO7uztyc3Ph4uIiHPPWW2/h/fffx5YtW+Dv7481a9YgMjISv/zyC2xsbIxY+45pS8wA8MgjjyApKUnYNvVhuhkZGVAoFML25cuXMWnSJDz11FMAzPO+bi1mwDzv6zfffBMfffQRtmzZgsGDB+Ps2bN4/vnn4eTkhEWLFgEw4n1NzCgqKyupX79+dOTIEQoLC6PFixcL+5pvm4NXX32Vhg0bpnXf7du3SSKR0O7du4WyrKwsAkDp6eldVEPD0xczkXleZyKi+Ph4GjdunM79SqWSvLy86O233xbKbt++TTKZjHbs2NEVVTS41mImIoqJiaGoqKiuqZCRLF68mB544AFSKpVme1831zRmIvO9rx977DGaO3euRtmMGTMoOjqaiIx7X3PTkpEsWLAAjz32GCIiIrTu37ZtG9zc3DBkyBAkJCSgpqami2toeLm5uejZsyf69u2L6OhoFBYWAgDOnTuHxsZGje9i4MCB8PX1RXp6urGqaxC6YlYzx+u8f/9+jBw5Ek899RQ8PDwwfPhw/Pe//xX2FxQUoKSkRON6Ozk5ITg42GSvd2sxq6WmpsLDwwMDBgzA/PnzUVZWZoTado6GhgZs3boVc+fOhUgkMuv7Wq15zGrmeF+Hhobi6NGjyMnJAQBcuHABp06dwpQpUwAY977mpiUj2LlzJ86fP4+MjAyt+2fPno0+ffqgZ8+euHjxIuLj45GdnY09e/Z0cU0NJzg4GMnJyRgwYACKi4uxfv16jB8/HpcvX0ZJSQmkUimcnZ013uPp6YmSkhLjVNgA9MXs4OBgltcZAK5evYqPPvoIS5cuxapVq5CRkYFFixZBKpUiJiZGuKaenp4a7zPl691azICqWWnGjBnw9/dHfn4+Vq1ahSlTpiA9PR1isdjIEdy/r776Crdv30ZsbCwAmO193VTzmAHz/PcbAFauXImKigoMHDgQYrEYCoUCr732GqKjowHAuPd1pz7vYS0UFhaSh4cHXbhwQShr7VHk0aNHCQDl5eV1QQ27Rnl5OTk6OtKnn35K27ZtI6lU2uKYUaNG0YoVK4xQu87RNGZtzOU6SyQSCgkJ0Sj761//SmPGjCEiorS0NAJAN27c0DjmqaeeoqeffrrL6mlIrcWsTX5+PgGglJSUzq5el5g8eTI9/vjjwrYl3NfNY9bGXO7rHTt2UO/evWnHjh108eJF+uyzz8jV1ZWSk5OJyLj3NTctdbFz586htLQUQUFBsLa2hrW1NY4fP473338f1tbWGp3I1IKDgwEAeXl5XV3dTuPs7Iz+/fsjLy8PXl5eaGhowO3btzWOuXnzJry8vIxTwU7QNGZtzOU6e3t7Y9CgQRplgYGBQrOa+po2H71iyte7tZi16du3L9zc3Ez+egPAtWvXkJKSghdffFEoM/f7WlvM2pjLfb18+XKsXLkSf/7znzF06FA899xzePnll/H6668DMO59zYlMFwsPD8elS5eQmZkpvEaOHIno6GhkZmZqfcScmZkJQPWPpbmoqqpCfn4+vL29MWLECEgkEhw9elTYn52djcLCQoSEhBixlobVNGZtzOU6jx07FtnZ2RplOTk56NOnDwDA398fXl5eGte7oqICp0+fNtnr3VrM2vz2228oKysz+esNAElJSfDw8MBjjz0mlJn7fa0tZm3M5b6uqamBlZVmyiAWi6FUKgEY+b7u1Oc9rE2aNi3l5eVRYmIinT17lgoKCmjfvn3Ut29fevjhh41byfv0t7/9jVJTU6mgoIDS0tIoIiKC3NzcqLS0lIiI5s2bR76+vvT999/T2bNnKSQkpMWjelOjL2Zzvc5ERGfOnCFra2t67bXXKDc3l7Zt20a2tra0detW4Zg33niDnJ2dad++fXTx4kWKiooif39/qq2tNWLNO661mCsrK2nZsmWUnp5OBQUFlJKSQkFBQdSvXz+qq6szcu3vj0KhIF9fX4qPj2+xzxzvayLdMZvzfR0TE0O9evWib775hgoKCmjPnj3k5uam0UxorPuaE5luoGkiU1hYSA8//DC5urqSTCajgIAAWr58Od25c8e4lbxPs2bNIm9vb5JKpdSrVy+aNWuWRptxbW0tvfTSS+Ti4kK2trY0ffp0Ki4uNmKN75++mM31Oqt9/fXXNGTIEJLJZDRw4ED65JNPNPYrlUpas2YNeXp6kkwmo/DwcMrOzjZSbQ1DX8w1NTU0efJkcnd3J4lEQn369KG4uDgqKSkxYo0N49ChQwRA6/Uzx/uaSHfM5nxfV1RU0OLFi8nX15dsbGyob9++9Morr1B9fb1wjLHuaxFRk2n5GGOMMcZMCPeRYYwxxpjJ4kSGMcYYYyaLExnGGGOMmSxOZBhjjDFmsjiRYYwxxpjJ4kSGMcYYYyaLExnGGGOMmSxOZBhjnWLChAlYsmSJwc8rEonw1VdfGfy8xtLe7yk2NhZPPPGEQc+pTWpqKkQiUYu1khjrbqyNXQHGWPcmEomwd+/eVn95Nrdnzx5IJJLOqZQJSk1NxcSJE1FeXg5nZ2ehvL3f03vvvQeex5SxeziRYcwEKRQKiESiFou4dSeurq7GrkK30djYqHNfe78nJyen+60OY2al+/4ryJiZmDBhAhYuXIiFCxfCyckJbm5uWLNmjcb/qsvLyzFnzhy4uLjA1tYWU6ZMQW5urrA/OTkZzs7O2L9/PwYNGgSZTIbCwkLU19cjPj4ePj4+kMlkCAgIwKZNm4T3Xb58GVOmTIG9vT08PT3x3HPP4Y8//tCo26JFi7BixQq4urrCy8sL69atE/b7+fkBAKZPnw6RSCRs5+fnIyoqCp6enrC3t8eoUaOQkpLSIu6mzRv19fVYtmwZevXqBTs7OwQHByM1NVXvd5ebm4uHH34YNjY2GDRoEI4cOdLimKKiIjz99NNwdnaGq6sroqKi8Ouvv+o8p0KhwAsvvAB/f3/I5XIMGDAA7733nsYxqampGD16NOzs7ODs7IyxY8fi2rVrwv59+/YhKCgINjY26Nu3L9avX4+7d+8K+0UiET766CNMmzYNdnZ2iIuLw8SJEwEALi4uEIlEiI2NbfE9rVq1CsHBwS3qPGzYMCQmJgJo2bRUXV2NOXPmwN7eHt7e3nj33XdbvP/zzz/HyJEj4eDgAC8vL8yePRulpaUaxxw4cAD9+/eHXC7HxIkT9X6HjHUrnb6aE2MWLiwsjOzt7Wnx4sV05coV2rp1K9na2mosKjht2jQKDAykEydOUGZmJkVGRlJAQAA1NDQQEVFSUhJJJBIKDQ2ltLQ0unLlClVXV9PTTz9NPj4+tGfPHsrPz6eUlBTauXMnERGVl5eTu7s7JSQkUFZWFp0/f54mTZpEEydO1Kibo6MjrVu3jnJycmjLli0kEono8OHDRERUWlpKACgpKYmKi4uF1cozMzPp448/pkuXLlFOTg6tXr2abGxs6Nq1axrnVi+GSkT04osvUmhoKJ04cYLy8vLo7bffJplMRjk5OVq/N4VCQUOGDKHw8HDKzMyk48eP0/DhwwkA7d27l4iIGhoaKDAwkObOnUsXL16kX375hWbPnk0DBgzQWMyuqYaGBlq7di1lZGTQ1atXheuxa9cuIiJqbGwkJycnWrZsGeXl5dEvv/xCycnJQmwnTpwgR0dHSk5Opvz8fDp8+DD5+fnRunXrhM8AQB4eHrR582bKz8+nX3/9lb788kthocHi4mK6fft2i+/p8uXLBEBjQVV1WW5uLhGpViGOiooS9s+fP598fX0pJSWFLl68SI8//jg5ODhofPebNm2iAwcOUH5+PqWnp1NISAhNmTJF2F9YWEgymYyWLl0q/Ix6enoSACovL9f6PTLWXXAiw1gnCwsLo8DAQFIqlUJZfHw8BQYGEhFRTk4OAaC0tDRh/x9//EFyuZy++OILIlIlMgAoMzNTOCY7O5sA0JEjR7R+7oYNG2jy5MkaZUVFRRqr9oaFhdG4ceM0jhk1ahTFx8cL200TB30GDx5MH3zwgUbc6l+m165dI7FYTNevX9d4T3h4OCUkJGg936FDh8ja2lrjPd99951GfT7//HMaMGCAxndbX19PcrmcDh061Gqd1RYsWEAzZ84kIqKysjICQKmpqVqPDQ8Pp3/84x8aZZ9//jl5e3sL2wBoyZIlGsccO3ZMa2LQPOEbNmwYJSYmCtsJCQkUHBwsbDdNZCorK0kqlQo/J+r6y+VyjXM2l5GRQQCosrJS+IxBgwZpHBMfH8+JDDMJ3LTEWBcYM2YMRCKRsB0SEoLc3FwoFApkZWXB2tpao0mhR48eGDBgALKysoQyqVSKBx98UNjOzMyEWCxGWFiY1s+8cOECjh07Bnt7e+E1cOBAAKqmIbWm5wQAb2/vFs0OzVVVVWHZsmUIDAyEs7Mz7O3tkZWVhcLCQq3HX7p0CQqFAv3799eoz/HjxzXq0lRWVhZ8fHzQs2dPoSwkJKRFjHl5eXBwcBDO6erqirq6Op3nBYAPP/wQI0aMgLu7O+zt7fHJJ58IdXd1dUVsbCwiIyMxdepUvPfeeyguLtb4zMTERI044uLiUFxcjJqaGuG4kSNH6v0OdYmOjsb27dsBAESEHTt2IDo6Wuux+fn5aGho0PjZcXV1xYABAzSOO3fuHKZOnQpfX184ODgIPzPqmLOyslo0aTX/rhnrrrizL2MmQi6XayRDcrlc7/FVVVWYOnUq3nzzzRb7vL29hb83HzEjEomgVCr1nnvZsmU4cuQI3nnnHQQEBEAul+PJJ59EQ0ODzrqIxWKcO3cOYrFYY5+9vb3ez9KnqqoKI0aMwLZt21rsc3d31/qenTt3YtmyZXj33XcREhICBwcHvP322zh9+rRwTFJSEhYtWoSDBw9i165dWL16NY4cOYIxY8agqqoK69evx4wZM1qc28bGRvi7nZ1dh2J65plnEB8fj/Pnz6O2thZFRUWYNWtWh84FqPrQREZGIjIyEtu2bYO7uzsKCwsRGRmp83oxZko4kWGsCzT9JQkAP/74I/r16wexWIzAwEDcvXsXp0+fRmhoKACgrKwM2dnZGDRokM5zDh06FEqlEsePH0dERESL/UFBQfjyyy/h5+cHa+uO3+oSiQQKhUKjLC0tDbGxsZg+fToAVUKhr3Po8OHDoVAoUFpaivHjx7fpcwMDA1FUVITi4mIh8frxxx81jgkKCsKuXbvg4eEBR0fHNp03LS0NoaGheOmll4QybU9vhg8fjuHDhyMhIQEhISHYvn07xowZg6CgIGRnZyMgIKBNn6cmlUoBoMV32Vzv3r0RFhaGbdu2oba2FpMmTYKHh4fWYx944AFIJBKcPn0avr6+AFQdx3NycoSnLleuXEFZWRneeOMN+Pj4AADOnj2rcZ7AwEDs379fo6z5d81Yd8VNS4x1gcLCQixduhTZ2dnYsWMHPvjgAyxevBgA0K9fP0RFRSEuLg6nTp3ChQsX8Oyzz6JXr16IiorSeU4/Pz/ExMRg7ty5+Oqrr1BQUIDU1FR88cUXAIAFCxbg1q1beOaZZ5CRkYH8/HwcOnQIzz//fKu/TJt/ztGjR1FSUoLy8nKhznv27EFmZiYuXLiA2bNn632K079/f0RHR2POnDnYs2cPCgoKcObMGbz++uv49ttvtb4nIiIC/fv3R0xMDC5cuICTJ0/ilVde0TgmOjoabm5uiIqKwsmTJ4XvYNGiRfjtt9+0nrdfv344e/YsDh06hJycHKxZswYZGRnC/oKCAiQkJCA9PR3Xrl3D4cOHkZubi8DAQADA2rVr8dlnn2H9+vX4+eefkZWVhZ07d2L16tV6v8c+ffpAJBLhm2++we+//46qqiqdx0ZHR2Pnzp3YvXu3zmYlQPU064UXXsDy5cvx/fff4/Lly4iNjdUYlu/r6wupVIoPPvgAV69exf79+7FhwwaN88ybNw+5ublYvnw5srOzsX37diQnJ+uNh7Fuw9iddBgzd2FhYfTSSy/RvHnzyNHRkVxcXGjVqlUaHVRv3bpFzz33HDk5OZFcLqfIyEiN0TxJSUnk5OTU4ty1tbX08ssvk7e3N0mlUgoICKDNmzcL+3Nycmj69Onk7OxMcrmcBg4cSEuWLBE+u3lHUyKiqKgoiomJEbb3799PAQEBZG1tTX369CEiooKCApo4cSLJ5XLy8fGhf//73y3O1XxbPVrIz8+PJBIJeXt70/Tp0+nixYs6v7vs7GwaN24cSaVS6t+/Px08eLBF5+Pi4mKaM2cOubm5kUwmo759+1JcXBzduXNH6znr6uooNjaWnJycyNnZmebPn08rV66kYcOGERFRSUkJPfHEE8J32qdPH1q7di0pFArhHAcPHqTQ0FCSy+Xk6OhIo0eP1hiF1ryOaomJieTl5UUikUj4jrVdg/LycpLJZGRrayt0yFVrPmqpsrKSnn32WbK1tSVPT0966623Wpxz+/bt5OfnRzKZjEJCQmj//v0EgH766SfhmK+//poCAgJIJpPR+PHjafPmzdzZl5kEERFPEclYZ5owYQIeeughbNy40dhV6VIhISEIDw/H3//+d2NXhTFmxrhpiTFmUPX19Th79ix+/vlnDB482NjVYYyZOU5kGGMG9d133+FPf/oTpk2bhieffNLY1WGMmTluWmKMMcaYyeInMowxxhgzWZzIMMYYY8xkcSLDGGOMMZPFiQxjjDHGTBYnMowxxhgzWZzIMMYYY8xkcSLDGGOMMZPFiQxjjDHGTBYnMowxxhgzWf8PjNQEjlAVWHMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp.plot(v_aA,v_eA, marker='o', linestyle=':', color='b', label = \"ADAM\")\n",
    "mp.plot(v_aR,v_eR, marker='x', linestyle='-', color='g', label = \"RMSProp\")\n",
    "\n",
    "#mp.xticks(np.arange(70,100,2))\n",
    "#mp.yticks(np.arange(0,4,1))\n",
    "mp.xlabel(\"porcentaje de asertividad\")\n",
    "mp.ylabel(\"Numero de epocas\")\n",
    "mp.legend(loc=\"upper left\")\n",
    "mp.title(\"Nivel de asertividad/epocas entre RSMProp y ADAM\")\n",
    "mp.grid(True)\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc60d660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asertividad del metodo ADAM: 80.0% alcanzado en: 10 epocas.\n",
      "asertividad del metodo RSMProp: 80.0% alcanzado en: 48 epocas.\n"
     ]
    }
   ],
   "source": [
    "print(\"asertividad del metodo ADAM: \"+str(round(v_aA[-1],1))+\"% alcanzado en: \"+str(v_eA[-1])+ \" epocas.\")\n",
    "print(\"asertividad del metodo RSMProp: \"+str(round(v_aR[-1],1))+\"% alcanzado en: \"+str(v_eR[-1])+ \" epocas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75137e72",
   "metadata": {},
   "source": [
    "## validando el modelo por LA CRUVA ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6385498",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = modelo1.predict_proba(x_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "041239ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = lr_probs[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17ad4a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_probs = [0 for _ in range(len(y_p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3db4c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin entrenar: ROC AUC=0.500\n",
      "Red Neuronal: ROC AUC=0.865\n"
     ]
    }
   ],
   "source": [
    "# Calculamos el AUC\n",
    "ns_auc = roc_auc_score(y_p, ns_probs)\n",
    "lr_auc = roc_auc_score(y_p, lr_probs)\n",
    "# Imprimimos en pantalla\n",
    "print('Sin entrenar: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Red Neuronal: ROC AUC=%.3f' % (lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cad3bbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculamos las curvas ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_p, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_p, lr_probs)\n",
    "# Pintamos las curvas ROC\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Sin entrenar')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Red Neuronal')\n",
    "# Etiquetas de los ejes\n",
    "pyplot.xlabel('Tasa de Falsos Positivos')\n",
    "pyplot.ylabel('Tasa de Verdaderos Positivos')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbba854",
   "metadata": {},
   "source": [
    "## sensibilidad y presicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "735ff74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = modelo1.predict_proba(x_p)\n",
    "# Nos quedamos unicamente con las predicciones positicas\n",
    "lr_probs = lr_probs[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a380509",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = modelo1.predict(x_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aadb5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_p, lr_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bbf062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_auc =  auc(lr_recall, lr_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd5d8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skill = len(y_p[y_p==1]) / len(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "222ed5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redes neuronales: auc=0.829\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Redes neuronales: auc=%.3f' % (lr_auc))\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='Sin entrenar')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='Redes Neuronales')\n",
    "#Etiquetas de ejes\n",
    "pyplot.xlabel('Sensibilidad')\n",
    "pyplot.ylabel('Precisión')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb4527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
