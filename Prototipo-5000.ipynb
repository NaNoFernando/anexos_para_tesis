{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f92b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965e3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5fb2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb8f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "Y_train=[]\n",
    "dataTr=[]\n",
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/entrenamiento/Melanoma_escalado','*.jpg')):\n",
    "    dataTr.append([1,cv2.imread(filename)])\n",
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/entrenamiento/Carcinoma_escalado','*.jpg')):\n",
    "    dataTr.append([0,cv2.imread(filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235b98a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particion(datos):\n",
    "    imagenes=[]\n",
    "    etiquetas=[]\n",
    "    for i,j in datos:\n",
    "        imagenes.append(j)\n",
    "        etiquetas.append(i)\n",
    "    imagenes=np.array(imagenes)\n",
    "    etiquetas=np.array(etiquetas)\n",
    "    return (imagenes,etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1079c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en total tenemos: 13319 imagenes dentro de la carpeta train\n"
     ]
    }
   ],
   "source": [
    "shuffle(dataTr)\n",
    "print(\"en total tenemos: \"+str(len(dataTr))+ \" imagenes dentro de la carpeta train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee439097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para entrenamiento tendremos: 3500 imagenes de la carpeta de train\n",
      "para prueba tendremos: 1500 imagenes de la carpeta de train\n"
     ]
    }
   ],
   "source": [
    "porcion1=dataTr[0:3500]\n",
    "porcion2=dataTr[3501:5001]\n",
    "print(\"para entrenamiento tendremos: \"+str(len(porcion1))+ \" imagenes de la carpeta de train\")\n",
    "print(\"para prueba tendremos: \"+str(len(porcion2))+ \" imagenes de la carpeta de train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cccc92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e,y_e=particion(porcion1)\n",
    "x_p,y_p=particion(porcion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06adaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacion(x_e,y_e,x_p,y_p,modelo1,epocas):\n",
    "    entre=modelo1.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
    "    a=modelo1.evaluate(x_p,y_p)\n",
    "    return a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8b8412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion(modelo1,porcentaje,nombre,v1,v2):\n",
    "    prediccion=0\n",
    "    epocas=1\n",
    "    while(True):\n",
    "        if prediccion < porcentaje:\n",
    "            prediccion=(validacion(x_e,y_e,x_p,y_p,modelo1,1))*100\n",
    "            epocas +=1\n",
    "            v1.append(epocas-1)\n",
    "            v2.append(prediccion)\n",
    "        else:\n",
    "            print(\"==> Para el metodo \"+nombre+\" se utilizo: \"+str(epocas-1)+\" epocas para llegar a mas del \"+str(porcentaje)+\"% de acertividad\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3a98edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 394272)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               50466944  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 50,474,341\n",
      "Trainable params: 50,474,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo=Sequential()\n",
    "modelo.add(Convolution2D(32,(3,3),input_shape=(224,224,3),activation='relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(128,activation='relu'))\n",
    "modelo.add(Dense(50,activation='relu'))\n",
    "modelo.add(Dense(1,activation='sigmoid'))\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1355d8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 300.4457 - acc: 0.5780 - val_loss: 94.5053 - val_acc: 0.5293\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 94.5053 - acc: 0.5293\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 10ms/sample - loss: 26.2904 - acc: 0.6203 - val_loss: 7.8858 - val_acc: 0.5747\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 7.8858 - acc: 0.5747\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 2.9708 - acc: 0.7309 - val_loss: 3.2381 - val_acc: 0.6107\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 3.2381 - acc: 0.6107\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 1.1905 - acc: 0.7920 - val_loss: 1.1983 - val_acc: 0.7080\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 1.1983 - acc: 0.7080\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 0.2813 - acc: 0.8963 - val_loss: 0.9563 - val_acc: 0.7573\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 0.9563 - acc: 0.7573\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 0.1403 - acc: 0.9517 - val_loss: 0.9434 - val_acc: 0.7813\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 0.9434 - acc: 0.7813\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 0.0940 - acc: 0.9731 - val_loss: 0.9230 - val_acc: 0.7720\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 0.9230 - acc: 0.7720\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 0.0665 - acc: 0.9863 - val_loss: 0.9509 - val_acc: 0.7820\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 0.9509 - acc: 0.7820\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 0.0566 - acc: 0.9866 - val_loss: 0.9495 - val_acc: 0.7887\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 0.9495 - acc: 0.7887\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 0.0364 - acc: 0.9969 - val_loss: 0.9349 - val_acc: 0.7873\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 0.9349 - acc: 0.7873\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 0.0270 - acc: 0.9989 - val_loss: 0.9797 - val_acc: 0.7820\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 0.9797 - acc: 0.7820\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 0.0201 - acc: 0.9991 - val_loss: 1.0113 - val_acc: 0.7860\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 1.0113 - acc: 0.7860\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "3500/3500 [==============================] - 33s 9ms/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.8007\n",
      "1500/1500 [==============================] - 3s 2ms/sample - loss: 0.9940 - acc: 0.8007\n",
      "==> Para el metodo ADAM se utilizo: 13 epocas para llegar a mas del 80% de acertividad\n"
     ]
    }
   ],
   "source": [
    "modelo_adam = keras.optimizers.Adam(learning_rate=0.0008)\n",
    "modelo.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "v_eA=[]\n",
    "v_aA=[]\n",
    "evaluacion(modelo,80,\"ADAM\",v_eA,v_aA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e5dacc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1038\n"
     ]
    }
   ],
   "source": [
    "modelo.save(\"D:/UMSA/Documentos/CNN cancer de piel/MODELOS/5000/modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f346ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save_weights(\"D:/UMSA/Documentos/CNN cancer de piel/PESOS/5000/modelo_pesos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa779d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
