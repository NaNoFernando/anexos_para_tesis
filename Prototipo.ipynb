{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673d13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b8d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba354674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9484586",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "Y_train=[]\n",
    "dataTr=[]\n",
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/entrenamiento/Melanoma_escalado','*.jpg')):\n",
    "    dataTr.append([1,cv2.imread(filename)])\n",
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/entrenamiento/Carcinoma_escalado','*.jpg')):\n",
    "    dataTr.append([0,cv2.imread(filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206b460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particion(datos):\n",
    "    imagenes=[]\n",
    "    etiquetas=[]\n",
    "    for i,j in datos:\n",
    "        imagenes.append(j)\n",
    "        etiquetas.append(i)\n",
    "    imagenes=np.array(imagenes)\n",
    "    etiquetas=np.array(etiquetas)\n",
    "    return (imagenes,etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88e3a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en total tenemos: 13319 imagenes dentro de la carpeta train\n"
     ]
    }
   ],
   "source": [
    "shuffle(dataTr)\n",
    "print(\"en total tenemos: \"+str(len(dataTr))+ \" imagenes dentro de la carpeta train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6193dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/prueba/melanoma_escalado','*.jpg')):\n",
    "    X_test.append(cv2.imread(filename))\n",
    "    Y_test.append(1)\n",
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/prueba/carcinoma_escalado','*.jpg')):\n",
    "    X_test.append(cv2.imread(filename))\n",
    "    Y_test.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b93d8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#porcion1=dataTr[0:700]\n",
    "#porcion2=dataTr[701:1001]\n",
    "porcion1=dataTr\n",
    "\n",
    "#print(\"para entrenamiento tendremos: \"+str(len(porcion1))+ \" imagenes de la carpeta de train\")\n",
    "#print(\"para prueba tendremos: \"+str(len(porcion2))+ \" imagenes de la carpeta de train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a86a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e,y_e=particion(porcion1)\n",
    "#x_p,y_p=particion(porcion2)\n",
    "x_p,y_p=X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb8e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e=np.array(x_e)\n",
    "x_p=np.array(x_p)\n",
    "y_e=np.array(y_e)\n",
    "y_p=np.array(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9d20bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacion(x_e,y_e,x_p,y_p,modelo1,epocas):\n",
    "    entre=modelo1.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
    "    a=modelo1.evaluate(x_p,y_p)\n",
    "    return a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce08783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion(modelo1,porcentaje,nombre,v1,v2):\n",
    "    prediccion=0\n",
    "    epocas=1\n",
    "    while(True):\n",
    "        if prediccion < porcentaje:\n",
    "            prediccion=(validacion(x_e,y_e,x_p,y_p,modelo1,1))*100\n",
    "            epocas +=1\n",
    "            v1.append(epocas-1)\n",
    "            v2.append(prediccion)\n",
    "        else:\n",
    "            print(\"==> Para el metodo \"+nombre+\" se utilizo: \"+str(epocas-1)+\" epocas para llegar a mas del \"+str(porcentaje)+\"% de acertividad\")\n",
    "            break   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6553a6",
   "metadata": {},
   "source": [
    "## CREAREMOS LA CONVOLUCION segun la estructura VGC16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379b35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo=Sequential()\n",
    "#modelo.add(Convolution2D(64,(3,3),input_shape=(224,224,3),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(Convolution2D(64,(3,3),input_shape=(224,224),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "#modelo.add(Convolution2D(128,(3,3),input_shape=(112,112),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(Convolution2D(128,(3,3),input_shape=(112,112),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "#modelo.add(Convolution2D(256,(3,3),input_shape=(56,56),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(Convolution2D(256,(3,3),input_shape=(56,56),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(Convolution2D(256,(3,3),input_shape=(56,56),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "#modelo.add(Convolution2D(512,(3,3),input_shape=(28,28),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(Convolution2D(512,(3,3),input_shape=(28,28),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(Convolution2D(512,(3,3),input_shape=(28,28),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "#modelo.add(Convolution2D(512,(3,3),input_shape=(14,14),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(Convolution2D(512,(3,3),input_shape=(14,14),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(Convolution2D(512,(3,3),input_shape=(14,14),activation='relu', padding=\"same\", strides=1))\n",
    "#modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "#modelo.add(Flatten())\n",
    "#modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32023b",
   "metadata": {},
   "source": [
    "## Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68dda4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo.add(Dense(1024,activation='relu'))\n",
    "#modelo.add(Dense(1024,activation='relu'))\n",
    "#modelo.add(Dense(1,activation='sigmoid'))\n",
    "#modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f634b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=Sequential()\n",
    "modelo.add(Convolution2D(32,(3,3),input_shape=(224,224,3),activation='relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(128,activation='relu'))\n",
    "modelo.add(Dense(128,activation='relu'))\n",
    "modelo.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce314caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13319 samples, validate on 4221 samples\n",
      "13319/13319 [==============================] - 165s 12ms/sample - loss: 563530860948067923105650904662016.0000 - accuracy: 0.5078 - val_loss: 1233284306363729181745822626092154880.0000 - val_accuracy: 0.4937\n",
      "4221/4221 [==============================] - 1s 252us/sample - loss: 998984973886055677143119135804227584.0000 - accuracy: 0.4937\n",
      "Train on 13319 samples, validate on 4221 samples\n",
      "13319/13319 [==============================] - 15s 1ms/sample - loss: nan - accuracy: 0.5090 - val_loss: nan - val_accuracy: 0.5070\n",
      "4221/4221 [==============================] - 1s 254us/sample - loss: nan - accuracy: 0.5070\n",
      "Train on 13319 samples, validate on 4221 samples\n",
      "13319/13319 [==============================] - 15s 1ms/sample - loss: nan - accuracy: 0.5091 - val_loss: nan - val_accuracy: 0.5070\n",
      "4221/4221 [==============================] - 1s 253us/sample - loss: nan - accuracy: 0.5070\n",
      "Train on 13319 samples, validate on 4221 samples\n",
      "13319/13319 [==============================] - 31s 2ms/sample - loss: nan - accuracy: 0.5091 - val_loss: nan - val_accuracy: 0.5070\n",
      "4221/4221 [==============================] - 1s 334us/sample - loss: nan - accuracy: 0.5070\n",
      "Train on 13319 samples, validate on 4221 samples\n",
      "13319/13319 [==============================] - 20s 2ms/sample - loss: nan - accuracy: 0.5091 - val_loss: nan - val_accuracy: 0.5070\n",
      "4221/4221 [==============================] - 1s 325us/sample - loss: nan - accuracy: 0.5070\n",
      "Train on 13319 samples, validate on 4221 samples\n",
      "13319/13319 [==============================] - 20s 1ms/sample - loss: nan - accuracy: 0.5091 - val_loss: nan - val_accuracy: 0.5070\n",
      "4221/4221 [==============================] - 1s 313us/sample - loss: nan - accuracy: 0.5070\n",
      "Train on 13319 samples, validate on 4221 samples\n",
      "13319/13319 [==============================] - 23s 2ms/sample - loss: nan - accuracy: 0.5091 - val_loss: nan - val_accuracy: 0.5070\n",
      "4221/4221 [==============================] - 2s 372us/sample - loss: nan - accuracy: 0.5070\n",
      "Train on 13319 samples, validate on 4221 samples\n",
      "13319/13319 [==============================] - 23s 2ms/sample - loss: nan - accuracy: 0.5091 - val_loss: nan - val_accuracy: 0.5070\n",
      "4221/4221 [==============================] - 1s 334us/sample - loss: nan - accuracy: 0.5070\n"
     ]
    }
   ],
   "source": [
    "modelo_adam = keras.optimizers.Adam(learning_rate=0.0009)\n",
    "modelo.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "v_eA=[]\n",
    "v_aA=[]\n",
    "evaluacion(modelo,80,\"ADAM\",v_eA,v_aA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961241c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b44f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesisgpu3",
   "language": "python",
   "name": "tesisgpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
