{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f92b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965e3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5fb2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb8f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "Y_train=[]\n",
    "dataTr=[]\n",
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/entrenamiento/Melanoma_escalado','*.jpg')):\n",
    "    dataTr.append([1,cv2.imread(filename)])\n",
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/entrenamiento/Carcinoma_escalado','*.jpg')):\n",
    "    dataTr.append([0,cv2.imread(filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6e8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTe=[]\n",
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/prueba/melanoma_escalado','*.jpg')):\n",
    "    dataTe.append([1,cv2.imread(filename)])\n",
    "for filename in glob.glob(os.path.join('D:/UMSA/TESIS/Tesis de grado/data/prueba/carcinoma_escalado','*.jpg')):\n",
    "    dataTe.append([0,cv2.imread(filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235b98a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particion(datos):\n",
    "    imagenes=[]\n",
    "    etiquetas=[]\n",
    "    for i,j in datos:\n",
    "        imagenes.append(j)\n",
    "        etiquetas.append(i)\n",
    "    imagenes=np.array(imagenes)\n",
    "    etiquetas=np.array(etiquetas)\n",
    "    return (imagenes,etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1079c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en total tenemos: 12279 imagenes dentro de la carpeta train\n",
      "en total tenemos: 5261 imagenes dentro de la carpeta test\n"
     ]
    }
   ],
   "source": [
    "shuffle(dataTr)\n",
    "print(\"en total tenemos: \"+str(len(dataTr))+ \" imagenes dentro de la carpeta train\")\n",
    "shuffle(dataTe)\n",
    "print(\"en total tenemos: \"+str(len(dataTe))+ \" imagenes dentro de la carpeta test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee439097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para entrenamiento tendremos: 12000 imagenes de la carpeta de train\n",
      "para prueba tendremos: 5000 imagenes de la carpeta de test\n"
     ]
    }
   ],
   "source": [
    "porcion1=dataTr[0:12000]\n",
    "porcion2=dataTe[0:5000]\n",
    "print(\"para entrenamiento tendremos: \"+str(len(porcion1))+ \" imagenes de la carpeta de train\")\n",
    "print(\"para prueba tendremos: \"+str(len(porcion2))+ \" imagenes de la carpeta de test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cccc92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e,y_e=particion(porcion1)\n",
    "x_p,y_p=particion(porcion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b06adaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacion(x_e,y_e,x_p,y_p,modelo1,epocas):\n",
    "    entre=modelo1.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
    "    a=modelo1.evaluate(x_p,y_p)\n",
    "    return a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa8b8412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion(modelo1,porcentaje,nombre,v1,v2):\n",
    "    prediccion=0\n",
    "    epocas=1\n",
    "    while(True):\n",
    "        if prediccion < porcentaje:\n",
    "            prediccion=(validacion(x_e,y_e,x_p,y_p,modelo1,1))*100\n",
    "            epocas +=1\n",
    "            v1.append(epocas-1)\n",
    "            v2.append(prediccion)\n",
    "        else:\n",
    "            print(\"==> Para el metodo \"+nombre+\" se utilizo: \"+str(epocas-1)+\" epocas para llegar a mas del \"+str(porcentaje)+\"% de acertividad\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a98edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 222, 222, 8)       224       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 220, 220, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 218, 218, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 380192)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               48664704  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 70)                9030      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 48,679,837\n",
      "Trainable params: 48,679,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo=Sequential()\n",
    "modelo.add(Convolution2D(8,(3,3),input_shape=(224,224,3),activation='relu'))\n",
    "modelo.add(Convolution2D(16,(3,3),activation='relu'))\n",
    "modelo.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(128,activation='relu'))\n",
    "modelo.add(Dense(70,activation='relu'))\n",
    "modelo.add(Dense(1,activation='sigmoid'))\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355d8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 265s 22ms/sample - loss: 6.3497 - acc: 0.6776 - val_loss: 0.5185 - val_acc: 0.7696\n",
      "5000/5000 [==============================] - 15s 3ms/sample - loss: 0.5185 - acc: 0.7696\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 266s 22ms/sample - loss: 0.3397 - acc: 0.8593 - val_loss: 0.5394 - val_acc: 0.7776\n",
      "5000/5000 [==============================] - 15s 3ms/sample - loss: 0.5394 - acc: 0.7776\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 270s 22ms/sample - loss: 0.1627 - acc: 0.9507 - val_loss: 0.7298 - val_acc: 0.7848\n",
      "5000/5000 [==============================] - 15s 3ms/sample - loss: 0.7298 - acc: 0.7848\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 280s 23ms/sample - loss: 0.0540 - acc: 0.9861 - val_loss: 0.9224 - val_acc: 0.7926\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 0.9224 - acc: 0.7926\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 283s 24ms/sample - loss: 0.0725 - acc: 0.9808 - val_loss: 0.8687 - val_acc: 0.7626\n",
      "5000/5000 [==============================] - 18s 4ms/sample - loss: 0.8687 - acc: 0.7626\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 284s 24ms/sample - loss: 0.0799 - acc: 0.9792 - val_loss: 0.8365 - val_acc: 0.7748\n",
      "5000/5000 [==============================] - 18s 4ms/sample - loss: 0.8365 - acc: 0.7748\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 284s 24ms/sample - loss: 0.0156 - acc: 0.9961 - val_loss: 1.1899 - val_acc: 0.7824\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.1899 - acc: 0.7824\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 283s 24ms/sample - loss: 0.0184 - acc: 0.9954 - val_loss: 0.9334 - val_acc: 0.7750\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 0.9334 - acc: 0.7750\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 279s 23ms/sample - loss: 0.0748 - acc: 0.9779 - val_loss: 1.1100 - val_acc: 0.7744\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.1100 - acc: 0.7744\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 279s 23ms/sample - loss: 0.0395 - acc: 0.9900 - val_loss: 1.2747 - val_acc: 0.7526\n",
      "5000/5000 [==============================] - 16s 3ms/sample - loss: 1.2747 - acc: 0.7526\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 279s 23ms/sample - loss: 0.0300 - acc: 0.9942 - val_loss: 1.2990 - val_acc: 0.7464\n",
      "5000/5000 [==============================] - 16s 3ms/sample - loss: 1.2990 - acc: 0.7464\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 279s 23ms/sample - loss: 0.0143 - acc: 0.9964 - val_loss: 1.2803 - val_acc: 0.7740\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.2803 - acc: 0.7740\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 280s 23ms/sample - loss: 0.0635 - acc: 0.9822 - val_loss: 1.2185 - val_acc: 0.7628\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.2185 - acc: 0.7628\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 282s 23ms/sample - loss: 0.0165 - acc: 0.9959 - val_loss: 1.1415 - val_acc: 0.7434\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.1415 - acc: 0.7434\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 278s 23ms/sample - loss: 0.0192 - acc: 0.9952 - val_loss: 1.3932 - val_acc: 0.7900\n",
      "5000/5000 [==============================] - 15s 3ms/sample - loss: 1.3932 - acc: 0.7900\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 272s 23ms/sample - loss: 0.0060 - acc: 0.9987 - val_loss: 1.4809 - val_acc: 0.7720\n",
      "5000/5000 [==============================] - 15s 3ms/sample - loss: 1.4809 - acc: 0.7720\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 274s 23ms/sample - loss: 0.0803 - acc: 0.9822 - val_loss: 1.3302 - val_acc: 0.7494\n",
      "5000/5000 [==============================] - 16s 3ms/sample - loss: 1.3302 - acc: 0.7494\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 279s 23ms/sample - loss: 0.0383 - acc: 0.9895 - val_loss: 1.2052 - val_acc: 0.7648\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.2052 - acc: 0.7648\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 282s 23ms/sample - loss: 0.0100 - acc: 0.9972 - val_loss: 1.4296 - val_acc: 0.7776\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.4296 - acc: 0.7776\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 283s 24ms/sample - loss: 0.0544 - acc: 0.9856 - val_loss: 1.2567 - val_acc: 0.7468\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.2567 - acc: 0.7468\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 283s 24ms/sample - loss: 0.0060 - acc: 0.9986 - val_loss: 1.4208 - val_acc: 0.7538\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.4208 - acc: 0.7538\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 280s 23ms/sample - loss: 7.8745e-04 - acc: 0.9998 - val_loss: 1.5353 - val_acc: 0.7582\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.5353 - acc: 0.7582\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 281s 23ms/sample - loss: 4.7833e-04 - acc: 0.9999 - val_loss: 1.5572 - val_acc: 0.7736\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.5572 - acc: 0.7736\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 280s 23ms/sample - loss: 8.8788e-05 - acc: 1.0000 - val_loss: 1.5924 - val_acc: 0.7742\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.5924 - acc: 0.7742\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 280s 23ms/sample - loss: 6.0342e-05 - acc: 1.0000 - val_loss: 1.6256 - val_acc: 0.7760\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.6256 - acc: 0.7760\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 280s 23ms/sample - loss: 3.5915e-05 - acc: 1.0000 - val_loss: 1.6561 - val_acc: 0.7770\n",
      "5000/5000 [==============================] - 17s 3ms/sample - loss: 1.6561 - acc: 0.7770\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      "12000/12000 [==============================] - 278s 23ms/sample - loss: 2.6658e-05 - acc: 1.0000 - val_loss: 1.6858 - val_acc: 0.7766\n",
      "5000/5000 [==============================] - 16s 3ms/sample - loss: 1.6858 - acc: 0.7766\n",
      "Train on 12000 samples, validate on 5000 samples\n",
      " 3264/12000 [=======>......................] - ETA: 3:11 - loss: 1.6075e-05 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_8388\\1455346729.py\", line 5, in <module>\n",
      "    evaluacion(modelo,82,\"ADAM\",v_eA,v_aA)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_8388\\1593769438.py\", line 6, in evaluacion\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo1,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_8388\\2085629365.py\", line 2, in validacion\n",
      "    entre=modelo1.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\contrib\\__init__.py\", line 39, in <module>\n",
      "    from tensorflow.contrib import compiler\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\contrib\\compiler\\__init__.py\", line 21, in <module>\n",
      "    from tensorflow.contrib.compiler import jit\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\contrib\\compiler\\__init__.py\", line 22, in <module>\n",
      "    from tensorflow.contrib.compiler import xla\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\contrib\\compiler\\xla.py\", line 22, in <module>\n",
      "    from tensorflow.python.estimator import model_fn as model_fn_lib\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\estimator\\model_fn.py\", line 26, in <module>\n",
      "    from tensorflow_estimator.python.estimator import model_fn\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow_estimator._api.v1 import estimator\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow_estimator._api.v1.estimator import experimental\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\experimental\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\", line 27, in <module>\n",
      "    from tensorflow_estimator.python.estimator import estimator\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 36, in <module>\n",
      "    from tensorflow.python.profiler import trace\n",
      "ImportError: cannot import name 'trace' from 'tensorflow.python.profiler' (C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\profiler\\__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_8388\\1455346729.py\", line 5, in <module>\n",
      "    evaluacion(modelo,82,\"ADAM\",v_eA,v_aA)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_8388\\1593769438.py\", line 6, in evaluacion\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo1,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_8388\\2085629365.py\", line 2, in validacion\n",
      "    entre=modelo1.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_8388\\1455346729.py\", line 5, in <module>\n",
      "    evaluacion(modelo,82,\"ADAM\",v_eA,v_aA)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_8388\\1593769438.py\", line 6, in evaluacion\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo1,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_8388\\2085629365.py\", line 2, in validacion\n",
      "    entre=modelo1.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\tesis\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "modelo_adam = keras.optimizers.Adam(learning_rate=0.0008)\n",
    "modelo.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "v_eA=[]\n",
    "v_aA=[]\n",
    "evaluacion(modelo,82,\"ADAM\",v_eA,v_aA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5dacc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save(\"D:/UMSA/Documentos/CNN cancer de piel/MODELOS/17000_2/modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f346ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save_weights(\"D:/UMSA/Documentos/CNN cancer de piel/PESOS/17000_2/modelo_pesos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=1\n",
    "print(\"# de EPOCAS     Valor del Accuracy\")\n",
    "print(\"----------------------------------\")\n",
    "for i in v_aA:\n",
    "    print(\"epoca \",count,\" => \",i)\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fea0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot(v_aA,v_eA, marker='o', linestyle=':', color='b', label = \"ADAM\")\n",
    "\n",
    "#mp.xticks(np.arange(70,100,2))\n",
    "#mp.yticks(np.arange(0,4,1))\n",
    "mp.xlabel(\"porcentaje de asertividad\")\n",
    "mp.ylabel(\"Numero de epocas\")\n",
    "mp.legend(loc=\"upper left\")\n",
    "mp.title(\"Nivel de asertividad y epocas con 10000 imagenes\")\n",
    "mp.grid(True)\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cargado=keras.models.load_model(\"D:/UMSA/Documentos/CNN cancer de piel/MODELOS/12500/modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aec762",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cargado.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a94bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot(v_aA,v_eA, marker='o', linestyle=':', color='b', label = \"ADAM\")\n",
    "\n",
    "#mp.xticks(np.arange(70,100,2))\n",
    "#mp.yticks(np.arange(0,4,1))\n",
    "mp.xlabel(\"porcentaje de asertividad\")\n",
    "mp.ylabel(\"Numero de epocas\")\n",
    "mp.legend(loc=\"upper left\")\n",
    "mp.title(\"Nivel de asertividad y epocas con 17000 imagenes\")\n",
    "mp.grid(True)\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22268183",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = modelo.predict_proba(x_p)\n",
    "lr_probs = lr_probs[:, 0]\n",
    "ns_probs = [0 for _ in range(len(y_p))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b207ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a674a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el AUC\n",
    "ns_auc = roc_auc_score(y_p, ns_probs)\n",
    "lr_auc = roc_auc_score(y_p, lr_probs)\n",
    "# Imprimimos en pantalla\n",
    "print('Sin entrenar: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Red Neuronal: ROC AUC=%.3f' % (lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos las curvas ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_p, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_p, lr_probs)\n",
    "# Pintamos las curvas ROC\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Sin entrenar')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Red Neuronal')\n",
    "# Etiquetas de los ejes\n",
    "pyplot.xlabel('Tasa de Falsos Positivos')\n",
    "pyplot.ylabel('Tasa de Verdaderos Positivos')\n",
    "pyplot.legend()\n",
    "mp.grid(True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = modelo.predict_proba(x_p)\n",
    "# Nos quedamos unicamente con las predicciones positicas\n",
    "lr_probs = lr_probs[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce60d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = modelo.predict(x_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_p, lr_probs)\n",
    "lr_auc =  auc(lr_recall, lr_precision)\n",
    "no_skill = len(y_p[y_p==1]) / len(y_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feaeb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Redes neuronales: auc=%.3f' % (lr_auc))\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='Sin entrenar')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='Redes Neuronales')\n",
    "#Etiquetas de ejes\n",
    "pyplot.xlabel('Sensibilidad')\n",
    "pyplot.ylabel('Precisi√≥n')\n",
    "pyplot.legend()\n",
    "mp.grid(True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f0d51",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
