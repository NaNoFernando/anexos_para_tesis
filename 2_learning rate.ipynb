{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02b0a65",
   "metadata": {},
   "source": [
    "# Probaremos el grado de nivel de aprendisaje, este no deberia ser muy alto o peque√±o\n",
    "### hay que tomar en cuenta que el grado se encuentra entre 0.000001 y 0.99999\n",
    "### probaremos entre intervalos de valores y el accuracy mas alto sera la prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "178649fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6561f4",
   "metadata": {},
   "source": [
    "## Nuevamente tomaremos 1000 imagenes como prueba de laboratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "806b9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "Y_train=[]\n",
    "dataTr=[]\n",
    "for filename in glob.glob(os.path.join('data/train/malignant','*.jpg')):\n",
    "    dataTr.append([1,cv2.imread(filename)])\n",
    "for filename in glob.glob(os.path.join('data/train/benign','*.jpg')):\n",
    "    dataTr.append([0,cv2.imread(filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f68dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en total tenemos: 2637 imagenes dentro de la carpeta train\n"
     ]
    }
   ],
   "source": [
    "shuffle(dataTr)\n",
    "print(\"en total tenemos: \"+str(len(dataTr))+ \" imagenes dentro de la carpeta train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e8cba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para entrenamiento tendremos: 700 imagenes de la carpeta de train\n",
      "para prueba tendremos: 300 imagenes de la carpeta de train\n"
     ]
    }
   ],
   "source": [
    "porcion1=dataTr[0:700]\n",
    "porcion2=dataTr[701:1001]\n",
    "print(\"para entrenamiento tendremos: \"+str(len(porcion1))+ \" imagenes de la carpeta de train\")\n",
    "print(\"para prueba tendremos: \"+str(len(porcion2))+ \" imagenes de la carpeta de train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7418a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particion(datos):\n",
    "    imagenes=[]\n",
    "    etiquetas=[]\n",
    "    for i,j in datos:\n",
    "        imagenes.append(j)\n",
    "        etiquetas.append(i)\n",
    "    imagenes=np.array(imagenes)\n",
    "    etiquetas=np.array(etiquetas)\n",
    "    return (imagenes,etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbefb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e,y_e=particion(porcion1)\n",
    "x_p,y_p=particion(porcion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef61b01",
   "metadata": {},
   "source": [
    "## Crearemos la convolucion y la RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44b827d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creacion_modelo():\n",
    "    modelo=Sequential()\n",
    "    modelo.add(Convolution2D(32,(3,3),input_shape=(224,224,3),activation='relu'))\n",
    "    modelo.add(MaxPooling2D(pool_size=((2,2))))\n",
    "    modelo.add(Flatten())\n",
    "    modelo.add(Dense(128,activation='relu'))\n",
    "    modelo.add(Dense(50,activation='relu'))\n",
    "    modelo.add(Dense(1,activation='sigmoid'))\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5929f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacion(x_e,y_e,x_p,y_p,model,epocas):\n",
    "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
    "    a=model.evaluate(x_p,y_p)\n",
    "    return a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e4ca6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalucion(modelo,porcentaje,nombre,indice):\n",
    "    prediccion=0\n",
    "    epocas=1\n",
    "    for i in range (11):\n",
    "        if prediccion < porcentaje:\n",
    "            prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,i))*100\n",
    "            if i==10:\n",
    "                print(\"No se pudo encontrar el porcentaje adecuado en 10 epocas PASANDO A otro LR\")\n",
    "        else:\n",
    "            print(\"************Para el metodo \"+nombre+\" se utilizo: \"+str(i)+\" epocas para llegar a mas del \"+str(porcentaje)+\"% de acertividad con el indice LR= \"+str(indice))\n",
    "            break   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec3fc82",
   "metadata": {},
   "source": [
    "## ajustamos el learning read =lr para ADAM, pues es el metodo de desenso de gradiante mas optimo para nuestro caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58da1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3a48594",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=[0.002,0.004,0.006,0.008,0.01]\n",
    "vector2=[0.02,0.04,0.06,0.08,0.1]\n",
    "vector3=[0.0002,0.0004,0.0006,0.0008,0.0009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de51afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 17.2984 - acc: 0.4467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 1169.8604 - acc: 0.5429 - val_loss: 6.7657 - val_acc: 0.6700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 6.7657 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 1.5079 - acc: 0.8014 - val_loss: 1.3649 - val_acc: 0.7600\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.7974 - acc: 0.8600 - val_loss: 1.2361 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.2361 - acc: 0.7300\n",
      "************Para el metodo ADAM se utilizo: 3 epocas para llegar a mas del 70% de acertividad con el indice LR= 0.002\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 9.0032 - acc: 0.5533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 3002.5026 - acc: 0.5300 - val_loss: 2.6703 - val_acc: 0.4267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.6703 - acc: 0.4267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 4.0888 - acc: 0.4743 - val_loss: 0.8914 - val_acc: 0.7433\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5732 - acc: 0.7671 - val_loss: 0.6629 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6629 - acc: 0.7100\n",
      "************Para el metodo ADAM se utilizo: 3 epocas para llegar a mas del 70% de acertividad con el indice LR= 0.004\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 40.1281 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 6428.9206 - acc: 0.5557 - val_loss: 0.8629 - val_acc: 0.5967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8629 - acc: 0.5967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6768 - acc: 0.6029 - val_loss: 0.6524 - val_acc: 0.6400\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6027 - acc: 0.6700 - val_loss: 0.6166 - val_acc: 0.6533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6166 - acc: 0.6533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6150 - acc: 0.6671 - val_loss: 0.6549 - val_acc: 0.6000\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6376 - acc: 0.6243 - val_loss: 0.6530 - val_acc: 0.6133\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6321 - acc: 0.6300 - val_loss: 0.6546 - val_acc: 0.6133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6546 - acc: 0.6133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6268 - acc: 0.6314 - val_loss: 0.6572 - val_acc: 0.6167\n",
      "Epoch 2/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6227 - acc: 0.6371 - val_loss: 0.6537 - val_acc: 0.6300\n",
      "Epoch 3/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5994 - acc: 0.6686 - val_loss: 0.6563 - val_acc: 0.6100\n",
      "Epoch 4/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6163 - acc: 0.6357 - val_loss: 0.6553 - val_acc: 0.6133\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6553 - acc: 0.6133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6134 - acc: 0.6371 - val_loss: 0.6587 - val_acc: 0.6133\n",
      "Epoch 2/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6104 - acc: 0.6371 - val_loss: 0.6630 - val_acc: 0.6133\n",
      "Epoch 3/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6088 - acc: 0.6371 - val_loss: 0.6702 - val_acc: 0.6133\n",
      "Epoch 4/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6078 - acc: 0.6386 - val_loss: 0.6837 - val_acc: 0.6133\n",
      "Epoch 5/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6069 - acc: 0.6386 - val_loss: 0.7035 - val_acc: 0.6100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7035 - acc: 0.6100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6080 - acc: 0.6386 - val_loss: 0.7154 - val_acc: 0.6067\n",
      "Epoch 2/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6089 - acc: 0.6386 - val_loss: 0.7286 - val_acc: 0.6067\n",
      "Epoch 3/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6054 - acc: 0.6386 - val_loss: 0.7407 - val_acc: 0.6100\n",
      "Epoch 4/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6044 - acc: 0.6386 - val_loss: 0.7421 - val_acc: 0.6067\n",
      "Epoch 5/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6030 - acc: 0.6386 - val_loss: 0.7493 - val_acc: 0.6100\n",
      "Epoch 6/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6026 - acc: 0.6386 - val_loss: 0.7545 - val_acc: 0.6067\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7545 - acc: 0.6067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6075 - acc: 0.6386 - val_loss: 0.7685 - val_acc: 0.6100\n",
      "Epoch 2/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6050 - acc: 0.6386 - val_loss: 0.7703 - val_acc: 0.6100\n",
      "Epoch 3/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6027 - acc: 0.6386 - val_loss: 0.7780 - val_acc: 0.6067\n",
      "Epoch 4/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6023 - acc: 0.6386 - val_loss: 0.7864 - val_acc: 0.6100\n",
      "Epoch 5/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6035 - acc: 0.6386 - val_loss: 0.7942 - val_acc: 0.6033\n",
      "Epoch 6/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6014 - acc: 0.6386 - val_loss: 0.8047 - val_acc: 0.6067\n",
      "Epoch 7/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6039 - acc: 0.6386 - val_loss: 0.8094 - val_acc: 0.6033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8094 - acc: 0.6033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6079 - acc: 0.6386 - val_loss: 0.8269 - val_acc: 0.6133\n",
      "Epoch 2/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6050 - acc: 0.6386 - val_loss: 0.8060 - val_acc: 0.6000\n",
      "Epoch 3/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6025 - acc: 0.6386 - val_loss: 0.8103 - val_acc: 0.6000\n",
      "Epoch 4/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6022 - acc: 0.6386 - val_loss: 0.8172 - val_acc: 0.6000\n",
      "Epoch 5/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6005 - acc: 0.6386 - val_loss: 0.8248 - val_acc: 0.6000\n",
      "Epoch 6/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6016 - acc: 0.6386 - val_loss: 0.8293 - val_acc: 0.5967\n",
      "Epoch 7/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6008 - acc: 0.6386 - val_loss: 0.8362 - val_acc: 0.6000\n",
      "Epoch 8/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6025 - acc: 0.6386 - val_loss: 0.8419 - val_acc: 0.5967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8419 - acc: 0.5967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6011 - acc: 0.6386 - val_loss: 0.8472 - val_acc: 0.6000\n",
      "Epoch 2/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6007 - acc: 0.6386 - val_loss: 0.8528 - val_acc: 0.6000\n",
      "Epoch 3/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6011 - acc: 0.6386 - val_loss: 0.8597 - val_acc: 0.6033\n",
      "Epoch 4/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6003 - acc: 0.6386 - val_loss: 0.8659 - val_acc: 0.6000\n",
      "Epoch 5/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6001 - acc: 0.6400 - val_loss: 0.8758 - val_acc: 0.6000\n",
      "Epoch 6/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5996 - acc: 0.6400 - val_loss: 0.8893 - val_acc: 0.6033\n",
      "Epoch 7/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6004 - acc: 0.6400 - val_loss: 0.8917 - val_acc: 0.5967\n",
      "Epoch 8/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6009 - acc: 0.6400 - val_loss: 0.8972 - val_acc: 0.6000\n",
      "Epoch 9/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5994 - acc: 0.6400 - val_loss: 0.9048 - val_acc: 0.5967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9048 - acc: 0.5967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5982 - acc: 0.6400 - val_loss: 0.9130 - val_acc: 0.6000\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5985 - acc: 0.6400 - val_loss: 0.9183 - val_acc: 0.6033\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5982 - acc: 0.6400 - val_loss: 0.9226 - val_acc: 0.6067\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5984 - acc: 0.6400 - val_loss: 0.9288 - val_acc: 0.6000\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5988 - acc: 0.6400 - val_loss: 0.9363 - val_acc: 0.6000\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5985 - acc: 0.6400 - val_loss: 0.9377 - val_acc: 0.5967\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5989 - acc: 0.6400 - val_loss: 0.9412 - val_acc: 0.6000\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5984 - acc: 0.6400 - val_loss: 0.9461 - val_acc: 0.6000\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5983 - acc: 0.6400 - val_loss: 0.9500 - val_acc: 0.6000\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5985 - acc: 0.6400 - val_loss: 0.9593 - val_acc: 0.6033\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.9593 - acc: 0.6033\n",
      "No se pudo encontrar el porcentaje adecuado en 10 epocas PASANDO A otro LR\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 58.1085 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 5152.7666 - acc: 0.4571 - val_loss: 0.6807 - val_acc: 0.4433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6807 - acc: 0.4433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6634 - acc: 0.6229 - val_loss: 0.6765 - val_acc: 0.5767\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6718 - acc: 0.6214 - val_loss: 0.6600 - val_acc: 0.6000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6600 - acc: 0.6000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6867 - acc: 0.6329 - val_loss: 0.6647 - val_acc: 0.5833\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.8408 - acc: 0.5971 - val_loss: 0.6789 - val_acc: 0.5733\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 2.8959 - acc: 0.6114 - val_loss: 0.6636 - val_acc: 0.6100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6636 - acc: 0.6100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6701 - acc: 0.5714 - val_loss: 0.6976 - val_acc: 0.5733\n",
      "Epoch 2/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6571 - acc: 0.6043 - val_loss: 0.6952 - val_acc: 0.5800\n",
      "Epoch 3/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6369 - acc: 0.6186 - val_loss: 0.6582 - val_acc: 0.5933\n",
      "Epoch 4/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6016 - acc: 0.6571 - val_loss: 0.6319 - val_acc: 0.6233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6319 - acc: 0.6233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5772 - acc: 0.6800 - val_loss: 0.6360 - val_acc: 0.6333\n",
      "Epoch 2/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5425 - acc: 0.7129 - val_loss: 0.6401 - val_acc: 0.6467\n",
      "Epoch 3/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5787 - acc: 0.7243 - val_loss: 0.6502 - val_acc: 0.6300\n",
      "Epoch 4/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5830 - acc: 0.6714 - val_loss: 0.6495 - val_acc: 0.6167\n",
      "Epoch 5/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5498 - acc: 0.7214 - val_loss: 0.6618 - val_acc: 0.6100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6618 - acc: 0.6100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5511 - acc: 0.6943 - val_loss: 0.6386 - val_acc: 0.6567\n",
      "Epoch 2/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.4943 - acc: 0.7471 - val_loss: 0.6693 - val_acc: 0.6267\n",
      "Epoch 3/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5143 - acc: 0.7329 - val_loss: 1.1634 - val_acc: 0.6600\n",
      "Epoch 4/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5396 - acc: 0.7243 - val_loss: 0.9555 - val_acc: 0.6167\n",
      "Epoch 5/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6144 - acc: 0.7329 - val_loss: 0.6660 - val_acc: 0.6000\n",
      "Epoch 6/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5974 - acc: 0.6557 - val_loss: 0.6625 - val_acc: 0.5967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6625 - acc: 0.5967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5721 - acc: 0.6757 - val_loss: 0.6330 - val_acc: 0.6233\n",
      "Epoch 2/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5067 - acc: 0.7386 - val_loss: 0.6631 - val_acc: 0.6133\n",
      "Epoch 3/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5884 - acc: 0.6614 - val_loss: 0.6645 - val_acc: 0.5967\n",
      "Epoch 4/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5602 - acc: 0.6857 - val_loss: 0.6417 - val_acc: 0.6400\n",
      "Epoch 5/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6387 - acc: 0.7314 - val_loss: 0.6839 - val_acc: 0.5800\n",
      "Epoch 6/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6617 - acc: 0.5886 - val_loss: 0.6795 - val_acc: 0.5700\n",
      "Epoch 7/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6537 - acc: 0.5971 - val_loss: 0.6791 - val_acc: 0.5733\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6791 - acc: 0.5733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6487 - acc: 0.6129 - val_loss: 0.7662 - val_acc: 0.5767\n",
      "Epoch 2/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6340 - acc: 0.6114 - val_loss: 0.8912 - val_acc: 0.5900\n",
      "Epoch 3/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6438 - acc: 0.6171 - val_loss: 0.6637 - val_acc: 0.5867\n",
      "Epoch 4/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6390 - acc: 0.6100 - val_loss: 0.7806 - val_acc: 0.5867\n",
      "Epoch 5/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6332 - acc: 0.6257 - val_loss: 0.6709 - val_acc: 0.5800\n",
      "Epoch 6/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6484 - acc: 0.5971 - val_loss: 0.6726 - val_acc: 0.5733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6480 - acc: 0.5957 - val_loss: 0.6724 - val_acc: 0.5733\n",
      "Epoch 8/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6462 - acc: 0.5957 - val_loss: 0.6704 - val_acc: 0.5767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6704 - acc: 0.5767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6453 - acc: 0.5957 - val_loss: 0.6698 - val_acc: 0.5767\n",
      "Epoch 2/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6458 - acc: 0.5957 - val_loss: 0.6698 - val_acc: 0.5767\n",
      "Epoch 3/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6452 - acc: 0.5957 - val_loss: 0.6700 - val_acc: 0.5767\n",
      "Epoch 4/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6444 - acc: 0.5957 - val_loss: 0.6705 - val_acc: 0.5767\n",
      "Epoch 5/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6440 - acc: 0.5957 - val_loss: 0.6699 - val_acc: 0.5767\n",
      "Epoch 6/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6437 - acc: 0.5957 - val_loss: 0.6700 - val_acc: 0.5767\n",
      "Epoch 7/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6455 - acc: 0.5957 - val_loss: 0.6713 - val_acc: 0.5767\n",
      "Epoch 8/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6429 - acc: 0.5957 - val_loss: 0.6704 - val_acc: 0.5767\n",
      "Epoch 9/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6441 - acc: 0.5957 - val_loss: 0.6706 - val_acc: 0.5767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6706 - acc: 0.5767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6425 - acc: 0.5957 - val_loss: 0.6702 - val_acc: 0.5767\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6430 - acc: 0.5957 - val_loss: 0.6710 - val_acc: 0.5767\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6429 - acc: 0.5957 - val_loss: 0.6703 - val_acc: 0.5767\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6429 - acc: 0.5957 - val_loss: 0.6704 - val_acc: 0.5767\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6429 - acc: 0.5957 - val_loss: 0.6705 - val_acc: 0.5767\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6428 - acc: 0.5971 - val_loss: 0.6706 - val_acc: 0.5767\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6428 - acc: 0.5986 - val_loss: 0.6705 - val_acc: 0.5767\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6412 - acc: 0.5986 - val_loss: 0.6709 - val_acc: 0.5767\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6418 - acc: 0.5986 - val_loss: 0.6703 - val_acc: 0.5767\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6415 - acc: 0.5986 - val_loss: 0.6709 - val_acc: 0.5767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6709 - acc: 0.5767\n",
      "No se pudo encontrar el porcentaje adecuado en 10 epocas PASANDO A otro LR\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 22.4891 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 12810.7471 - acc: 0.5143 - val_loss: 0.7216 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.7216 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6019 - acc: 0.7057 - val_loss: 0.7868 - val_acc: 0.6200\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5081 - acc: 0.7543 - val_loss: 0.8523 - val_acc: 0.6267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.8523 - acc: 0.6267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.4338 - acc: 0.7900 - val_loss: 1.0931 - val_acc: 0.6333\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3917 - acc: 0.8114 - val_loss: 1.5057 - val_acc: 0.6333\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3780 - acc: 0.8200 - val_loss: 1.7217 - val_acc: 0.6167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7217 - acc: 0.6167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3509 - acc: 0.8286 - val_loss: 2.3356 - val_acc: 0.6100\n",
      "Epoch 2/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3346 - acc: 0.8357 - val_loss: 2.4203 - val_acc: 0.6300\n",
      "Epoch 3/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3273 - acc: 0.8371 - val_loss: 2.7827 - val_acc: 0.6100\n",
      "Epoch 4/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3139 - acc: 0.8457 - val_loss: 3.1309 - val_acc: 0.6267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.1309 - acc: 0.6267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2946 - acc: 0.8543 - val_loss: 3.8241 - val_acc: 0.5933\n",
      "Epoch 2/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2909 - acc: 0.8643 - val_loss: 3.6156 - val_acc: 0.6167\n",
      "Epoch 3/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2652 - acc: 0.8757 - val_loss: 4.4238 - val_acc: 0.6033\n",
      "Epoch 4/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.4864 - acc: 0.8729 - val_loss: 4.3530 - val_acc: 0.6133\n",
      "Epoch 5/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5085 - acc: 0.7743 - val_loss: 2.3819 - val_acc: 0.6200\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.3819 - acc: 0.6200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.4110 - acc: 0.8129 - val_loss: 2.7605 - val_acc: 0.6200\n",
      "Epoch 2/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3372 - acc: 0.8343 - val_loss: 3.1228 - val_acc: 0.6200\n",
      "Epoch 3/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2871 - acc: 0.8643 - val_loss: 4.2743 - val_acc: 0.6033\n",
      "Epoch 4/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2517 - acc: 0.8814 - val_loss: 5.1397 - val_acc: 0.6133\n",
      "Epoch 5/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2348 - acc: 0.8886 - val_loss: 5.8537 - val_acc: 0.6267\n",
      "Epoch 6/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2219 - acc: 0.8971 - val_loss: 6.7573 - val_acc: 0.6233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 6.7573 - acc: 0.6233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2038 - acc: 0.9043 - val_loss: 7.4311 - val_acc: 0.6200\n",
      "Epoch 2/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1889 - acc: 0.9114 - val_loss: 8.0517 - val_acc: 0.6133\n",
      "Epoch 3/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1787 - acc: 0.9200 - val_loss: 8.6249 - val_acc: 0.6233\n",
      "Epoch 4/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1721 - acc: 0.9186 - val_loss: 8.5626 - val_acc: 0.6200\n",
      "Epoch 5/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1774 - acc: 0.9186 - val_loss: 8.9337 - val_acc: 0.6233\n",
      "Epoch 6/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1604 - acc: 0.9257 - val_loss: 11.3849 - val_acc: 0.6133\n",
      "Epoch 7/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1731 - acc: 0.9286 - val_loss: 11.2674 - val_acc: 0.6367\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 11.2674 - acc: 0.6367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1938 - acc: 0.9286 - val_loss: 11.0475 - val_acc: 0.6167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1720 - acc: 0.9171 - val_loss: 8.3997 - val_acc: 0.6133\n",
      "Epoch 3/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2718 - acc: 0.9043 - val_loss: 8.3817 - val_acc: 0.6167\n",
      "Epoch 4/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 10.2879 - acc: 0.8500 - val_loss: 2.6634 - val_acc: 0.6333\n",
      "Epoch 5/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.7364 - acc: 0.7857 - val_loss: 1.5431 - val_acc: 0.6267\n",
      "Epoch 6/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.4841 - acc: 0.7871 - val_loss: 2.3257 - val_acc: 0.6400\n",
      "Epoch 7/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3678 - acc: 0.8114 - val_loss: 3.1727 - val_acc: 0.6267\n",
      "Epoch 8/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3187 - acc: 0.8429 - val_loss: 4.3967 - val_acc: 0.6433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 4.3967 - acc: 0.6433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2738 - acc: 0.8857 - val_loss: 6.6142 - val_acc: 0.6233\n",
      "Epoch 2/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2021 - acc: 0.9114 - val_loss: 7.2342 - val_acc: 0.6100\n",
      "Epoch 3/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1778 - acc: 0.9171 - val_loss: 8.9960 - val_acc: 0.6067\n",
      "Epoch 4/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2065 - acc: 0.9057 - val_loss: 5.0767 - val_acc: 0.6200\n",
      "Epoch 5/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2200 - acc: 0.8986 - val_loss: 7.1140 - val_acc: 0.6100\n",
      "Epoch 6/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1681 - acc: 0.9200 - val_loss: 7.6911 - val_acc: 0.6167\n",
      "Epoch 7/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1721 - acc: 0.9200 - val_loss: 8.0554 - val_acc: 0.6267\n",
      "Epoch 8/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1703 - acc: 0.9343 - val_loss: 11.1124 - val_acc: 0.5800\n",
      "Epoch 9/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.5554 - acc: 0.8857 - val_loss: 5.2493 - val_acc: 0.6100\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 5.2493 - acc: 0.6100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.3415 - acc: 0.8329 - val_loss: 5.9416 - val_acc: 0.6267\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2548 - acc: 0.8829 - val_loss: 9.9806 - val_acc: 0.6400\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2238 - acc: 0.9086 - val_loss: 10.2338 - val_acc: 0.6400\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1830 - acc: 0.9257 - val_loss: 10.9549 - val_acc: 0.6333\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1664 - acc: 0.9300 - val_loss: 12.4070 - val_acc: 0.6167\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.2141 - acc: 0.9243 - val_loss: 10.5853 - val_acc: 0.6333\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1391 - acc: 0.9343 - val_loss: 15.3133 - val_acc: 0.6300\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1398 - acc: 0.9414 - val_loss: 13.0420 - val_acc: 0.6167\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1147 - acc: 0.9471 - val_loss: 15.3220 - val_acc: 0.6300\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.1114 - acc: 0.9543 - val_loss: 14.4328 - val_acc: 0.6400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 14.4328 - acc: 0.6400\n",
      "No se pudo encontrar el porcentaje adecuado en 10 epocas PASANDO A otro LR\n"
     ]
    }
   ],
   "source": [
    "for i in (vector):\n",
    "    modelo1=creacion_modelo()\n",
    "    modelo_adam = keras.optimizers.Adam(learning_rate=i)\n",
    "    modelo1.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    evalucion(modelo1,70,\"ADAM\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12da2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 12.5130 - acc: 0.4500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 26716.3268 - acc: 0.4986 - val_loss: 0.6870 - val_acc: 0.5667\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6870 - acc: 0.5667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6885 - acc: 0.5486 - val_loss: 0.6870 - val_acc: 0.5533\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6805 - acc: 0.5629 - val_loss: 0.6757 - val_acc: 0.5833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6757 - acc: 0.5833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.7025 - acc: 0.6000 - val_loss: 0.6800 - val_acc: 0.5633\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6854 - acc: 0.5514 - val_loss: 0.6798 - val_acc: 0.5633\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6839 - acc: 0.5514 - val_loss: 0.6794 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6794 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6832 - acc: 0.5514 - val_loss: 0.6784 - val_acc: 0.5633\n",
      "Epoch 2/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6841 - acc: 0.5529 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "Epoch 3/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6838 - acc: 0.5357 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 4/4\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6832 - acc: 0.5529 - val_loss: 0.6778 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6778 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6834 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 2/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6824 - acc: 0.5529 - val_loss: 0.6785 - val_acc: 0.5633\n",
      "Epoch 3/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6836 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 4/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6816 - acc: 0.5529 - val_loss: 0.6781 - val_acc: 0.5633\n",
      "Epoch 5/5\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6826 - acc: 0.5529 - val_loss: 0.6781 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6781 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6815 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 2/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6820 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 3/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6840 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 4/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6812 - acc: 0.5529 - val_loss: 0.6792 - val_acc: 0.5633\n",
      "Epoch 5/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6831 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 6/6\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6821 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6776 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6840 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 2/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6825 - acc: 0.5529 - val_loss: 0.6779 - val_acc: 0.5633\n",
      "Epoch 3/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6824 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 4/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6834 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 5/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6824 - acc: 0.5529 - val_loss: 0.6779 - val_acc: 0.5633\n",
      "Epoch 6/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6825 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "Epoch 7/7\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6822 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6774 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6830 - acc: 0.5529 - val_loss: 0.6779 - val_acc: 0.5633\n",
      "Epoch 2/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6822 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 3/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6819 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 4/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6818 - acc: 0.5529 - val_loss: 0.6783 - val_acc: 0.5633\n",
      "Epoch 5/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6821 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 6/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6823 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 7/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6833 - acc: 0.5529 - val_loss: 0.6781 - val_acc: 0.5633\n",
      "Epoch 8/8\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6816 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6774 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6824 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "Epoch 2/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6822 - acc: 0.5529 - val_loss: 0.6781 - val_acc: 0.5633\n",
      "Epoch 3/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6822 - acc: 0.5529 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "Epoch 4/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6821 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 5/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6818 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 6/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6826 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 7/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6818 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 8/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6824 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 9/9\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6820 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6774 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6843 - acc: 0.5529 - val_loss: 0.6789 - val_acc: 0.5633\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6822 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6819 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6837 - acc: 0.5529 - val_loss: 0.6782 - val_acc: 0.5633\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6838 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6839 - acc: 0.5529 - val_loss: 0.6779 - val_acc: 0.5633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6828 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6820 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6820 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 7s 10ms/sample - loss: 0.6823 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6775 - acc: 0.5633\n",
      "No se pudo encontrar el porcentaje adecuado en 10 epocas PASANDO A otro LR\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 9.7061 - acc: 0.5533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 101031.0860 - acc: 0.5414 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6882 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6910 - acc: 0.5457 - val_loss: 1.3312 - val_acc: 0.5900\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.7022 - acc: 0.5457 - val_loss: 0.6849 - val_acc: 0.5567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6849 - acc: 0.5567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6890 - acc: 0.5486 - val_loss: 0.6812 - val_acc: 0.5600\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6845 - acc: 0.5514 - val_loss: 0.6794 - val_acc: 0.5633\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6852 - acc: 0.5286 - val_loss: 0.6780 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6780 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/4\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6844 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "Epoch 2/4\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6869 - acc: 0.5529 - val_loss: 0.6787 - val_acc: 0.5633\n",
      "Epoch 3/4\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6835 - acc: 0.5529 - val_loss: 0.6785 - val_acc: 0.5633\n",
      "Epoch 4/4\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6836 - acc: 0.5529 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6777 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/5\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6839 - acc: 0.5157 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 2/5\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6827 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 3/5\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6835 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 4/5\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6828 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 5/5\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6824 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6774 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/6\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6827 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 2/6\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6839 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 3/6\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6826 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "Epoch 4/6\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6834 - acc: 0.5529 - val_loss: 0.6792 - val_acc: 0.5633\n",
      "Epoch 5/6\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6826 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "Epoch 6/6\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6858 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6776 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/7\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6821 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 2/7\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6837 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 3/7\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6840 - acc: 0.5529 - val_loss: 0.6809 - val_acc: 0.5633\n",
      "Epoch 4/7\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6841 - acc: 0.5343 - val_loss: 0.6780 - val_acc: 0.5633\n",
      "Epoch 5/7\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6845 - acc: 0.5543 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 6/7\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6837 - acc: 0.5543 - val_loss: 0.6782 - val_acc: 0.5633\n",
      "Epoch 7/7\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6804 - acc: 0.5543 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6775 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/8\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6836 - acc: 0.5543 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 2/8\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6795 - acc: 0.5557 - val_loss: 0.6779 - val_acc: 0.5633\n",
      "Epoch 3/8\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6824 - acc: 0.5557 - val_loss: 0.6782 - val_acc: 0.5633\n",
      "Epoch 4/8\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6888 - acc: 0.5557 - val_loss: 0.6813 - val_acc: 0.5633\n",
      "Epoch 5/8\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6837 - acc: 0.5286 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "Epoch 6/8\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6804 - acc: 0.5557 - val_loss: 0.6779 - val_acc: 0.5633\n",
      "Epoch 7/8\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6819 - acc: 0.5557 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "Epoch 8/8\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6812 - acc: 0.5557 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6775 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/9\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6802 - acc: 0.5557 - val_loss: 0.6807 - val_acc: 0.5633\n",
      "Epoch 2/9\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6838 - acc: 0.5557 - val_loss: 0.6800 - val_acc: 0.5633\n",
      "Epoch 3/9\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6807 - acc: 0.5557 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 4/9\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6818 - acc: 0.5557 - val_loss: 0.6778 - val_acc: 0.5633\n",
      "Epoch 5/9\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6808 - acc: 0.5557 - val_loss: 0.6785 - val_acc: 0.5633\n",
      "Epoch 6/9\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6817 - acc: 0.5557 - val_loss: 0.6780 - val_acc: 0.5633\n",
      "Epoch 7/9\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6823 - acc: 0.5557 - val_loss: 0.6782 - val_acc: 0.5633\n",
      "Epoch 8/9\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6821 - acc: 0.5171 - val_loss: 0.6779 - val_acc: 0.5633\n",
      "Epoch 9/9\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6855 - acc: 0.5557 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6776 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6804 - acc: 0.5557 - val_loss: 0.6778 - val_acc: 0.5633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6800 - acc: 0.5557 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6802 - acc: 0.5557 - val_loss: 0.6779 - val_acc: 0.5633\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6804 - acc: 0.5557 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6813 - acc: 0.5557 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6802 - acc: 0.5557 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6805 - acc: 0.5557 - val_loss: 0.6783 - val_acc: 0.5633\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6821 - acc: 0.5557 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6814 - acc: 0.5557 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.6803 - acc: 0.5557 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6774 - acc: 0.5633\n",
      "No se pudo encontrar el porcentaje adecuado en 10 epocas PASANDO A otro LR\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 22.0400 - acc: 0.4533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 284345.6423 - acc: 0.5129 - val_loss: 0.6952 - val_acc: 0.5600\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6952 - acc: 0.5600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.9389 - acc: 0.5257 - val_loss: 0.6902 - val_acc: 0.5600\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 2060.2955 - acc: 0.5914 - val_loss: 0.6884 - val_acc: 0.5600\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6884 - acc: 0.5600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6913 - acc: 0.5500 - val_loss: 0.6802 - val_acc: 0.5633\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6841 - acc: 0.5529 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6829 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6775 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/4\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6830 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 2/4\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6821 - acc: 0.5529 - val_loss: 0.6779 - val_acc: 0.5633\n",
      "Epoch 3/4\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6839 - acc: 0.5529 - val_loss: 0.6786 - val_acc: 0.5633\n",
      "Epoch 4/4\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6828 - acc: 0.5529 - val_loss: 0.6778 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6778 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6864 - acc: 0.5529 - val_loss: 0.6780 - val_acc: 0.5633\n",
      "Epoch 2/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6840 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 3/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6842 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 4/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6824 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 5/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6823 - acc: 0.5529 - val_loss: 0.6780 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6780 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6827 - acc: 0.5529 - val_loss: 0.6778 - val_acc: 0.5633\n",
      "Epoch 2/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6834 - acc: 0.5529 - val_loss: 0.6794 - val_acc: 0.5633\n",
      "Epoch 3/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6834 - acc: 0.5529 - val_loss: 0.6791 - val_acc: 0.5633\n",
      "Epoch 4/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6814 - acc: 0.5529 - val_loss: 0.6788 - val_acc: 0.5633\n",
      "Epoch 5/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6844 - acc: 0.5529 - val_loss: 0.6783 - val_acc: 0.5633\n",
      "Epoch 6/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6835 - acc: 0.5529 - val_loss: 0.6779 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6779 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6850 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 2/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6826 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 3/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6845 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 4/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6832 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 5/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6829 - acc: 0.5529 - val_loss: 0.6781 - val_acc: 0.5633\n",
      "Epoch 6/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6827 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "Epoch 7/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6826 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6776 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6831 - acc: 0.5529 - val_loss: 0.6790 - val_acc: 0.5633\n",
      "Epoch 2/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6833 - acc: 0.5529 - val_loss: 0.6775 - val_acc: 0.5633\n",
      "Epoch 3/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6827 - acc: 0.5529 - val_loss: 0.6782 - val_acc: 0.5633\n",
      "Epoch 4/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6825 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "Epoch 5/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6825 - acc: 0.5529 - val_loss: 0.6781 - val_acc: 0.5633\n",
      "Epoch 6/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6829 - acc: 0.5529 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "Epoch 7/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6830 - acc: 0.5529 - val_loss: 0.6781 - val_acc: 0.5633\n",
      "Epoch 8/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6847 - acc: 0.5529 - val_loss: 0.6781 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6781 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6826 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 2/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6832 - acc: 0.5529 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "Epoch 3/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6842 - acc: 0.5286 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 4/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6831 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 5/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6833 - acc: 0.5529 - val_loss: 0.6797 - val_acc: 0.5633\n",
      "Epoch 6/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6837 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 7/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6844 - acc: 0.5529 - val_loss: 0.6789 - val_acc: 0.5633\n",
      "Epoch 8/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6837 - acc: 0.5529 - val_loss: 0.6813 - val_acc: 0.5633\n",
      "Epoch 9/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6852 - acc: 0.5529 - val_loss: 0.6777 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6777 - acc: 0.5633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6838 - acc: 0.5529 - val_loss: 0.6776 - val_acc: 0.5633\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6836 - acc: 0.5529 - val_loss: 0.6790 - val_acc: 0.5633\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6859 - acc: 0.4957 - val_loss: 0.6792 - val_acc: 0.5633\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6861 - acc: 0.5529 - val_loss: 0.6798 - val_acc: 0.5633\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6964 - acc: 0.4800 - val_loss: 0.6795 - val_acc: 0.5633\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6833 - acc: 0.5529 - val_loss: 0.6799 - val_acc: 0.5633\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6822 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6847 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6834 - acc: 0.5529 - val_loss: 0.6819 - val_acc: 0.5633\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6839 - acc: 0.5529 - val_loss: 0.6774 - val_acc: 0.5633\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6774 - acc: 0.5633\n",
      "No se pudo encontrar el porcentaje adecuado en 10 epocas PASANDO A otro LR\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 38.4470 - acc: 0.5533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 9s 12ms/sample - loss: 741444.7196 - acc: 0.5571 - val_loss: 0.6928 - val_acc: 0.5567\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6928 - acc: 0.5567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.7149 - acc: 0.5429 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 9s 12ms/sample - loss: 0.6898 - acc: 0.5443 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6883 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6896 - acc: 0.5443 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6899 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6908 - acc: 0.5443 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6889 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/4\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6898 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 2/4\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6918 - acc: 0.5443 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 3/4\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6903 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 4/4\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6899 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6882 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6905 - acc: 0.5443 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 2/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 3/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6907 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 4/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6906 - acc: 0.5443 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 5/5\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6930 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6882 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6916 - acc: 0.5443 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 2/6\n",
      "700/700 [==============================] - 9s 12ms/sample - loss: 0.6912 - acc: 0.5443 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 3/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6911 - acc: 0.5443 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 4/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6916 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 5/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6904 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 6/6\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6883 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6920 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 2/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6905 - acc: 0.5443 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 3/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 4/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 5/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6900 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 6/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6905 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 7/7\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6909 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6884 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6905 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 2/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6896 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 3/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6901 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 4/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6903 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 5/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6903 - acc: 0.5443 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 6/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6911 - acc: 0.5443 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 7/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6924 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 8/8\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6900 - acc: 0.5443 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6887 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6900 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 2/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6924 - acc: 0.5443 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 3/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6905 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 4/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6904 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 5/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6926 - acc: 0.5443 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 6/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6905 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 7/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6914 - acc: 0.5443 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 8/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6915 - acc: 0.5443 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 9/9\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6916 - acc: 0.5443 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6888 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6908 - acc: 0.5443 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6899 - acc: 0.5443 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6906 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6906 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6935 - acc: 0.5443 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6903 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6898 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6898 - acc: 0.5443 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6920 - acc: 0.5443 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6902 - acc: 0.5500\n",
      "No se pudo encontrar el porcentaje adecuado en 10 epocas PASANDO A otro LR\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 16.0291 - acc: 0.4500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 1150636.1293 - acc: 0.5071 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6887 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6952 - acc: 0.4986 - val_loss: 0.6925 - val_acc: 0.5500\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6884 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6905 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6905 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6940 - acc: 0.5443 - val_loss: 0.6906 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6906 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/4\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6951 - acc: 0.5329 - val_loss: 0.6969 - val_acc: 0.4500\n",
      "Epoch 2/4\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6919 - acc: 0.5186 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 3/4\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6903 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 4/4\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6898 - acc: 0.5443 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6883 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/5\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6900 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 2/5\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6914 - acc: 0.5443 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 3/5\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6944 - acc: 0.5443 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 4/5\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6921 - acc: 0.5443 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 5/5\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6910 - acc: 0.5443 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6885 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/6\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6915 - acc: 0.5443 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 2/6\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6901 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 3/6\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6906 - acc: 0.5443 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 4/6\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6932 - acc: 0.5443 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 5/6\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6918 - acc: 0.5443 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 6/6\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6923 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6881 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/7\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6902 - acc: 0.5443 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 2/7\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6901 - acc: 0.5443 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 3/7\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6935 - acc: 0.5443 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 4/7\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6906 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 5/7\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6900 - acc: 0.5443 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 6/7\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6906 - acc: 0.5443 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 7/7\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6904 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6882 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/8\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6901 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 2/8\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6908 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 3/8\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6927 - acc: 0.5443 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 4/8\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6930 - acc: 0.5186 - val_loss: 0.6891 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/8\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6949 - acc: 0.5443 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 6/8\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6909 - acc: 0.5443 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 7/8\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6923 - acc: 0.5443 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 8/8\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6882 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/9\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6911 - acc: 0.5443 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 2/9\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6911 - acc: 0.5443 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 3/9\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6933 - acc: 0.5443 - val_loss: 0.6929 - val_acc: 0.5500\n",
      "Epoch 4/9\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6978 - acc: 0.4843 - val_loss: 0.6930 - val_acc: 0.5500\n",
      "Epoch 5/9\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6944 - acc: 0.5443 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 6/9\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6915 - acc: 0.5443 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 7/9\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6907 - acc: 0.5071 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 8/9\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6952 - acc: 0.5443 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 9/9\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6916 - acc: 0.5186 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.6889 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6918 - acc: 0.5443 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6922 - acc: 0.5443 - val_loss: 0.6907 - val_acc: 0.5500\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6893 - acc: 0.5443 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6968 - acc: 0.5043 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6920 - acc: 0.5443 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6878 - acc: 0.5443 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6937 - acc: 0.5071 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6905 - acc: 0.5443 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 9s 13ms/sample - loss: 0.6892 - acc: 0.5443 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 0.6955 - acc: 0.5443 - val_loss: 0.6905 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 0.6905 - acc: 0.5500\n",
      "No se pudo encontrar el porcentaje adecuado en 10 epocas PASANDO A otro LR\n"
     ]
    }
   ],
   "source": [
    "for i in (vector2):\n",
    "    modelo1=creacion_modelo()\n",
    "    modelo_adam = keras.optimizers.Adam(learning_rate=i)\n",
    "    modelo1.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    evalucion(modelo1,70,\"ADAM\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192aa4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 4.4301 - acc: 0.4600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 185.0840 - acc: 0.6114 - val_loss: 63.9668 - val_acc: 0.6300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 63.9668 - acc: 0.6300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 48.8190 - acc: 0.7143 - val_loss: 25.7789 - val_acc: 0.7267\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 8s 12ms/sample - loss: 15.0369 - acc: 0.7743 - val_loss: 10.8375 - val_acc: 0.7400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 10.8375 - acc: 0.7400\n",
      "************Para el metodo ADAM se utilizo: 3 epocas para llegar a mas del 70% de acertividad con el indice LR= 0.0002\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 43.7190 - acc: 0.4500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 9s 12ms/sample - loss: 297.5882 - acc: 0.5471 - val_loss: 125.0189 - val_acc: 0.6333\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 125.0189 - acc: 0.6333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 9s 12ms/sample - loss: 87.3093 - acc: 0.7314 - val_loss: 46.3809 - val_acc: 0.6433\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 9s 12ms/sample - loss: 40.2683 - acc: 0.7086 - val_loss: 62.2785 - val_acc: 0.6033\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 62.2785 - acc: 0.6033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 10s 15ms/sample - loss: 40.7816 - acc: 0.7329 - val_loss: 25.5020 - val_acc: 0.7133\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 10s 15ms/sample - loss: 26.2069 - acc: 0.7571 - val_loss: 51.3407 - val_acc: 0.6500\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 10s 15ms/sample - loss: 15.7592 - acc: 0.8029 - val_loss: 21.9667 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 21.9667 - acc: 0.7300\n",
      "************Para el metodo ADAM se utilizo: 4 epocas para llegar a mas del 70% de acertividad con el indice LR= 0.0004\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 37.2698 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 754.2733 - acc: 0.5557 - val_loss: 392.3311 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 392.3311 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 256.7418 - acc: 0.6057 - val_loss: 194.0832 - val_acc: 0.6633\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 68.7483 - acc: 0.7157 - val_loss: 35.1369 - val_acc: 0.7533\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 35.1369 - acc: 0.7533\n",
      "************Para el metodo ADAM se utilizo: 3 epocas para llegar a mas del 70% de acertividad con el indice LR= 0.0006\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 33.7430 - acc: 0.4500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 775.3324 - acc: 0.4914 - val_loss: 507.0901 - val_acc: 0.5500\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 507.0901 - acc: 0.5500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 122.8930 - acc: 0.6686 - val_loss: 32.0765 - val_acc: 0.7600\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 24.5361 - acc: 0.7743 - val_loss: 50.9812 - val_acc: 0.6067\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 50.9812 - acc: 0.6067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 28.2899 - acc: 0.7343 - val_loss: 20.7573 - val_acc: 0.7567\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 12.6811 - acc: 0.7971 - val_loss: 10.3714 - val_acc: 0.7733\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 10.9604 - acc: 0.8086 - val_loss: 24.4908 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 24.4908 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/4\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 10.8332 - acc: 0.8171 - val_loss: 36.8910 - val_acc: 0.6767\n",
      "Epoch 2/4\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 3.8455 - acc: 0.8943 - val_loss: 6.8124 - val_acc: 0.7633\n",
      "Epoch 3/4\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.7285 - acc: 0.9443 - val_loss: 6.9088 - val_acc: 0.7467\n",
      "Epoch 4/4\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.6845 - acc: 0.9500 - val_loss: 6.4317 - val_acc: 0.7567\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 6.4317 - acc: 0.7567\n",
      "************Para el metodo ADAM se utilizo: 5 epocas para llegar a mas del 70% de acertividad con el indice LR= 0.0008\n",
      "Train on 700 samples, validate on 300 samples\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 10.5983 - acc: 0.4433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 10s 15ms/sample - loss: 1593.9061 - acc: 0.5457 - val_loss: 83.9322 - val_acc: 0.6467\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 83.9322 - acc: 0.6467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/2\n",
      "700/700 [==============================] - 10s 14ms/sample - loss: 59.6779 - acc: 0.7243 - val_loss: 27.3070 - val_acc: 0.7433\n",
      "Epoch 2/2\n",
      "700/700 [==============================] - 10s 14ms/sample - loss: 21.3095 - acc: 0.7629 - val_loss: 47.0795 - val_acc: 0.6100\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 47.0795 - acc: 0.6100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3\n",
      "700/700 [==============================] - 10s 14ms/sample - loss: 11.6234 - acc: 0.7800 - val_loss: 76.7428 - val_acc: 0.4933\n",
      "Epoch 2/3\n",
      "700/700 [==============================] - 10s 14ms/sample - loss: 21.5045 - acc: 0.7457 - val_loss: 42.5242 - val_acc: 0.6800\n",
      "Epoch 3/3\n",
      "700/700 [==============================] - 10s 14ms/sample - loss: 14.1188 - acc: 0.8257 - val_loss: 9.3032 - val_acc: 0.7567\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 9.3032 - acc: 0.7567\n",
      "************Para el metodo ADAM se utilizo: 4 epocas para llegar a mas del 70% de acertividad con el indice LR= 0.0009\n"
     ]
    }
   ],
   "source": [
    "for i in (vector3):\n",
    "    modelo1=creacion_modelo()\n",
    "    modelo_adam = keras.optimizers.Adam(learning_rate=i)\n",
    "    modelo1.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    evalucion(modelo1,70,\"ADAM\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79693fe",
   "metadata": {},
   "source": [
    "## Para Graficar los candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbbc82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_candidatos=[0.0008,0.0009,0.001,0.002,0.003,0.004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c13e2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion_candidatos(modelo,porcentaje,nombre,v1,v2):\n",
    "    prediccion=0\n",
    "    epocas=1\n",
    "    while(True):\n",
    "        if prediccion < porcentaje:\n",
    "            prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
    "            epocas +=1\n",
    "            v1.append(epocas-1)\n",
    "            v2.append(prediccion)\n",
    "        else:\n",
    "            print(\"==> Para el metodo \"+nombre+\" se utilizo: \"+str(epocas-1)+\" epocas para llegar a mas del \"+str(porcentaje)+\"% de acertividad\")\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7a11699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacion_candidatos(x_e,y_e,x_p,y_p,model,epocas):\n",
    "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
    "    a=model.evaluate(x_p,y_p)\n",
    "    return a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a2c169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 511.1554 - acc: 0.5529 - val_loss: 37.5147 - val_acc: 0.7633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 37.5147 - acc: 0.7633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 21.4242 - acc: 0.7443 - val_loss: 21.1857 - val_acc: 0.7000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 21.1857 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 16.7600 - acc: 0.7286 - val_loss: 8.8940 - val_acc: 0.7633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 8.8940 - acc: 0.7633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 4.9765 - acc: 0.8143 - val_loss: 3.4680 - val_acc: 0.7967\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.4680 - acc: 0.7967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 1.3128 - acc: 0.9014 - val_loss: 3.8214 - val_acc: 0.7900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.8214 - acc: 0.7900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.4975 - acc: 0.9300 - val_loss: 2.0305 - val_acc: 0.7767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.0305 - acc: 0.7767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.0951 - acc: 0.9729 - val_loss: 2.1547 - val_acc: 0.7767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.1547 - acc: 0.7767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.0995 - acc: 0.9686 - val_loss: 2.1561 - val_acc: 0.7833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.1561 - acc: 0.7833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.1798 - acc: 0.9600 - val_loss: 2.8780 - val_acc: 0.7700\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.8780 - acc: 0.7700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.4587 - acc: 0.9257 - val_loss: 2.3860 - val_acc: 0.7633\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.3860 - acc: 0.7633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.3847 - acc: 0.9371 - val_loss: 2.2928 - val_acc: 0.7933\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 2.2928 - acc: 0.7933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.1042 - acc: 0.9671 - val_loss: 1.7288 - val_acc: 0.7900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.7288 - acc: 0.7900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.0446 - acc: 0.9843 - val_loss: 1.6807 - val_acc: 0.7800\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6807 - acc: 0.7800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 1.5823 - val_acc: 0.7900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.5823 - acc: 0.7900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 0.0047 - acc: 0.9971 - val_loss: 1.6043 - val_acc: 0.8000\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 1.6043 - acc: 0.8000\n",
      "==> Para el metodo ADAM se utilizo: 15 epocas para llegar a mas del 80% de acertividad\n"
     ]
    }
   ],
   "source": [
    "v_ca1=[]\n",
    "v_ce1=[]\n",
    "modelo_final=creacion_modelo()\n",
    "modelo_adam = keras.optimizers.Adam(learning_rate=0.0008)\n",
    "modelo_final.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce1,v_ca1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "854cee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 818\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 1215.9899 - acc: 0.5629 - val_loss: 188.4281 - val_acc: 0.5533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 188.4281 - acc: 0.5533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 77.1894 - acc: 0.6757 - val_loss: 63.8864 - val_acc: 0.5900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 63.8864 - acc: 0.5900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 36.0919 - acc: 0.6900 - val_loss: 23.3306 - val_acc: 0.7833\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 23.3306 - acc: 0.7833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 31.1116 - acc: 0.7914 - val_loss: 11.7240 - val_acc: 0.7767\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 11.7240 - acc: 0.7767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 9.9976 - acc: 0.8129 - val_loss: 9.2650 - val_acc: 0.7400\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 9.2650 - acc: 0.7400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 13.6564 - acc: 0.7271 - val_loss: 11.0451 - val_acc: 0.7533\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 11.0451 - acc: 0.7533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 9.1189 - acc: 0.8400 - val_loss: 16.0014 - val_acc: 0.7333\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 16.0014 - acc: 0.7333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 2.9423 - acc: 0.9057 - val_loss: 7.3845 - val_acc: 0.7867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 7.3845 - acc: 0.7867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 1.1772 - acc: 0.9043 - val_loss: 6.0154 - val_acc: 0.7433\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 6.0154 - acc: 0.7433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 1.1532 - acc: 0.9143 - val_loss: 6.3336 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 6.3336 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 0.5597 - acc: 0.9457 - val_loss: 6.8578 - val_acc: 0.7233\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 6.8578 - acc: 0.7233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 0.9110 - acc: 0.9414 - val_loss: 13.0165 - val_acc: 0.6900\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 13.0165 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 2.5820 - acc: 0.9014 - val_loss: 10.6236 - val_acc: 0.7267\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 10.6236 - acc: 0.7267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 7s 11ms/sample - loss: 1.4389 - acc: 0.9100 - val_loss: 4.6000 - val_acc: 0.8167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 4.6000 - acc: 0.8167\n",
      "==> Para el metodo ADAM se utilizo: 14 epocas para llegar a mas del 80% de acertividad\n"
     ]
    }
   ],
   "source": [
    "v_ca2=[]\n",
    "v_ce2=[]\n",
    "modelo_final=creacion_modelo()\n",
    "modelo_adam = keras.optimizers.Adam(learning_rate=0.0009)\n",
    "modelo_final.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce2,v_ca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe691570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 819\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 1241.0118 - acc: 0.5543 - val_loss: 90.8352 - val_acc: 0.6567\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 90.8352 - acc: 0.6567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 62.4594 - acc: 0.6743 - val_loss: 25.3321 - val_acc: 0.7867\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 25.3321 - acc: 0.7867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 21.7805 - acc: 0.7457 - val_loss: 19.0662 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 19.0662 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 8s 11ms/sample - loss: 5.8996 - acc: 0.7957 - val_loss: 3.9336 - val_acc: 0.8167\n",
      "300/300 [==============================] - 1s 2ms/sample - loss: 3.9336 - acc: 0.8167\n",
      "==> Para el metodo ADAM se utilizo: 4 epocas para llegar a mas del 80% de acertividad\n"
     ]
    }
   ],
   "source": [
    "v_ca3=[]\n",
    "v_ce3=[]\n",
    "modelo_final=creacion_modelo()\n",
    "modelo_adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "modelo_final.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce3,v_ca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff04c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 826\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 1720.3740 - acc: 0.5571 - val_loss: 12.2069 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 12.2069 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 8.2636 - acc: 0.7357 - val_loss: 1.8521 - val_acc: 0.7500\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.8521 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 1.7477 - acc: 0.7914 - val_loss: 2.4284 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 2.4284 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.8576 - acc: 0.8343 - val_loss: 8.6433 - val_acc: 0.5833\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 8.6433 - acc: 0.5833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 1.0859 - acc: 0.8429 - val_loss: 0.9228 - val_acc: 0.7367\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 0.9228 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.3744 - acc: 0.8943 - val_loss: 1.8796 - val_acc: 0.7000\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.8796 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.2902 - acc: 0.9214 - val_loss: 1.0473 - val_acc: 0.7833\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.0473 - acc: 0.7833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.2448 - acc: 0.9329 - val_loss: 0.9578 - val_acc: 0.7733\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 0.9578 - acc: 0.7733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.1334 - acc: 0.9686 - val_loss: 1.1214 - val_acc: 0.7667\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.1214 - acc: 0.7667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.1104 - acc: 0.9757 - val_loss: 1.3036 - val_acc: 0.7567\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.3036 - acc: 0.7567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0836 - acc: 0.9814 - val_loss: 1.6584 - val_acc: 0.7533\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.6584 - acc: 0.7533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0655 - acc: 0.9800 - val_loss: 1.7005 - val_acc: 0.7933\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.7005 - acc: 0.7933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0906 - acc: 0.9814 - val_loss: 0.8711 - val_acc: 0.7567\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 0.8711 - acc: 0.7567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0838 - acc: 0.9771 - val_loss: 0.7892 - val_acc: 0.7533\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 0.7892 - acc: 0.7533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0739 - acc: 0.9886 - val_loss: 2.8106 - val_acc: 0.7200\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 2.8106 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0931 - acc: 0.9829 - val_loss: 1.0954 - val_acc: 0.7567\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.0954 - acc: 0.7567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.1145 - acc: 0.9800 - val_loss: 1.3034 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.3034 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0829 - acc: 0.9843 - val_loss: 1.2358 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.2358 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0545 - acc: 0.9829 - val_loss: 1.1272 - val_acc: 0.7500\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.1272 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0364 - acc: 0.9957 - val_loss: 0.9854 - val_acc: 0.7700\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 0.9854 - acc: 0.7700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0313 - acc: 0.9971 - val_loss: 1.0275 - val_acc: 0.7767\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.0275 - acc: 0.7767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0269 - acc: 0.9971 - val_loss: 1.0312 - val_acc: 0.7733\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.0312 - acc: 0.7733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0244 - acc: 0.9971 - val_loss: 1.0600 - val_acc: 0.7733\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.0600 - acc: 0.7733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0221 - acc: 0.9971 - val_loss: 1.0903 - val_acc: 0.7733\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.0903 - acc: 0.7733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0202 - acc: 0.9971 - val_loss: 1.1314 - val_acc: 0.7667\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.1314 - acc: 0.7667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0188 - acc: 0.9971 - val_loss: 1.1588 - val_acc: 0.7700\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.1588 - acc: 0.7700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0177 - acc: 0.9971 - val_loss: 1.1948 - val_acc: 0.7700\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.1948 - acc: 0.7700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0164 - acc: 0.9971 - val_loss: 1.2341 - val_acc: 0.7700\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.2341 - acc: 0.7700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0153 - acc: 0.9971 - val_loss: 1.2748 - val_acc: 0.7667\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.2748 - acc: 0.7667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 0.0144 - acc: 0.9971 - val_loss: 1.3078 - val_acc: 0.7633\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.3078 - acc: 0.7633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 0.0134 - acc: 0.9986 - val_loss: 1.3225 - val_acc: 0.7667\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.3225 - acc: 0.7667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 0.0125 - acc: 0.9986 - val_loss: 1.3578 - val_acc: 0.7667\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.3578 - acc: 0.7667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 0.0117 - acc: 0.9986 - val_loss: 1.3815 - val_acc: 0.7633\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.3815 - acc: 0.7633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 0.0111 - acc: 0.9986 - val_loss: 1.4136 - val_acc: 0.7600\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.4136 - acc: 0.7600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 0.0105 - acc: 0.9986 - val_loss: 1.4212 - val_acc: 0.7600\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.4212 - acc: 0.7600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 0.0100 - acc: 0.9986 - val_loss: 1.4570 - val_acc: 0.7600\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.4570 - acc: 0.7600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 0.0096 - acc: 0.9986 - val_loss: 1.4657 - val_acc: 0.7567\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.4657 - acc: 0.7567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 0.0092 - acc: 0.9986 - val_loss: 1.4837 - val_acc: 0.7567\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.4837 - acc: 0.7567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 18ms/sample - loss: 0.0088 - acc: 0.9986 - val_loss: 1.5125 - val_acc: 0.7567\n",
      "300/300 [==============================] - 1s 5ms/sample - loss: 1.5125 - acc: 0.7567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.0084 - acc: 0.9986 - val_loss: 1.5235 - val_acc: 0.7600\n",
      "300/300 [==============================] - 2s 6ms/sample - loss: 1.5235 - acc: 0.7600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 14s 19ms/sample - loss: 0.0081 - acc: 0.9986 - val_loss: 1.5084 - val_acc: 0.7633\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.5084 - acc: 0.7633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.0076 - acc: 0.9986 - val_loss: 1.5351 - val_acc: 0.7600\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.5351 - acc: 0.7600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.0073 - acc: 0.9986 - val_loss: 1.5185 - val_acc: 0.7600\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.5185 - acc: 0.7600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.0069 - acc: 0.9986 - val_loss: 1.5189 - val_acc: 0.7533\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.5189 - acc: 0.7533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.0066 - acc: 0.9986 - val_loss: 1.5472 - val_acc: 0.7533\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.5472 - acc: 0.7533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.0063 - acc: 0.9986 - val_loss: 1.5576 - val_acc: 0.7467\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.5576 - acc: 0.7467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.0059 - acc: 0.9986 - val_loss: 1.5878 - val_acc: 0.7367\n",
      "300/300 [==============================] - 2s 6ms/sample - loss: 1.5878 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.0052 - acc: 0.9986 - val_loss: 1.5902 - val_acc: 0.7400\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.5902 - acc: 0.7400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 14s 19ms/sample - loss: 0.0043 - acc: 0.9986 - val_loss: 1.6214 - val_acc: 0.7333\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.6214 - acc: 0.7333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 14s 19ms/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 1.6465 - val_acc: 0.7367\n",
      "300/300 [==============================] - 2s 6ms/sample - loss: 1.6465 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 14s 20ms/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 1.6757 - val_acc: 0.7367\n",
      "300/300 [==============================] - 2s 6ms/sample - loss: 1.6757 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 14s 20ms/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 1.7010 - val_acc: 0.7367\n",
      "300/300 [==============================] - 2s 6ms/sample - loss: 1.7010 - acc: 0.7367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 14s 20ms/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 1.7217 - val_acc: 0.7333\n",
      "300/300 [==============================] - 2s 6ms/sample - loss: 1.7217 - acc: 0.7333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "352/700 [==============>...............] - ETA: 6s - loss: 9.4420e-04 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\254955899.py\", line 6, in <module>\n",
      "    evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce4,v_ca4)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1294313218.py\", line 6, in evaluacion_candidatos\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\254955899.py\", line 6, in <module>\n",
      "    evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce4,v_ca4)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1294313218.py\", line 6, in evaluacion_candidatos\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\254955899.py\", line 6, in <module>\n",
      "    evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce4,v_ca4)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1294313218.py\", line 6, in evaluacion_candidatos\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "v_ca4=[]\n",
    "v_ce4=[]\n",
    "modelo_final=creacion_modelo()\n",
    "modelo_adam = keras.optimizers.Adam(learning_rate=0.002)\n",
    "modelo_final.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce4,v_ca4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe26f548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 825\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 2078.0975 - acc: 0.5457 - val_loss: 1.0512 - val_acc: 0.6700\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.0512 - acc: 0.6700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.6841 - acc: 0.7557 - val_loss: 0.7152 - val_acc: 0.6867\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 0.7152 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.4999 - acc: 0.7957 - val_loss: 0.9493 - val_acc: 0.6900\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 0.9493 - acc: 0.6900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.3804 - acc: 0.8357 - val_loss: 0.9159 - val_acc: 0.7100\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 0.9159 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.2885 - acc: 0.8814 - val_loss: 1.1001 - val_acc: 0.6933\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.1001 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.2223 - acc: 0.9214 - val_loss: 1.8034 - val_acc: 0.7000\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.8034 - acc: 0.7000\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 13s 19ms/sample - loss: 0.2121 - acc: 0.9271 - val_loss: 1.2689 - val_acc: 0.6667\n",
      "300/300 [==============================] - 2s 5ms/sample - loss: 1.2689 - acc: 0.6667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "384/700 [===============>..............] - ETA: 5s - loss: 0.3217 - acc: 0.8385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2693169880.py\", line 6, in <module>\n",
      "    evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce5,v_ca5)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1294313218.py\", line 6, in evaluacion_candidatos\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2693169880.py\", line 6, in <module>\n",
      "    evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce5,v_ca5)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1294313218.py\", line 6, in evaluacion_candidatos\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2693169880.py\", line 6, in <module>\n",
      "    evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce5,v_ca5)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1294313218.py\", line 6, in evaluacion_candidatos\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "v_ca5=[]\n",
    "v_ce5=[]\n",
    "modelo_final=creacion_modelo()\n",
    "modelo_adam = keras.optimizers.Adam(learning_rate=0.003)\n",
    "modelo_final.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce5,v_ca5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3456671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 823\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 18ms/sample - loss: 2277.4132 - acc: 0.5571 - val_loss: 0.8386 - val_acc: 0.7500\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 0.8386 - acc: 0.7500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.6660 - acc: 0.7514 - val_loss: 0.8134 - val_acc: 0.6967\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 0.8134 - acc: 0.6967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.5384 - acc: 0.7800 - val_loss: 1.1036 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.1036 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4998 - acc: 0.7929 - val_loss: 0.8017 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 0.8017 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4132 - acc: 0.8414 - val_loss: 0.8494 - val_acc: 0.7267\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 0.8494 - acc: 0.7267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4203 - acc: 0.8157 - val_loss: 0.8513 - val_acc: 0.6867\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 0.8513 - acc: 0.6867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4017 - acc: 0.8243 - val_loss: 0.9323 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 0.9323 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4176 - acc: 0.8229 - val_loss: 0.9358 - val_acc: 0.6933\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 0.9358 - acc: 0.6933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4321 - acc: 0.7986 - val_loss: 1.0117 - val_acc: 0.7033\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.0117 - acc: 0.7033\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4197 - acc: 0.8086 - val_loss: 1.1282 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.1282 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4055 - acc: 0.8143 - val_loss: 1.1971 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.1971 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3977 - acc: 0.8171 - val_loss: 1.2600 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.2600 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3933 - acc: 0.8200 - val_loss: 1.3268 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.3268 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3898 - acc: 0.8214 - val_loss: 1.3817 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.3817 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3857 - acc: 0.8229 - val_loss: 1.4403 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.4403 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3821 - acc: 0.8243 - val_loss: 1.5218 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.5218 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3803 - acc: 0.8271 - val_loss: 1.5412 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.5412 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3757 - acc: 0.8286 - val_loss: 1.5789 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.5789 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3751 - acc: 0.8286 - val_loss: 1.6471 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.6471 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3726 - acc: 0.8300 - val_loss: 1.6342 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.6342 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3712 - acc: 0.8314 - val_loss: 1.6738 - val_acc: 0.7167\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.6738 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3674 - acc: 0.8314 - val_loss: 1.7390 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.7390 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3664 - acc: 0.8343 - val_loss: 1.7451 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.7451 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3645 - acc: 0.8357 - val_loss: 1.7708 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.7708 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 12s 16ms/sample - loss: 0.3599 - acc: 0.8386 - val_loss: 1.8253 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.8253 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3550 - acc: 0.8414 - val_loss: 1.8478 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.8478 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3505 - acc: 0.8443 - val_loss: 1.8674 - val_acc: 0.7100\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.8674 - acc: 0.7100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3453 - acc: 0.8457 - val_loss: 1.9366 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.9366 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3396 - acc: 0.8500 - val_loss: 2.0097 - val_acc: 0.7200\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 2.0097 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3373 - acc: 0.8500 - val_loss: 2.0127 - val_acc: 0.7133\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 2.0127 - acc: 0.7133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3536 - acc: 0.8486 - val_loss: 2.6271 - val_acc: 0.7300\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 2.6271 - acc: 0.7300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4447 - acc: 0.8443 - val_loss: 2.0394 - val_acc: 0.7167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 4ms/sample - loss: 2.0394 - acc: 0.7167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 1.3700 - acc: 0.8414 - val_loss: 2.1128 - val_acc: 0.7267\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 2.1128 - acc: 0.7267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.4402 - acc: 0.8500 - val_loss: 1.7622 - val_acc: 0.7200\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 1.7622 - acc: 0.7200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "700/700 [==============================] - 11s 16ms/sample - loss: 0.3371 - acc: 0.8557 - val_loss: 2.1149 - val_acc: 0.7067\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 2.1149 - acc: 0.7067\n",
      "Train on 700 samples, validate on 300 samples\n",
      "224/700 [========>.....................] - ETA: 6s - loss: 0.3154 - acc: 0.8661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1233012558.py\", line 6, in <module>\n",
      "    evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce6,v_ca6)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1294313218.py\", line 6, in evaluacion_candidatos\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1233012558.py\", line 6, in <module>\n",
      "    evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce6,v_ca6)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1294313218.py\", line 6, in evaluacion_candidatos\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1233012558.py\", line 6, in <module>\n",
      "    evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce6,v_ca6)\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\1294313218.py\", line 6, in evaluacion_candidatos\n",
      "    prediccion=(validacion(x_e,y_e,x_p,y_p,modelo,1))*100\n",
      "  File \"C:\\Users\\Desktop\\AppData\\Local\\Temp\\ipykernel_14476\\2902134277.py\", line 2, in validacion\n",
      "    entre=model.fit(x_e,y_e,batch_size=32,epochs=epocas,validation_data=(x_p,y_p))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 675, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 394, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Desktop\\.conda\\envs\\TESIS\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "v_ca6=[]\n",
    "v_ce6=[]\n",
    "modelo_final=creacion_modelo()\n",
    "modelo_adam = keras.optimizers.Adam(learning_rate=0.004)\n",
    "modelo_final.compile(optimizer=modelo_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "evaluacion_candidatos(modelo_final,80,\"ADAM\",v_ce6,v_ca6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "708917eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9a6e3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp.plot(v_ca1,v_ce1, marker='o', linestyle=':', color='b', label = \"LR=0.0008\")\n",
    "mp.plot(v_ca2,v_ce2, marker='x', linestyle='-', color='g', label = \"LR=0.0009\")\n",
    "mp.plot(v_ca3,v_ce3, marker='^', linestyle='--', color='r', label = \"LR=0.001\")\n",
    "\n",
    "#mp.xticks(np.arange(70,100,2))\n",
    "#mp.yticks(np.arange(0,4,1))\n",
    "mp.xlabel(\"porcentaje de asertividad\")\n",
    "mp.ylabel(\"Numero de epocas\")\n",
    "mp.legend(loc=\"upper left\")\n",
    "mp.title(\"Nivel de asertividad/epocas respecto a los LR candidatos\")\n",
    "mp.grid(True)\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c619fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asertividad del LR=0.0008: 80.0% alcanzado en: 15 epocas.\n",
      "asertividad del LR=0.0008: 81.7% alcanzado en: 14 epocas.\n",
      "asertividad del LR=0.0008: 81.7% alcanzado en: 4 epocas.\n"
     ]
    }
   ],
   "source": [
    "print(\"asertividad del LR=0.0008: \"+str(round(v_ca1[-1],1))+\"% alcanzado en: \"+str(v_ce1[-1])+ \" epocas.\")\n",
    "print(\"asertividad del LR=0.0008: \"+str(round(v_ca2[-1],1))+\"% alcanzado en: \"+str(v_ce2[-1])+ \" epocas.\")\n",
    "print(\"asertividad del LR=0.0008: \"+str(round(v_ca3[-1],1))+\"% alcanzado en: \"+str(v_ce3[-1])+ \" epocas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86b0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
